{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdSTSEabgyx2"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Introdução e Problemática\n",
        "\n",
        "O objetivo deste projeto é desenvolver um modelo preditivo capaz de prever o **placar final de partidas de futebol**, utilizando dados históricos do Campeonato Brasileiro Série A. A previsão de placares em eventos esportivos é um desafio complexo devido à alta variabilidade de fatores que influenciam o resultado de uma partida. Dessa forma, a abordagem utilizada aqui envolve a modelagem de dados históricos de jogos para capturar padrões e tendências que possam auxiliar na previsão.\n",
        "\n",
        "#### Hipóteses de Trabalho\n",
        "\n",
        "Antes de iniciar o processo de modelagem, algumas **hipóteses** foram formuladas com base na natureza do problema e no comportamento esperado dos dados:\n",
        "\n",
        "1. **Hipótese 1**: As estatísticas de desempenho dos times, como número de chutes a gol, posse de bola, e estatísticas defensivas, têm correlação direta com o número de gols marcados.\n",
        "   \n",
        "2. **Hipótese 2**: Variáveis como **gols ao intervalo**, **xG (expected goals)** e **faltas cometidas** podem servir como preditores relevantes, especialmente quando combinadas com métricas de eficiência ofensiva e defensiva.\n",
        "\n",
        "3. **Hipótese 3**: Modelos lineares, como o **Lasso**, devido à sua capacidade de regularização e tratamento de features menos relevantes, podem fornecer previsões estáveis e evitar o overfitting, enquanto modelos não lineares, como **Random Forest**, podem capturar interações mais complexas entre as variáveis.\n",
        "\n",
        "#### Abordagem\n",
        "\n",
        "A abordagem adotada inclui a experimentação de diferentes modelos, sendo os principais:\n",
        "\n",
        "- **Lasso Regression**: Um modelo linear com regularização que reduz a influência de variáveis menos importantes. Esta abordagem é utilizada para evitar o overfitting, ao mesmo tempo em que mantém a interpretabilidade do modelo.\n",
        "  \n",
        "- **Random Forest**: Um modelo baseado em árvores de decisão, capaz de capturar interações complexas entre variáveis. Apesar de sua flexibilidade, pode sofrer com overfitting, principalmente em conjuntos de dados pequenos.\n",
        "\n",
        "- **XGBoost e LightGBM**: Testados como alternativas não lineares robustas, especialmente para capturar interações de dados complexos e otimizar a predição dos placares.\n",
        "\n",
        "#### Conceitos Chave\n",
        "\n",
        "Os seguintes **conceitos** desempenham um papel fundamental na análise e serão discutidos ao longo do projeto:\n",
        "\n",
        "- **Expected Goals (xG)**: Uma métrica preditiva que avalia a probabilidade de um time marcar em cada jogada. Usada para entender a eficiência ofensiva dos times.\n",
        "- **Regularização (Lasso)**: Reduz o impacto de variáveis menos relevantes, evitando o ajuste excessivo e permitindo um modelo mais generalizável.\n",
        "- **Validação Cruzada (Cross-Validation)**: Utilizada para garantir que o modelo não esteja apenas ajustado aos dados de treino, testando o desempenho em várias partições dos dados.\n",
        "\n",
        "#### Modelos Promissores\n",
        "\n",
        "Baseado nas hipóteses e testes iniciais, os **modelos mais promissores** identificados foram:\n",
        "\n",
        "1. **Lasso Regression**: Mostrou-se eficaz em balancear simplicidade e capacidade preditiva, obtendo os melhores resultados de previsão de gols até o momento.\n",
        "   \n",
        "2. **Random Forest**: Embora tenha mostrado algum potencial, apresentou problemas de overfitting em comparação ao Lasso.\n",
        "\n",
        "3. **Modelos Boosting (XGBoost e LightGBM)**: Explorados por sua robustez em cenários de dados mais complexos, com um potencial promissor de melhorias em futuros ajustes de hiperparâmetros.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eohaMc8ro9SN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Leitura dos arquivos CSV\n",
        "df_matches = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/brazil-serie-a-matches-2024-to-2024-stats_edit - brazil-serie-a-matches-2024-to-2024-stats_edit.csv')\n",
        "df_teams = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/brazil-serie-a-teams-2024-to-2024-stats (1) - brazil-serie-a-teams-2024-to-2024-stats (1).csv')\n",
        "df_teams2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/brazil-serie-a-teams2-2024-to-2024-stats (1) - brazil-serie-a-teams2-2024-to-2024-stats (1).csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nieAQUFfqFHr",
        "outputId": "0534ba74-2658-42ab-f10c-7558ae9ec3a6"
      },
      "outputs": [],
      "source": [
        "# Visualizando as primeiras 5 linhas dos DataFrames\n",
        "print(df_matches.head())\n",
        "print(df_teams.head())\n",
        "print(df_teams2.head())\n",
        "\n",
        "# Informações sobre os DataFrames\n",
        "print(df_matches.info())\n",
        "print(df_teams.info())\n",
        "print(df_teams2.info())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMACDkynhLqY"
      },
      "source": [
        "Essas células estão carregando e inspecionando os dados a partir de arquivos CSV, e aqui estão as principais observações sobre o conteúdo:\n",
        "\n",
        "### 1. **Leitura dos arquivos CSV**:\n",
        "- Três arquivos CSV estão sendo carregados:\n",
        "  - **`df_matches`**: Contém dados relacionados às partidas (com atributos como timestamp, times, status, e estatísticas de pré-jogo).\n",
        "  - **`df_teams`**: Contém dados sobre os times.\n",
        "  - **`df_teams2`**: Outro conjunto de dados relacionado aos times (provavelmente com mais detalhes ou atributos adicionais sobre os times).\n",
        "\n",
        "### 2. **Visualização das primeiras 5 linhas**:\n",
        "- A função **`head()`** está sendo usada para visualizar as 5 primeiras linhas dos DataFrames:\n",
        "  - **df_matches**: Possui atributos como timestamp, data, status do jogo, times, e estatísticas pré-jogo (como porcentagens de chance de mais de 35%, 45% de gols antes do intervalo, entre outras).\n",
        "  - **df_teams**: Contém o nome do time, estádio, e outras características relacionadas aos times (a partir das colunas exibidas, parece conter informações sobre a temporada e número de jogos disputados).\n",
        "\n",
        "### 3. **Informações sobre os DataFrames**:\n",
        "- A função **`info()`** está sendo usada para fornecer detalhes sobre o número de colunas, tipos de dados e a presença de valores nulos em cada um dos DataFrames.\n",
        "  - **df_matches**: Possui 58 colunas, incluindo variáveis como **Pre-Match PPG (Home)**, **average cards per match**, e **average corners per match**. Algumas dessas colunas apresentam **valores nulos** (como `attendance`, `stadium_name`), o que pode exigir algum tratamento posterior.\n",
        "  - **df_teams** e **df_teams2**: Ambos contêm atributos dos times. Os detalhes exibidos no `head()` mostram informações como **team_name**, **stadium_name**, e **matches_played**, mas há colunas sem nomes (coluna \"Unnamed\") que podem precisar ser ajustadas ou removidas.\n",
        "\n",
        "### Ações sugeridas:\n",
        "1. **Limpeza de Dados**:\n",
        "   - É importante tratar os **valores nulos**, especialmente em colunas como `attendance`, `stadium_name`, e outros atributos cruciais para a análise.\n",
        "   - Verificar colunas com nomes como \"Unnamed\", que podem ter sido criadas por erros ao exportar ou carregar os dados, e ver se elas são relevantes.\n",
        "\n",
        "2. **Análise de Features**:\n",
        "   - Algumas das features carregadas podem não ser diretamente relevantes para o modelo (por exemplo, `stadium_name` ou `attendance` podem não influenciar diretamente o placar).\n",
        "   - Focar em features relacionadas ao desempenho de jogo (chutes, posse de bola, etc.) e em estatísticas pré-jogo que possam ter correlação com o número de gols.\n",
        "\n",
        "3. **Consolidação dos Dados**:\n",
        "   - É possível que seja necessário unir os DataFrames (como `df_matches` e `df_teams`) para consolidar informações das partidas com dados dos times.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH1CBUX6qFrS",
        "outputId": "63615e6c-b4a2-4317-d11e-c0812e26ff17"
      },
      "outputs": [],
      "source": [
        "# Descrição estatística dos dados numéricos\n",
        "print(df_matches.describe())\n",
        "print(df_teams.describe())\n",
        "print(df_teams2.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI3SBYumqHmx",
        "outputId": "e27308be-faaa-4678-96ce-577e0a5e80ac"
      },
      "outputs": [],
      "source": [
        "# Verificando a presença de valores nulos\n",
        "print(df_matches.isnull().sum())\n",
        "print(df_teams.isnull().sum())\n",
        "print(df_teams2.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fTp1bOvhcTM"
      },
      "source": [
        "### Análise das Células:\n",
        "\n",
        "#### 1. **Descrição Estatística dos Dados Numéricos**:\n",
        "- **`describe()`** foi aplicado em cada um dos DataFrames para exibir uma **descrição estatística** dos dados numéricos, incluindo a média (**mean**), desvio padrão (**std**), valores mínimos e máximos, além dos percentis (25%, 50%, 75%).\n",
        "\n",
        "**Principais observações**:\n",
        "- **df_matches**: Exibe estatísticas sobre **attendance (público)**, **gols por minuto**, e **cartões**.\n",
        "  - A média de público varia entre 9.369 para jogos em casa e 17.372 para jogos no total, com um máximo de 56.929 espectadores.\n",
        "  - Minutos por gol marcado em casa e fora variam bastante: média de 81 minutos para o time da casa e 114 minutos para o time visitante, o que indica que os times da casa tendem a marcar mais rápido.\n",
        "  \n",
        "- **df_teams e df_teams2**: Esses DataFrames trazem estatísticas por time, como **minutos por gol sofrido**, **minutos por gol marcado**, e dados de **gols com ambas as equipes marcando (btts)**.\n",
        "  - Valores extremos, como **450 minutos** por gol sofrido fora de casa ou **225 minutos** para gols marcados fora, indicam que algumas equipes possuem defesas muito fortes ou ataques menos eficientes.\n",
        "  \n",
        "#### 2. **Verificação da Presença de Valores Nulos**:\n",
        "- A célula que usa **`isnull().sum()`** para verificar a quantidade de valores nulos em cada coluna dos três DataFrames revela algumas colunas com grandes quantidades de valores ausentes:\n",
        "  - **df_matches**: As colunas **home_team_goal_timings** e **away_team_goal_timings** possuem uma quantidade significativa de valores ausentes (309 e 318 nulos, respectivamente). Isso é importante, pois esses valores podem influenciar diretamente na predição do placar.\n",
        "  - **df_teams e df_teams2**: Não apresentam valores nulos nas colunas mostradas.\n",
        "\n",
        "### Ações Sugeridas:\n",
        "1. **Tratamento de Valores Nulos**:\n",
        "   - Para as colunas com valores nulos, como **goal_timings**, é necessário decidir se esses valores devem ser preenchidos (imputação) ou se essas colunas devem ser removidas caso os dados ausentes sejam predominantes.\n",
        "   - Para o público ausente, uma opção seria preencher os valores com a média ou mediana do público dos outros jogos, caso seja uma variável importante para o modelo.\n",
        "\n",
        "2. **Revisão de Outliers**:\n",
        "   - Algumas métricas como **minutos por gol marcado/sofrido** possuem valores muito altos ou baixos. Esses outliers podem ser tratados (removidos ou ajustados) para evitar distorções nas previsões.\n",
        "\n",
        "3. **Avaliação da Relevância das Features**:\n",
        "   - Nem todas as variáveis podem ser relevantes para prever o placar final. Estatísticas como **average cards per match** e **minutes per goal** são potencialmente úteis, mas outras, como **attendance**, podem não ser tão impactantes para o objetivo final.\n",
        "\n",
        "Essas análises iniciais ajudam a entender a distribuição dos dados, identificar problemas com valores ausentes e estabelecer um ponto de partida para a limpeza e preparação dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQtpAoWRqJzg",
        "outputId": "e1c8492f-57ba-40c0-f91c-7867c285b3bc"
      },
      "outputs": [],
      "source": [
        "# Verificando duplicatas\n",
        "print(df_matches.duplicated().sum())\n",
        "print(df_teams.duplicated().sum())\n",
        "print(df_teams2.duplicated().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-h3gcJyqK4S",
        "outputId": "95b28e4f-6087-4e95-eccb-037a0d41d6a9"
      },
      "outputs": [],
      "source": [
        "# Exibindo colunas e tipos de dados\n",
        "print(df_matches.dtypes)\n",
        "print(df_teams.dtypes)\n",
        "print(df_teams2.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YA67brLwuSnN",
        "outputId": "154eb7b8-8e2d-4af3-afd4-db9ae1e00a2d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Distribuição dos gols marcados pelos times da casa e visitantes\n",
        "plt.figure(figsize=(14,6))\n",
        "\n",
        "# Gols marcados pelo time da casa\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df_matches['home_team_goal_count'], bins=10, kde=True, color='blue')\n",
        "plt.title('Distribuição dos Gols do Time da Casa')\n",
        "\n",
        "# Gols marcados pelo time visitante\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df_matches['away_team_goal_count'], bins=10, kde=True, color='green')\n",
        "plt.title('Distribuição dos Gols do Time Visitante')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlação entre as variáveis principais e os gols marcados pensando em prever placar final e sustentado por uma das hipoteses do placar final\n",
        "correlation_matrix = df_matches[['home_team_goal_count', 'away_team_goal_count', 'Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'Home Team Pre-Match xG', 'Away Team Pre-Match xG']].corr()\n",
        "\n",
        "# Exibindo a matriz de correlação\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlação entre Variáveis Selecionadas e Gols')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeUHgtQshupj"
      },
      "source": [
        "### Análise das Células:\n",
        "\n",
        "#### 1. **Distribuição dos Gols Marcados pelos Times da Casa e Visitantes**:\n",
        "- O gráfico de histograma mostra a distribuição dos gols para os times da casa e visitantes.\n",
        "  - **Distribuição dos Gols do Time da Casa**: A maioria dos times da casa marcam de 0 a 1 gol, com pouquíssimas ocorrências de mais de 3 gols. Isso indica uma baixa frequência de placares com muitos gols pelos times da casa.\n",
        "  - **Distribuição dos Gols do Time Visitante**: A distribuição é semelhante à dos times da casa, com a maioria dos visitantes marcando entre 0 e 1 gol. No entanto, há algumas ocorrências de times visitantes marcando até 5 gols, o que é um outlier importante a ser observado.\n",
        "\n",
        "#### 2. **Matriz de Correlação**:\n",
        "- A matriz de correlação mostra como as variáveis principais estão correlacionadas com os gols marcados pelos times da casa e visitantes.\n",
        "  - **Correlação entre Gols e xG (Expected Goals)**:\n",
        "    - Existe uma correlação negativa moderada entre **gols marcados pelo time da casa** e o **xG do time visitante** (-0.34), e uma correlação similar entre **gols marcados pelo time visitante** e o **xG do time da casa** (-0.28). Isso sugere que quanto maior o xG do time adversário, menor é a probabilidade de o time marcar gols, o que faz sentido, pois um bom desempenho esperado do adversário reflete uma possível contenção de gols.\n",
        "  - **Pre-Match PPG (Points Per Game)**:\n",
        "    - A correlação entre **Pre-Match PPG (Home)** e **gols marcados pelo time da casa** é fraca (-0.14), sugerindo que essa métrica, isoladamente, pode não ser um bom indicador para prever o número de gols marcados. O mesmo padrão se aplica ao time visitante (-0.16).\n",
        "  \n",
        "#### **Principais Observações**:\n",
        "1. **Distribuições Desequilibradas**: As distribuições dos gols são fortemente inclinadas para poucos gols (0 ou 1), o que pode influenciar o modelo preditivo, fazendo com que ele tenda a prever resultados com poucos gols com mais frequência.\n",
        "2. **Correlação Moderada**: Algumas das variáveis, como o **xG** (Expected Goals), mostram uma correlação moderada, enquanto outras, como o **PPG (Points Per Game)**, têm correlação baixa, sugerindo que estas podem não ser as melhores variáveis preditivas para o placar.\n",
        "3. **Possíveis Outliers**: A presença de times visitantes que marcaram até 5 gols pode ser considerada um outlier, o que pode impactar negativamente a performance do modelo caso não seja tratado.\n",
        "\n",
        "#### Ações Sugeridas:\n",
        "1. **Transformação dos Dados**: A distribuição dos gols é altamente concentrada em 0 e 1, o que pode sugerir a necessidade de uma transformação nos dados (como uma transformação logarítmica) para normalizar essa distribuição e ajudar no desempenho do modelo.\n",
        "2. **Revisar o Impacto do PPG e xG**: Com base na matriz de correlação, é importante testar o impacto das variáveis **PPG** e **xG** e verificar se elas realmente agregam ao modelo ou se devem ser removidas para evitar ruído nas previsões.\n",
        "3. **Consideração de Outliers**: Deve-se avaliar se os outliers observados (placares de 5 gols por times visitantes) devem ser tratados para evitar distorções na performance do modelo.\n",
        "\n",
        "Esses gráficos ajudam a entender a relação entre as variáveis e as distribuições de gols, fornecendo insights importantes para o ajuste dos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N8oMBOSvu7D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "threshold = 0.8\n",
        "\n",
        "# Função para remover colunas e linhas com valores nulos acima de um limite\n",
        "def clean_data(df, column_thresh=0.8, row_thresh=0.5):\n",
        "    # Remove colunas com mais de 80% de valores ausentes\n",
        "    df_cleaned = df.dropna(thresh=df.shape[0] * column_thresh, axis=1)\n",
        "\n",
        "    # Remove linhas com mais de 50% de valores ausentes\n",
        "    df_cleaned = df_cleaned.dropna(thresh=df_cleaned.shape[1] * row_thresh)\n",
        "\n",
        "    return df_cleaned\n",
        "\n",
        "# Limpar as três tabelas\n",
        "matches_df_cleaned = clean_data(df_matches)\n",
        "teams_df_cleaned = clean_data(df_teams)\n",
        "teams2_df_cleaned = clean_data(df_teams2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMrfsedGvvDX"
      },
      "outputs": [],
      "source": [
        "# Função para remover outliers com base no IQR (Interquartile Range) sua abordagem e melhor que o Z-score pois nao depende de uma distribuicao normal dos dados\n",
        "def remove_outliers(df, columns):\n",
        "    Q1 = df[columns].quantile(0.25)\n",
        "    Q3 = df[columns].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    return df[~((df[columns] < (Q1 - 1.5 * IQR)) | (df[columns] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Selecionar as colunas numéricas relevantes\n",
        "numerical_columns = [\n",
        "    'home_team_goal_count', 'away_team_goal_count', 'Pre-Match PPG (Home)',\n",
        "    'Pre-Match PPG (Away)', 'Home Team Pre-Match xG', 'Away Team Pre-Match xG'\n",
        "]\n",
        "\n",
        "# Remover outliers das colunas numéricas no dataset de partidas\n",
        "matches_df_no_outliers = remove_outliers(matches_df_cleaned, numerical_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVEGw_x_vvJX",
        "outputId": "1cfb073a-894a-4b3c-d0e1-8f23aadd6d00"
      },
      "outputs": [],
      "source": [
        "# Visualizando os novo df limpos\n",
        "matches_df_cleaned.info()\n",
        "teams_df_cleaned.info()\n",
        "teams2_df_cleaned.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZnMG2mFir1Y"
      },
      "source": [
        "### Análise das Células:\n",
        "\n",
        "#### 1. **Função de Limpeza de Dados**:\n",
        "- A função **`clean_data()`** é utilizada para remover colunas e linhas com valores nulos acima de um limite especificado:\n",
        "  - **Remoção de Colunas**: Colunas com mais de 80% de valores ausentes são removidas.\n",
        "  - **Remoção de Linhas**: Linhas com mais de 50% de valores ausentes são removidas.\n",
        "- Essa limpeza ajuda a garantir que apenas colunas e linhas com dados relevantes sejam mantidas, eliminando informações que possam gerar ruído no modelo.\n",
        "  \n",
        "#### 2. **Função de Remoção de Outliers**:\n",
        "- A função **`remove_outliers()`** utiliza o método do **Interquartile Range (IQR)** para identificar e remover outliers das colunas numéricas selecionadas:\n",
        "  - **IQR**: A diferença entre o terceiro quartil (**Q3**) e o primeiro quartil (**Q1**) é usada para identificar valores fora do intervalo esperado.\n",
        "  - **Critério**: Valores menores que **Q1 - 1.5 * IQR** ou maiores que **Q3 + 1.5 * IQR** são considerados outliers e removidos.\n",
        "  - Esse método é uma abordagem mais robusta que o uso de **Z-score**, pois é menos sensível a distribuições que não seguem uma forma perfeitamente normal.\n",
        "\n",
        "#### 3. **Seleção de Colunas Numéricas**:\n",
        "- As colunas numéricas selecionadas para a remoção de outliers são:\n",
        "  - **home_team_goal_count** e **away_team_goal_count**: Contagem dos gols marcados por cada time.\n",
        "  - **Pre-Match PPG (Home)** e **Pre-Match PPG (Away)**: Pontos por jogo antes da partida.\n",
        "  - **Home Team Pre-Match xG** e **Away Team Pre-Match xG**: Gols esperados antes da partida.\n",
        "  - Essas colunas são importantes para a previsão do placar final e eliminar outliers nelas garante que o modelo não seja influenciado por valores extremos.\n",
        "\n",
        "#### 4. **Visualização dos Dados Limpos**:\n",
        "- Após a limpeza e remoção de outliers, a função **`.info()`** é utilizada para exibir informações sobre os DataFrames:\n",
        "  - **matches_df_cleaned**: Agora contém 380 entradas, o que indica que a limpeza preservou a maioria dos dados, sendo uma base robusta para análise posterior.\n",
        "  - As colunas numéricas como **gols**, **xG** e **PPG** foram limpas e não possuem valores nulos, o que é essencial para o bom desempenho dos modelos preditivos.\n",
        "\n",
        "### Principais Observações:\n",
        "1. **Limpeza Eficiente**:\n",
        "   - A limpeza dos dados foi feita de maneira eficiente, eliminando tanto colunas quanto linhas com grandes proporções de valores nulos.\n",
        "   - O uso do **IQR** para detectar e remover outliers é uma abordagem sólida, especialmente em dados com distribuições não normais, como é o caso de eventos esportivos.\n",
        "\n",
        "2. **Dados Prontos para Modelagem**:\n",
        "   - Com os dados numéricos relevantes limpos e sem valores nulos, o próximo passo será utilizá-los diretamente no treinamento dos modelos preditivos, garantindo que o impacto de valores extremos ou inconsistências seja minimizado.\n",
        "\n",
        "3. **Possível Ajuste**:\n",
        "   - Dependendo da performance dos modelos, pode ser interessante ajustar o limite de remoção de outliers (por exemplo, alterando o fator 1.5 no cálculo do IQR) para testar diferentes níveis de sensibilidade à detecção de valores extremos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "wcyKVffjvvLs",
        "outputId": "85215cd2-f281-410c-a3ca-f8a5a9fbfe5a"
      },
      "outputs": [],
      "source": [
        "#Juntando as tabelas\n",
        "\n",
        "# Examinando os nomes das equipes nas tabelas para encontrar a melhor chave de junção\n",
        "matches_teams_cleaned = matches_df_no_outliers.copy()\n",
        "\n",
        "# Verificar se as colunas de nome de time estão consistentes nas três tabelas\n",
        "teams_df_cleaned_columns = teams_df_cleaned.columns\n",
        "teams2_df_cleaned_columns = teams2_df_cleaned.columns\n",
        "\n",
        "# Unir as tabelas pela chave de time (home_team_name e away_team_name com nomes nas tabelas de times)\n",
        "# Realizando merge da tabela de partidas(matches) com as tabelas de times (teams e teams2)\n",
        "\n",
        "# Primeiramente com teams_df_cleaned, fazendo merge com base nos nomes dos times\n",
        "merged_df = pd.merge(\n",
        "    matches_teams_cleaned,\n",
        "    teams_df_cleaned,\n",
        "    how='left',\n",
        "    left_on='home_team_name',\n",
        "    right_on=teams_df_cleaned.columns[0]  # Usando a primeira coluna da tabela de times para junção\n",
        ")\n",
        "\n",
        "# Agora fazemos o mesmo para os times visitantes, unindo pela coluna de nome do time visitante\n",
        "final_merged_df = pd.merge(\n",
        "    merged_df,\n",
        "    teams2_df_cleaned,\n",
        "    how='left',\n",
        "    left_on='away_team_name',\n",
        "    right_on=teams2_df_cleaned.columns[0]  # Usando a primeira coluna da tabela de times para junção\n",
        ")\n",
        "\n",
        "# Exibindo as primeiras linhas do DataFrame final, com as tabelas já unidas\n",
        "final_merged_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "RJJOtMeCvvOC",
        "outputId": "57e24f15-71e2-4e74-bda5-e334c62058dd"
      },
      "outputs": [],
      "source": [
        "# Carregando o novamente arquivo fornecido para reiniciar a análise com foco em jogos completos\n",
        "matches_df_new = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/brazil-serie-a-matches-2024-to-2024-stats_edit - brazil-serie-a-matches-2024-to-2024-stats_edit.csv')\n",
        "\n",
        "# Filtrando apenas os jogos completos\n",
        "matches_df_new_complete = matches_df_new[matches_df_new['status'] == 'complete']\n",
        "\n",
        "# Exibindo as primeiras linhas dos jogos completos para revisão\n",
        "matches_df_new_complete.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdg75Xpui8pU"
      },
      "source": [
        "### Análise das Células:\n",
        "\n",
        "#### 1. **Juntando as Tabelas de Times e Partidas**:\n",
        "- **Objetivo**: Combinar a tabela de partidas com as tabelas de dados dos times (times da casa e visitantes) para formar um único DataFrame unificado, que contenha tanto os dados das partidas quanto os dados agregados dos times.\n",
        "  \n",
        "- **Passos Realizados**:\n",
        "  1. **Verificação de Colunas Consistentes**: É feito um check para garantir que as colunas relevantes estejam presentes em todas as tabelas de times.\n",
        "  2. **Merge da Tabela de Partidas com Times da Casa**: Utilizando o nome do time da casa (`home_team_name`) para combinar as informações da tabela de partidas com a tabela de times da casa.\n",
        "  3. **Merge da Tabela de Partidas com Times Visitantes**: A mesma operação é realizada para unir a tabela de times visitantes, utilizando o campo `away_team_name`.\n",
        "  4. **Resultado**: O DataFrame resultante contém informações completas sobre a partida, incluindo estatísticas e dados dos dois times envolvidos (casa e visitante). A visualização do **`final_merged_df`** mostra 787 colunas, representando a união das informações das tabelas de times e partidas.\n",
        "\n",
        "#### 2. **Carregando Arquivo e Filtrando Jogos Completos**:\n",
        "- **Objetivo**: Carregar e filtrar a tabela de partidas para garantir que apenas os jogos completos (onde todas as informações relevantes estão disponíveis) sejam utilizados na análise posterior.\n",
        "\n",
        "- **Passos Realizados**:\n",
        "  1. **Carregamento dos Dados**: A tabela de partidas é recarregada para garantir que os dados estão atualizados.\n",
        "  2. **Filtragem por Status de Jogos Completos**: Filtra-se apenas as linhas onde o status da partida é `complete`, removendo jogos suspensos ou incompletos que poderiam prejudicar a precisão do modelo.\n",
        "  3. **Exibição dos Jogos Completos**: A visualização da tabela filtrada mostra que todos os jogos presentes na nova tabela têm o status `complete`, assegurando a integridade dos dados para a modelagem.\n",
        "\n",
        "### Pontos Importantes:\n",
        "- **Consistência dos Dados**: A junção das tabelas foi bem-sucedida, e o filtro para considerar apenas jogos completos melhora a qualidade do dataset utilizado para a predição.\n",
        "- **Complexidade das Colunas**: A combinação das tabelas resultou em um DataFrame com um grande número de colunas (787), o que pode ser desafiador, mas também oferece uma gama ampla de variáveis para refinar o modelo preditivo.\n",
        "- **Próximos Passos**:\n",
        "  - Analisar as correlações entre as variáveis mais relevantes e os resultados dos jogos.\n",
        "  - Avaliar a necessidade de remover ou agregar variáveis menos relevantes para simplificar o modelo sem perda de performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNrLTkL-xUQ7",
        "outputId": "a147406d-390b-4110-e0d7-764c4bfc8c56"
      },
      "outputs": [],
      "source": [
        "# Carregando novamente as tabelas de time\n",
        "teams2_df_new = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/brazil-serie-a-teams2-2024-to-2024-stats (1) - brazil-serie-a-teams2-2024-to-2024-stats (1).csv')\n",
        "teams_df_new = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/brazil-serie-a-teams-2024-to-2024-stats (1) - brazil-serie-a-teams-2024-to-2024-stats (1).csv')\n",
        "\n",
        "# Limpar as tabelas de times\n",
        "teams2_df_cleaned = clean_data(teams2_df_new)\n",
        "teams_df_cleaned = clean_data(teams_df_new)\n",
        "\n",
        "# Unir a tabela de partidas completas com as tabelas de times\n",
        "# Primeiro com a tabela de times da casa\n",
        "merged_df_new = pd.merge(\n",
        "    matches_df_new_complete,\n",
        "    teams_df_cleaned,\n",
        "    how='left',\n",
        "    left_on='home_team_name',\n",
        "    right_on=teams_df_cleaned.columns[0]\n",
        ")\n",
        "\n",
        "# Unir com a tabela de times visitantes\n",
        "final_merged_df_new = pd.merge(\n",
        "    merged_df_new,\n",
        "    teams2_df_cleaned,\n",
        "    how='left',\n",
        "    left_on='away_team_name',\n",
        "    right_on=teams2_df_cleaned.columns[0]\n",
        ")\n",
        "\n",
        "# Exibe as primeiras 5 linhas do DataFrame\n",
        "print(final_merged_df_new.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dkQSeXGxUZ2",
        "outputId": "69107c1e-ff66-411e-db56-e7a3dfee8641"
      },
      "outputs": [],
      "source": [
        "# Limpeza dos dados nas três tabelas que vou utilizar\n",
        "\n",
        "# Função para remover colunas com mais de 80% de valores ausentes\n",
        "def clean_data(df, threshold=0.8):\n",
        "    # Remove colunas com valores nulos acima do threshold especificado\n",
        "    df_cleaned = df.dropna(thresh=df.shape[0] * (1 - threshold), axis=1)\n",
        "    return df_cleaned\n",
        "\n",
        "# Aplicando a limpeza nas três tabelas, removendo colunas com mais de 80% de valores ausentes\n",
        "matches_df_cleaned = clean_data(matches_df_new, threshold=0.8)\n",
        "teams2_df_cleaned = clean_data(teams2_df_new, threshold=0.8)\n",
        "teams_df_cleaned = clean_data(teams_df_new, threshold=0.8)\n",
        "\n",
        "# Exibindo as primeiras linhas das tabelas após a limpeza para verificar a qualidade dos dados\n",
        "matches_df_cleaned.head(), teams2_df_cleaned.head(), teams_df_cleaned.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22dKHvusjQ5R"
      },
      "source": [
        "### Análise das Células:\n",
        "\n",
        "#### 1. **Junção das Tabelas de Times e Partidas (Novamente)**:\n",
        "- **Objetivo**: Repetir o processo de junção das tabelas de times e partidas, mas agora utilizando uma versão nova dos dados de times, corrigida ou atualizada.\n",
        "\n",
        "- **Passos Realizados**:\n",
        "  1. **Carregamento das Tabelas de Times**: Foram recarregadas as tabelas `teams_df_new` e `teams2_df_new` que contêm informações dos times (casa e visitante).\n",
        "  2. **Limpeza dos Dados de Times**: Aplicou-se a função de limpeza `clean_data` para remover colunas com valores nulos acima de um certo threshold (80%). Isso ajuda a reduzir o volume de colunas com muitos valores ausentes, aumentando a qualidade dos dados.\n",
        "  3. **Junção das Tabelas**:\n",
        "     - Primeiramente, fez-se o **merge** da tabela de partidas com a tabela de times da casa, utilizando a chave `home_team_name`.\n",
        "     - Em seguida, realizou-se a mesma operação para a tabela de times visitantes, usando a chave `away_team_name`.\n",
        "  4. **Resultado**: Um DataFrame contendo informações das partidas e dos times, com 793 colunas após a junção.\n",
        "\n",
        "#### 2. **Limpeza das Colunas com Muitos Valores Ausentes**:\n",
        "- **Objetivo**: Garantir que as colunas com muitos valores ausentes (acima de 80%) sejam removidas para evitar que essas colunas prejudiquem a análise e a modelagem.\n",
        "\n",
        "- **Passos Realizados**:\n",
        "  1. **Definição da Função de Limpeza**: A função `clean_data` foi implementada para remover colunas com mais de 80% de valores ausentes.\n",
        "  2. **Aplicação da Função nas Três Tabelas**: A função foi aplicada nas tabelas de partidas e nas tabelas de times (`matches_df_cleaned`, `teams_df_cleaned`, `teams2_df_cleaned`).\n",
        "  3. **Exibição dos Dados Limpos**:\n",
        "     - A visualização do DataFrame limpo mostra que o número de colunas foi reduzido significativamente (de 793 para 53), com os valores ausentes sendo removidos, o que indica uma limpeza eficiente dos dados.\n",
        "\n",
        "### Pontos Importantes:\n",
        "- **Limpeza Eficiente**: Ao remover colunas com muitos valores ausentes, a análise fica mais robusta e menos suscetível a ruídos e inconsistências nos dados.\n",
        "- **Consistência dos Dados**: A junção de dados de times da casa e visitantes foi realizada com sucesso, e os dados limpos estão prontos para uma análise mais detalhada.\n",
        "- **Próximos Passos**:\n",
        "  - Analisar a qualidade e a relevância das colunas restantes, após a limpeza, para identificar as melhores variáveis preditoras.\n",
        "  - Continuar o processo de feature engineering e seleção de variáveis, utilizando métodos como correlação e análise de importância de features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO4JnnqJxUdI",
        "outputId": "9916a0cb-290f-4857-ee44-a9b5cefaef4e"
      },
      "outputs": [],
      "source": [
        "# Remover colunas irrelevantes como timestamp, date_GMT, referee, e outras que não contribuem para a predição\n",
        "columns_to_drop = ['timestamp', 'date_GMT', 'referee', 'stadium_name', 'attendance']\n",
        "\n",
        "# Removendo essas colunas das três tabelas principais\n",
        "matches_df_cleaned = matches_df_cleaned.drop(columns=columns_to_drop, errors='ignore')\n",
        "teams2_df_cleaned = teams2_df_cleaned.drop(columns=columns_to_drop, errors='ignore')\n",
        "teams_df_cleaned = teams_df_cleaned.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Exibir as primeiras linhas dos DataFrames após a limpeza\n",
        "matches_df_cleaned.head(), teams2_df_cleaned.head(), teams_df_cleaned.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "OqWIMMhv1jRb",
        "outputId": "78500af3-d429-4e19-9410-cf6b48c486f4"
      },
      "outputs": [],
      "source": [
        "# Dropando colunas categóricas para manter apenas as numéricas\n",
        "matches_df_numeric = matches_df_cleaned.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Exibindo as primeiras linhas do DataFrame apenas com colunas numéricas\n",
        "matches_df_numeric.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQD2n8V3xUfk",
        "outputId": "5c49a983-9c60-4d77-ee10-baa168f2bd91"
      },
      "outputs": [],
      "source": [
        "# Calculando a correlação das features com os gols marcados pelo time da casa e pelo time visitante\n",
        "correlation_matrix = matches_df_numeric.corr()\n",
        "\n",
        "# Selecionando as correlações mais altas com as variáveis alvo: 'home_team_goal_count' e 'away_team_goal_count'\n",
        "home_goals_corr = correlation_matrix['home_team_goal_count'].sort_values(ascending=False)\n",
        "away_goals_corr = correlation_matrix['away_team_goal_count'].sort_values(ascending=False)\n",
        "\n",
        "# Exibir as 10 maiores correlações para os gols da equipe da casa e da equipe visitante\n",
        "home_goals_corr.head(10), away_goals_corr.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC1swPgTj2vB"
      },
      "source": [
        "### Análise das Células:\n",
        "\n",
        "#### 1. **Remoção de Colunas Irrelevantes**:\n",
        "- **Objetivo**: Remover colunas que não são necessárias para a predição, como timestamp, GMT, nome do estádio, e outras que não influenciam diretamente no placar do jogo.\n",
        "- **Passos**:\n",
        "  1. Foi criada uma lista de colunas a serem removidas: `['timestamp', 'date_GMT', 'referee', 'stadium_name', 'attendance']`.\n",
        "  2. As colunas foram removidas dos três DataFrames principais (partidas, times da casa e times visitantes) usando a função `.drop()`.\n",
        "  3. O DataFrame resultante tem 50 colunas restantes, com as primeiras linhas exibidas para verificação.\n",
        "\n",
        "#### 2. **Manutenção Apenas das Colunas Numéricas**:\n",
        "- **Objetivo**: Focar apenas em colunas numéricas, removendo as categóricas que não serão utilizadas nos modelos preditivos.\n",
        "- **Passos**:\n",
        "  1. A função `.select_dtypes()` foi usada para filtrar apenas as colunas com tipos `float64` e `int64`, mantendo apenas as colunas numéricas.\n",
        "  2. O DataFrame resultante tem 47 colunas numéricas, como `home_team_goal_count`, `total_goal_count`, e `Pre-Match PPG`.\n",
        "\n",
        "#### 3. **Cálculo da Correlação das Features com os Gols**:\n",
        "- **Objetivo**: Entender quais features têm maior correlação com os gols marcados pelos times da casa e visitante, facilitando a seleção de features importantes para os modelos.\n",
        "- **Passos**:\n",
        "  1. Usando a função `.corr()`, foi calculada a matriz de correlação entre todas as variáveis numéricas do DataFrame.\n",
        "  2. Foram selecionadas as correlações mais altas com as variáveis-alvo, `home_team_goal_count` e `away_team_goal_count`.\n",
        "  3. As 10 maiores correlações foram exibidas, destacando variáveis como `home_team_goal_count_half_time`, `home_team_shots_on_target`, `total_goal_count`, e outras que estão fortemente associadas aos gols.\n",
        "\n",
        "### Pontos Importantes:\n",
        "- **Remoção de Colunas Irrelevantes**: A remoção de colunas como `timestamp` e `referee` é essencial, pois essas variáveis não influenciam diretamente a predição do número de gols, e mantê-las poderia adicionar ruído ao modelo.\n",
        "- **Filtro de Colunas Numéricas**: Reduzir o foco apenas para variáveis numéricas simplifica o processo de modelagem, já que os modelos como Lasso e Random Forest trabalham melhor com dados numéricos diretamente.\n",
        "- **Correlação e Seleção de Features**: Analisar as variáveis mais correlacionadas com os gols ajuda a escolher as features mais relevantes, permitindo construir modelos mais eficientes e focados nas variáveis que realmente impactam o placar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4rPrhE8mxUhz",
        "outputId": "88f911fd-110e-4187-839b-269bbb513153"
      },
      "outputs": [],
      "source": [
        "# Visualizando a matriz de correlação das colunas numéricas\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Definindo o tamanho da figura para melhor visualização\n",
        "plt.figure(figsize=(14,10))\n",
        "\n",
        "# Criando um heatmap da matriz de correlação\n",
        "sns.heatmap(matches_df_numeric.corr(), annot=False, cmap='coolwarm', linewidths=0.5)\n",
        "\n",
        "# Exibir o gráfico\n",
        "plt.title(\"Matriz de Correlação das Features Numéricas\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jBpE1iLT2jFb",
        "outputId": "ceca3885-f749-4a0b-e9b7-4dbe2e4b6552"
      },
      "outputs": [],
      "source": [
        "# Importando as bibliotecas necessárias para as visualizações dos graficos\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Features que mais se correlacionam com os gols da casa e visitante uma vez que queremos encontrar o placar final\n",
        "features_to_plot = [\n",
        "    'home_team_goal_count', 'away_team_goal_count', 'home_team_shots_on_target',\n",
        "    'away_team_shots_on_target', 'team_a_xg', 'team_b_xg'\n",
        "]\n",
        "\n",
        "# Histograma para visualizar a distribuição de gols do time da casa e do visitante\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(matches_df_numeric['home_team_goal_count'], kde=True, color='blue')\n",
        "plt.title('Distribuição de Gols do Time da Casa')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(matches_df_numeric['away_team_goal_count'], kde=True, color='green')\n",
        "plt.title('Distribuição de Gols do Time Visitante')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Boxplot para verificar outliers nas variáveis de chutes no alvo e xG(expected goals)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(data=matches_df_numeric, x='home_team_shots_on_target', color='blue')\n",
        "plt.title('Boxplot de Chutes no Alvo do Time da Casa')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(data=matches_df_numeric, x='away_team_shots_on_target', color='green')\n",
        "plt.title('Boxplot de Chutes no Alvo do Time Visitante')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Scatter Plot para analisar a relação entre chutes no alvo e xG (expected goals)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(data=matches_df_numeric, x='home_team_shots_on_target', y='team_a_xg', color='blue')\n",
        "plt.title('Chutes no Alvo vs Expected Goals (Time da Casa)')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.scatterplot(data=matches_df_numeric, x='away_team_shots_on_target', y='team_b_xg', color='green')\n",
        "plt.title('Chutes no Alvo vs Expected Goals (Time Visitante)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeIzH0skkN-U"
      },
      "source": [
        "\n",
        "\n",
        "### **Matriz de Correlação das Features Numéricas**\n",
        "\n",
        "- **O que é?**: Essa célula utiliza uma *heatmap* para mostrar a correlação entre as variáveis numéricas do dataset, calculando o coeficiente de correlação entre cada par de variáveis.\n",
        "  \n",
        "- **Como agrega à análise?**:\n",
        "  - A matriz de correlação nos permite identificar quais variáveis têm uma relação mais forte com o número de gols marcados, tanto para o time da casa quanto para o time visitante.\n",
        "  - Na matriz, vemos que o *home_team_goal_count* e o *away_team_goal_count* estão altamente correlacionados com o número total de gols e outras variáveis relacionadas, como *shots on target* e *xG*.\n",
        "  - Essas informações são cruciais para selecionar as melhores variáveis a serem utilizadas em modelos preditivos, descartando aquelas que não têm uma relação forte com o resultado final (gols).\n",
        "\n",
        "### **Visualizações Gráficas das Features Selecionadas**\n",
        "\n",
        "- **O que é?**: Essa célula contém uma série de gráficos, como histogramas, boxplots e scatter plots, que visualizam a distribuição dos gols e a relação entre as variáveis mais importantes para a previsão (como *shots on target* e *xG*).\n",
        "\n",
        "- **Como agrega à análise?**:\n",
        "  - Os **histogramas** mostram a distribuição dos gols marcados pelos times da casa e visitante. Esses gráficos nos ajudam a entender o padrão de distribuição dos dados (se há mais partidas com 0 gols, por exemplo) e possíveis outliers.\n",
        "  - Os **boxplots** comparam a distribuição das variáveis de chutes no alvo (*shots on target*) e *xG* para identificar padrões de comportamento. Eles nos ajudam a verificar a presença de outliers e o comportamento geral das variáveis em relação ao número de gols.\n",
        "  - Os **scatter plots** mostram a relação direta entre chutes no alvo e os expected goals (xG). Aqui, podemos visualizar se há uma relação clara entre o número de chutes e a expectativa de gols, que é um indicativo importante para a performance das equipes e a previsão de placares.\n",
        "\n",
        "### Conclusão:\n",
        "- A matriz de correlação permite identificar as variáveis mais relevantes para o modelo de previsão de gols.\n",
        "- As visualizações gráficas detalhadas ajudam a entender o comportamento dessas variáveis e sua relação com o resultado final, servindo de base para melhorar a performance dos modelos preditivos ao ajustar as features e remover outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0b57N4YlDrm"
      },
      "source": [
        "\n",
        "\n",
        "### Introdução aos Modelos e Abordagens\n",
        "Neste projeto, utilizamos diferentes abordagens de **machine learning** para prever o placar final de partidas de futebol, com base em dados históricos de equipes e características das partidas. Os principais modelos testados incluem algoritmos de regressão como o **Lasso**, além de modelos baseados em árvores como o **Random Forest**. Cada modelo foi selecionado com base em suas características para lidar com os desafios do problema, como a **multicolinearidade** entre as features e o risco de **overfitting** em um conjunto de dados relativamente pequeno.\n",
        "\n",
        "#### Modelos Utilizados:\n",
        "1. **Lasso Regression**:\n",
        "   - O **Lasso (Least Absolute Shrinkage and Selection Operator)** é um modelo de regressão linear que aplica uma penalização às features menos relevantes, forçando seus coeficientes a se aproximarem de zero. Ele é útil para selecionar variáveis e prevenir o overfitting, especialmente em cenários com muitas variáveis correlacionadas.\n",
        "\n",
        "2. **Random Forest**:\n",
        "   - O **Random Forest** é um algoritmo baseado em árvores de decisão, que constrói múltiplas árvores de decisão aleatórias e usa a média para fazer previsões. Ele é robusto a outliers e menos propenso ao overfitting, sendo uma boa escolha para cenários com muitas variáveis.\n",
        "\n",
        "3. **GridSearchCV**:\n",
        "   - Foi utilizado para encontrar os melhores hiperparâmetros tanto no **Lasso** quanto no **Random Forest**, visando otimizar o desempenho dos modelos.\n",
        "\n",
        "### Avaliações dos Modelos e Métricas\n",
        "Cada modelo foi avaliado utilizando métricas comuns para problemas de regressão, como:\n",
        "- **Mean Squared Error (MSE)**: Mede o erro quadrado médio entre as previsões e os valores reais.\n",
        "- **R² Score**: Indica a proporção da variabilidade dos dados que o modelo é capaz de explicar.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_5-3XAC2jMr",
        "outputId": "2112881c-c2d0-437a-db69-45889020cb05"
      },
      "outputs": [],
      "source": [
        "# Importando RandomForest e bibliotecas necessárias para dividir os dados e avaliar metricas do modelo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Separando as features (X) e a variável alvo (y) - Usando total de gols como alvo (home_team_goal_count + away_team_goal_count)\n",
        "X = matches_df_numeric.drop(columns=['home_team_goal_count', 'away_team_goal_count', 'total_goal_count'])\n",
        "y = matches_df_numeric['total_goal_count']\n",
        "\n",
        "# Dividindo os dados em conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criando o modelo RandomForest\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Treinando o modelo\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_train = rf_model.predict(X_train)\n",
        "y_pred_test = rf_model.predict(X_test)\n",
        "\n",
        "# Avaliando o modelo\n",
        "train_mse = mean_squared_error(y_train, y_pred_train)\n",
        "test_mse = mean_squared_error(y_test, y_pred_test)\n",
        "train_r2 = r2_score(y_train, y_pred_train)\n",
        "test_r2 = r2_score(y_test, y_pred_test)\n",
        "\n",
        "train_mse, test_mse, test_r2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9g9OOQ12jRf",
        "outputId": "7aa89538-2d41-4dac-8da5-991cdbe5e876"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definindo o grid de hiperparâmetros\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Criando o modelo RandomForest\n",
        "rf_model_grid = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Configurando o GridSearchCV para otimização\n",
        "grid_search = GridSearchCV(estimator=rf_model_grid, param_grid=param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
        "\n",
        "# Treinando o modelo com busca de hiperparâmetros\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtendo os melhores hiperparâmetros\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Fazendo previsões com o melhor modelo\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_pred_test_optimized = best_rf_model.predict(X_test)\n",
        "\n",
        "# Avaliação do modelo otimizado\n",
        "test_mse_optimized = mean_squared_error(y_test, y_pred_test_optimized)\n",
        "test_r2_optimized = r2_score(y_test, y_pred_test_optimized)\n",
        "\n",
        "best_params, test_mse_optimized, test_r2_optimized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r92Kgo4r2jWL",
        "outputId": "c956992a-13c5-405f-f63d-7d000bf6d812"
      },
      "outputs": [],
      "source": [
        "# Recarregar os dados e fazer a divisão de treino e teste\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separando as features (X) e a variável alvo (y) - Usando total de gols como alvo\n",
        "X = matches_df_numeric.drop(columns=['home_team_goal_count', 'away_team_goal_count', 'total_goal_count'])\n",
        "y = matches_df_numeric['total_goal_count']\n",
        "\n",
        "# Dividindo os dados em conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Continuando com a otimização do modelo\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtendo os melhores hiperparâmetros\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Fazendo previsões com o melhor modelo\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_pred_test_optimized = best_rf_model.predict(X_test)\n",
        "\n",
        "# Avaliação do modelo otimizado\n",
        "test_mse_optimized = mean_squared_error(y_test, y_pred_test_optimized)\n",
        "test_r2_optimized = r2_score(y_test, y_pred_test_optimized)\n",
        "\n",
        "best_params, test_mse_optimized, test_r2_optimized\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfMaizgZkqMw"
      },
      "source": [
        "A partir desse ponto, vamos continuar o treinamento dos modelos e explicar as abordagens utilizadas, além de discutir os próximos passos com base nos resultados que obtivemos até aqui.\n",
        "\n",
        "### Introdução ao Treinamento de Modelos\n",
        "\n",
        "Nesta etapa, começamos a explorar modelos de Machine Learning para prever o número de gols de uma partida, baseando-se em variáveis numéricas relacionadas ao desempenho pré-jogo, como xG (*expected goals*), chutes no alvo e outros indicadores relevantes.\n",
        "\n",
        "O **Random Forest** foi um dos primeiros modelos que utilizamos. Este algoritmo é conhecido por sua capacidade de lidar com dados complexos e seu bom desempenho em diferentes contextos de previsão. No entanto, ele pode ser suscetível ao *overfitting* se não for devidamente otimizado.\n",
        "\n",
        "### Avaliação do Modelo Random Forest\n",
        "1. **Métricas Iniciais**:\n",
        "   - MSE (Erro Médio Quadrático) no conjunto de treino: `0.0440703947368421`\n",
        "   - MSE no conjunto de teste: `0.5830313157894736`\n",
        "   - R² (Coeficiente de Determinação) no conjunto de treino: `0.9716786415125829`\n",
        "   - R² no conjunto de teste: `0.68846716376223`\n",
        "\n",
        "   **Interpretação**:\n",
        "   - O modelo apresentou um bom desempenho no conjunto de treino, mas o desempenho caiu um pouco no conjunto de teste, sugerindo que o modelo pode estar superajustado (*overfitting*) aos dados de treino.\n",
        "\n",
        "### Otimização com GridSearchCV\n",
        "\n",
        "Para mitigar o problema de *overfitting*, utilizamos a técnica de **Grid Search** para otimizar os hiperparâmetros do Random Forest, incluindo:\n",
        "- `n_estimators`: Número de árvores na floresta.\n",
        "- `max_depth`: Profundidade máxima das árvores.\n",
        "- `min_samples_split`: Número mínimo de amostras para dividir um nó.\n",
        "\n",
        "Após a otimização, obtivemos os seguintes melhores hiperparâmetros:\n",
        "- `n_estimators`: 200\n",
        "- `min_samples_split`: 2\n",
        "- `max_depth`: None\n",
        "\n",
        "**Métricas após a otimização**:\n",
        "- MSE no conjunto de teste otimizado: `0.546477396485179`\n",
        "- R² no conjunto de teste otimizado: `0.706039924668923`\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "Apesar da melhoria significativa após a otimização, o modelo Random Forest ainda apresenta limitações em termos de precisão no conjunto de teste. Isso pode ser explicado pela quantidade limitada de dados, o que afeta a capacidade de generalização do modelo.\n",
        "\n",
        "Os próximos passos são:\n",
        "1. **Explorar outros modelos**: Além do Random Forest, podemos testar abordagens como Lasso ou Gradient Boosting para verificar se algum deles traz melhorias adicionais.\n",
        "2. **Regularização de Features**: Testar a aplicação de técnicas de regularização, como Lasso e Ridge, pode ajudar a reduzir a complexidade do modelo e melhorar o desempenho em cenários de menor quantidade de dados.\n",
        "3. **Aprimorar o Dataset**: Tentar aumentar a quantidade de dados (se disponível) ou aplicar técnicas de *data augmentation* para melhorar a capacidade de generalização dos modelos treinados.\n",
        "\n",
        "Esses próximos passos visam aumentar a precisão das previsões de placar final e mitigar os efeitos do *overfitting* observados até agora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "foLms3m-2jaK",
        "outputId": "b84d9d1d-1469-4249-a9a7-fc96219cfe19"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Criando o modelo RandomForest otimizado\n",
        "best_rf_model = RandomForestRegressor(n_estimators=200, max_depth=None, min_samples_split=2, random_state=42)\n",
        "\n",
        "# Treinando o modelo novamente\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Obtendo a importância das features\n",
        "feature_importances = pd.Series(best_rf_model.feature_importances_, index=X.columns)\n",
        "\n",
        "# Ordenar por importância\n",
        "sorted_importances = feature_importances.sort_values(ascending=False)\n",
        "\n",
        "# Plotando as 10 features mais importantes\n",
        "plt.figure(figsize=(10, 6))\n",
        "sorted_importances.head(10).plot(kind='barh', color='skyblue')\n",
        "plt.title('Top 10 Features mais Importantes no Modelo Random Forest')\n",
        "plt.xlabel('Importância da Feature')\n",
        "plt.ylabel('Features')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwX4MUveBfVv",
        "outputId": "6530f5ad-d3cf-48b3-8c48-1fad6040d343"
      },
      "outputs": [],
      "source": [
        "# Usando as top 10 features mais importantes\n",
        "important_features = sorted_importances.head(10).index.tolist()\n",
        "\n",
        "# Criando um novo conjunto de dados com apenas as top features selecionadas\n",
        "X_refined = X[important_features]\n",
        "\n",
        "# Dividindo os dados em conjunto de treino e teste com as features refinadas\n",
        "X_train_refined, X_test_refined, y_train_refined, y_test_refined = train_test_split(X_refined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinando o modelo RandomForest com as features refinadas\n",
        "best_rf_model.fit(X_train_refined, y_train_refined)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_train_refined = best_rf_model.predict(X_train_refined)\n",
        "y_pred_test_refined = best_rf_model.predict(X_test_refined)\n",
        "\n",
        "# Avaliando o modelo com as features refinadas\n",
        "train_mse_refined = mean_squared_error(y_train_refined, y_pred_train_refined)\n",
        "test_mse_refined = mean_squared_error(y_test_refined, y_pred_test_refined)\n",
        "train_r2_refined = r2_score(y_train_refined, y_pred_train_refined)\n",
        "test_r2_refined = r2_score(y_test_refined, y_pred_test_refined)\n",
        "\n",
        "print(train_mse_refined, test_mse_refined, train_r2_refined, test_r2_refined)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYDvWYb-mTXd"
      },
      "source": [
        "**Random Forest**:\n",
        "\n",
        "### 1. Importância das Features no Random Forest:\n",
        "Primeiramente, o modelo **Random Forest** foi treinado com todas as features e, em seguida, analisamos as **10 principais variáveis mais importantes** que contribuíram para as previsões. A importância das variáveis foi visualizada em um gráfico de barras, com as features como **\"home_team_goal_count_half_time\"** e **\"away_team_fouls\"** sendo destacadas como as mais relevantes para prever o placar.\n",
        "\n",
        "A importância dessas features nos ajuda a identificar quais características têm mais impacto na previsão do resultado de uma partida. Com isso, podemos selecionar as features mais relevantes e criar um modelo mais eficiente, removendo o ruído gerado por variáveis menos importantes.\n",
        "\n",
        "### 2. Refinamento e Otimização do Random Forest:\n",
        "Com base nas **top 10 features mais importantes**, criamos um novo conjunto de dados refinado, contendo apenas essas features, e treinamos novamente o modelo **Random Forest**.\n",
        "\n",
        "#### Resultados do Modelo Refinado:\n",
        "- O **MSE** e o **R²** do modelo refinado foram avaliados tanto no conjunto de treino quanto no conjunto de teste, apresentando valores como:\n",
        "  - **MSE no treino**: 0.0368\n",
        "  - **MSE no teste**: 0.4891\n",
        "  - **R² no treino**: 0.8720\n",
        "  - **R² no teste**: 0.7356\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boSCMo3SBfjr",
        "outputId": "c7f60008-7c36-4063-c2e3-5c2f08898759"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definindo o grid de hiperparâmetros para regularizar o modelo\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [5, 10, 15, None],  # Limitar a profundidade\n",
        "    'min_samples_split': [2, 5, 10],  # Maior número mínimo de amostras para divisão\n",
        "    'max_features': ['auto', 'sqrt', 'log2']  # Ajustar o número de features consideradas por divisão\n",
        "}\n",
        "\n",
        "# Criando o modelo RandomForest\n",
        "rf_model_grid = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Configurando o GridSearchCV para otimização\n",
        "grid_search = GridSearchCV(estimator=rf_model_grid, param_grid=param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
        "\n",
        "# Treinando o modelo com busca de hiperparâmetros\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtendo os melhores hiperparâmetros\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Fazendo previsões com o melhor modelo\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_pred_test_optimized = best_rf_model.predict(X_test)\n",
        "\n",
        "# Avaliação do modelo otimizado\n",
        "test_mse_optimized = mean_squared_error(y_test, y_pred_test_optimized)\n",
        "test_r2_optimized = r2_score(y_test, y_pred_test_optimized)\n",
        "\n",
        "best_params, test_mse_optimized, test_r2_optimized\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUmFLldJl0zw"
      },
      "source": [
        "\n",
        "\n",
        "### GridSearchCV:\n",
        "Após o refinamento inicial, aplicamos o **GridSearchCV** para realizar uma busca pelos melhores hiperparâmetros do modelo. O **GridSearch** testou diferentes combinações de parâmetros como a profundidade máxima das árvores (**max_depth**), o número de árvores (**n_estimators**) e o número mínimo de amostras para dividir um nó (**min_samples_split**). Isso foi feito para encontrar a configuração que melhor otimiza o desempenho do **Random Forest**.\n",
        "\n",
        "O modelo otimizado resultou nos seguintes melhores hiperparâmetros:\n",
        "- **n_estimators**: 200\n",
        "- **max_depth**: None\n",
        "- **min_samples_split**: 2\n",
        "\n",
        "Essas mudanças permitiram uma melhora significativa no **R²** do conjunto de teste.\n",
        "\n",
        "#### Conclusão:\n",
        "Este processo de otimização e refinamento demonstrou como podemos usar tanto a análise das features quanto a otimização de hiperparâmetros para melhorar a performance de um modelo de **Random Forest**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW2IMqqUmxqb"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Introdução ao Lasso\n",
        "\n",
        "O **Lasso** (Least Absolute Shrinkage and Selection Operator) é um método de **regressão linear regularizada** que aplica uma penalização na soma dos valores absolutos dos coeficientes do modelo. Ele é particularmente útil em cenários onde há muitas variáveis, pois tem a capacidade de realizar **seleção de variáveis** ao \"forçar\" coeficientes irrelevantes a se aproximarem de zero, o que simplifica o modelo e reduz o overfitting.\n",
        "\n",
        "### Por que Utilizamos o Lasso?\n",
        "\n",
        "Optamos por utilizar o **Lasso** neste projeto devido às seguintes razões:\n",
        "- **Overfitting**: No nosso problema de previsão de placares, enfrentamos um cenário onde algumas features podem estar correlacionadas com o ruído ou são redundantes. O Lasso nos ajuda a reduzir o overfitting ao penalizar coeficientes grandes e manter o modelo mais simples.\n",
        "- **Seleção de Variáveis**: Como temos várias variáveis (features) que podem ou não ser relevantes para a previsão dos gols, o Lasso também nos ajuda a selecionar automaticamente as mais importantes, ignorando as que têm menos impacto no resultado final.\n",
        "- **Robustez em Pequenos Conjuntos de Dados**: O Lasso é eficaz em situações de conjuntos de dados relativamente pequenos, como o nosso, onde temos que garantir que o modelo não se ajuste demais aos dados de treino, mantendo um bom desempenho nos dados de teste.\n",
        "\n",
        "### Como Funciona o Lasso?\n",
        "\n",
        "O Lasso ajusta o modelo de regressão linear adicionando uma penalização ao erro quadrático da função de custo. A penalização está associada à soma dos valores absolutos dos coeficientes do modelo:\n",
        "\n",
        "$$\n",
        "\\text{Função de Custo do Lasso} = \\frac{1}{2n} \\sum_{i=1}^{n} \\left( y_i - \\hat{y}_i \\right)^2 + \\alpha \\sum_{j=1}^{p} |w_j|\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- $y_i$ são os valores reais.\n",
        "- $\\hat{y}_i$ são os valores previstos.\n",
        "- $\\alpha$ é o parâmetro de regularização que controla a força da penalização.\n",
        "- $w_j$ são os coeficientes do modelo.\n",
        "\n",
        "Quanto maior o valor de **$\\alpha$**, maior será a penalização aplicada aos coeficientes, o que resultará em coeficientes menores ou até mesmo zero para algumas features. Isso ajuda na seleção das variáveis mais importantes e também controla o overfitting.\n",
        "\n",
        "### Aplicação do GridSearch para Otimizar o Lasso\n",
        "\n",
        "Embora o Lasso ofereça vantagens com sua regularização, a escolha do valor de **$\\alpha$** é crítica para alcançar um bom equilíbrio entre bias e variância. O **GridSearchCV** é uma técnica de busca sistemática que nos ajuda a encontrar os melhores hiperparâmetros, como o valor ideal de **$\\alpha$**.\n",
        "\n",
        "O **GridSearch** testa várias combinações de hiperparâmetros (neste caso, diferentes valores de **$\\alpha$**) e seleciona o conjunto que oferece a melhor performance com base em uma métrica de avaliação, como o **Mean Squared Error (MSE)** ou o **$R^2$**. Isso nos permite explorar diferentes configurações sem precisar testar manualmente cada valor possível.\n",
        "\n",
        "#### Resumo dos Benefícios do GridSearch no Lasso:\n",
        "- **Exploração Automatizada**: Em vez de escolhermos manualmente o valor de **$\\alpha$**, o GridSearch faz uma exploração abrangente de possíveis valores.\n",
        "- **Validação Cruzada**: O GridSearch usa validação cruzada para testar os diferentes valores de **$\\alpha$**, garantindo que a avaliação seja mais robusta e menos propensa a variabilidade dos dados de treino e teste.\n",
        "- **Melhoria da Performance**: Encontrar o melhor valor de **$\\alpha$** maximiza a performance do modelo, tanto em termos de ajuste (reduzindo o overfitting) quanto em termos de generalização para novos dados.\n",
        "\n",
        "### Conclusão\n",
        "\n",
        "Escolhemos o **Lasso** pela sua capacidade de regularizar o modelo e selecionar variáveis, o que é importante no nosso problema, onde há muitas features que podem ou não ser relevantes. Combinado com o **GridSearchCV**, conseguimos ajustar o hiperparâmetro **$\\alpha$** de forma eficiente, garantindo um modelo otimizado, que evita overfitting e tem uma melhor capacidade de previsão.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5k_IPN6Bfmp",
        "outputId": "758676ef-b48b-4006-bbad-fee8604a13ca"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Definir o grid de hiperparâmetros para o Lasso\n",
        "param_grid = {\n",
        "    'alpha': [0.035, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Criando o modelo Lasso\n",
        "lasso_model = Lasso(max_iter=10000, random_state=42)\n",
        "\n",
        "# Configurando o GridSearchCV para otimização\n",
        "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
        "\n",
        "# Treinando o modelo com busca de hiperparâmetros\n",
        "grid_search.fit(X_train_refined, y_train_refined)\n",
        "\n",
        "# Obtendo os melhores hiperparâmetros\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Fazendo previsões com o melhor modelo\n",
        "best_lasso_model = grid_search.best_estimator_\n",
        "y_pred_test_lasso = best_lasso_model.predict(X_test_refined)\n",
        "\n",
        "# Avaliação do modelo otimizado\n",
        "test_mse_lasso = mean_squared_error(y_test, y_pred_test_lasso)\n",
        "test_r2_lasso = r2_score(y_test, y_pred_test_lasso)\n",
        "\n",
        "best_params, test_mse_lasso, test_r2_lasso\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDcWkykXMeC6",
        "outputId": "b224f192-13c0-4176-e18d-51b9ffb6fc5a"
      },
      "outputs": [],
      "source": [
        "#Testando Abordagem de Stacking\n",
        "\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import Lasso\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Criando os modelos base\n",
        "lasso_model = Lasso(alpha=0.045, max_iter=10000, random_state=42)\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
        "\n",
        "# Criando o modelo meta (neste caso, Random Forest)\n",
        "meta_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Configurando o Stacking\n",
        "stacking_model = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('lasso', lasso_model),\n",
        "        ('xgboost', xgb_model),\n",
        "        ('lightgbm', lgb_model)\n",
        "    ],\n",
        "    final_estimator=meta_model\n",
        ")\n",
        "\n",
        "# Treinando o modelo de stacking\n",
        "stacking_model.fit(X_train_refined, y_train_refined)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_test_stacking = stacking_model.predict(X_test_refined)\n",
        "\n",
        "# Avaliando o modelo de stacking\n",
        "test_mse_stacking = mean_squared_error(y_test_refined, y_pred_test_stacking)\n",
        "test_r2_stacking = r2_score(y_test_refined, y_pred_test_stacking)\n",
        "\n",
        "print(\"Stacking Model - MSE:\", test_mse_stacking, \"R²:\", test_r2_stacking)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUefaymoocoD"
      },
      "source": [
        "\n",
        "\n",
        "### Introdução ao Lasso com GridSearch\n",
        "\n",
        "Nesta primeira célula, estamos utilizando o **Lasso** para realizar a regressão regularizada, combinando-o com o **GridSearchCV** para encontrar o melhor valor para o hiperparâmetro **alpha**. O Lasso é ideal quando queremos selecionar as variáveis mais importantes e controlar o overfitting, como já discutido anteriormente.\n",
        "\n",
        "1. **Definição do Grid**: O GridSearch está testando diferentes valores de **alpha** em um intervalo que vai de 0.035 a 10.\n",
        "2. **Melhores Parâmetros**: Após treinar o modelo com diferentes valores de **alpha**, o GridSearchCV escolhe **alpha = 0.035** como o melhor valor para o problema em questão, apresentando um **MSE** de **0.37468719906131465** e um **\\(R^2\\)** de **0.794746466068081**.\n",
        "\n",
        "Este resultado mostra que o **Lasso** foi bem-sucedido em encontrar um modelo adequado para o problema de previsão de gols, selecionando as variáveis mais relevantes e otimizando o modelo.\n",
        "\n",
        "### Testando Abordagem de Stacking\n",
        "\n",
        "Nesta célula, estamos implementando uma abordagem de **Stacking Regressor**, que combina a predição de diferentes modelos de base (como **Lasso**, **XGBoost**, e **LightGBM**) e utiliza um meta-modelo (no caso, **RandomForestRegressor**) para fazer a predição final. A ideia por trás do stacking é combinar as forças de diferentes algoritmos para melhorar a performance geral.\n",
        "\n",
        "1. **Modelos de Base**:\n",
        "   - **Lasso** com **alpha = 0.045**: Um modelo de regularização para ajudar na seleção de features.\n",
        "   - **XGBoost**: Um modelo de boosting que é bom para capturar interações complexas.\n",
        "   - **LightGBM**: Um modelo leve e eficiente para grandes volumes de dados.\n",
        "\n",
        "2. **Meta-Modelo**: O **RandomForest** foi escolhido como o meta-modelo para combinar as predições dos modelos de base.\n",
        "\n",
        "3. **Problema Identificado**: Como vemos no output do **LightGBM**, houve um problema ao tentar realizar as previsões, onde o ganho da árvore não foi significativo (indicando algum problema na modelagem ou no ajuste dos hiperparâmetros para este modelo específico).\n",
        "\n",
        "### Próximos Passos:\n",
        "\n",
        "1. **Avaliar os Modelos**: Aparentemente, o **Stacking** não teve o desempenho esperado devido ao problema identificado com o LightGBM. É importante ajustar os hiperparâmetros do LightGBM e do Stacking como um todo para tentar melhorar a performance.\n",
        "\n",
        "2. **Rever a Configuração de Stacking**: Outra abordagem pode ser a de substituir o **LightGBM** por um modelo diferente ou ajustar os parâmetros de treinamento para que o modelo de stacking possa combinar melhor as predições de cada modelo de base.\n",
        "\n",
        "3. **Comparação Final**: Após ajustar o stacking, seria interessante comparar diretamente os resultados do **Lasso** puro, do **Random Forest** e do **Stacking** para verificar qual abordagem traz os melhores resultados no conjunto de teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox8He75GMeF0",
        "outputId": "d0fe8421-96d4-4562-87ad-199dcc02c3d3"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Criando o modelo Lasso com validação cruzada para otimizar alpha\n",
        "lasso_cv = LassoCV(alphas=[0.04, 0.045, 0.05], cv=5, max_iter=10000, random_state=42)\n",
        "\n",
        "# Treinando o modelo Lasso com cross-validation\n",
        "lasso_cv.fit(X_train_refined, y_train_refined)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_test_lasso_cv = lasso_cv.predict(X_test_refined)\n",
        "\n",
        "# Avaliando o modelo com cross-validation\n",
        "test_mse_lasso_cv = mean_squared_error(y_test_refined, y_pred_test_lasso_cv)\n",
        "test_r2_lasso_cv = r2_score(y_test_refined, y_pred_test_lasso_cv)\n",
        "\n",
        "# Melhor alpha encontrado\n",
        "best_alpha = lasso_cv.alpha_\n",
        "\n",
        "print(f\"Melhor Alpha: {best_alpha}\")\n",
        "print(\"Cross-Validation Lasso - MSE:\", test_mse_lasso_cv, \"R²:\", test_r2_lasso_cv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daLNup2jPF0i",
        "outputId": "92af7d27-fd17-431f-f7cd-cb1beb10b7be"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Criando o modelo Lasso com validação cruzada para ajustar o alpha\n",
        "lasso_cv = LassoCV(alphas=[0.035, 0.04, 0.045, 0.05, 0.055], cv=5, max_iter=10000, random_state=42)\n",
        "\n",
        "# Treinando o modelo Lasso com cross-validation\n",
        "lasso_cv.fit(X_train_refined, y_train_refined)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred_test_lasso_cv = lasso_cv.predict(X_test_refined)\n",
        "\n",
        "# Avaliando o modelo com cross-validation\n",
        "test_mse_lasso_cv = mean_squared_error(y_test_refined, y_pred_test_lasso_cv)\n",
        "test_r2_lasso_cv = r2_score(y_test_refined, y_pred_test_lasso_cv)\n",
        "\n",
        "# Melhor valor de alpha encontrado\n",
        "best_alpha = lasso_cv.alpha_\n",
        "\n",
        "print(f\"Melhor Alpha: {best_alpha}\")\n",
        "print(\"Cross-Validation Lasso - MSE:\", test_mse_lasso_cv, \"R²:\", test_r2_lasso_cv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ucxld1TPGBF",
        "outputId": "897bcd31-30d1-48c7-a08c-28dc7ac77b45"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Separando as features e a variável alvo (gols do time da casa)\n",
        "X_home = matches_df_numeric.drop(columns=['home_team_goal_count', 'away_team_goal_count', 'total_goal_count'])\n",
        "y_home = matches_df_numeric['home_team_goal_count']\n",
        "\n",
        "# Dividindo os dados em conjunto de treino e teste\n",
        "X_train_home, X_test_home, y_train_home, y_test_home = train_test_split(X_home, y_home, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criando o modelo Lasso para o time da casa\n",
        "lasso_home = Lasso(alpha=0.035, max_iter=10000, random_state=42)\n",
        "\n",
        "# Treinando o modelo\n",
        "lasso_home.fit(X_train_home, y_train_home)\n",
        "\n",
        "# Fazendo previsões para o time da casa\n",
        "y_pred_test_home = lasso_home.predict(X_test_home)\n",
        "\n",
        "# Avaliando o modelo\n",
        "test_mse_home = mean_squared_error(y_test_home, y_pred_test_home)\n",
        "test_r2_home = r2_score(y_test_home, y_pred_test_home)\n",
        "\n",
        "print(\"Home Team - MSE:\", test_mse_home, \"R²:\", test_r2_home)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM5T1gtPBful",
        "outputId": "73138183-6618-4b20-8a26-e945c9c107c6"
      },
      "outputs": [],
      "source": [
        "# Separando as features e a variável alvo (gols do time visitante)\n",
        "X_away = matches_df_numeric.drop(columns=['home_team_goal_count', 'away_team_goal_count', 'total_goal_count'])\n",
        "y_away = matches_df_numeric['away_team_goal_count']\n",
        "\n",
        "# Dividindo os dados em conjunto de treino e teste\n",
        "X_train_away, X_test_away, y_train_away, y_test_away = train_test_split(X_away, y_away, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criando o modelo Lasso para o time visitante\n",
        "lasso_away = Lasso(alpha=0.035, max_iter=10000, random_state=42)\n",
        "\n",
        "# Treinando o modelo\n",
        "lasso_away.fit(X_train_away, y_train_away)\n",
        "\n",
        "# Fazendo previsões para o time visitante\n",
        "y_pred_test_away = lasso_away.predict(X_test_away)\n",
        "\n",
        "# Avaliando o modelo\n",
        "test_mse_away = mean_squared_error(y_test_away, y_pred_test_away)\n",
        "test_r2_away = r2_score(y_test_away, y_pred_test_away)\n",
        "\n",
        "print(\"Away Team - MSE:\", test_mse_away, \"R²:\", test_r2_away)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apy1Sx0fo3Q0"
      },
      "source": [
        "Nestas células, estamos lidando com o modelo **Lasso** novamente, mas desta vez utilizando uma validação cruzada com o **LassoCV**. Isso nos permite encontrar automaticamente o melhor valor de **alpha** com base em diferentes valores testados durante a validação cruzada.\n",
        "\n",
        "---\n",
        "O **LassoCV** é uma variação do modelo de regressão Lasso que incorpora validação cruzada (cross-validation) no processo de ajuste do modelo. Ele automatiza a escolha do parâmetro de regularização **alpha**, que controla a intensidade da penalização aplicada aos coeficientes do modelo. Essa regularização é importante porque ajuda a combater o overfitting, forçando alguns coeficientes a zero e mantendo o modelo mais simples e eficiente.\n",
        "\n",
        "### Funcionamento do LassoCV:\n",
        "\n",
        "1. **Regularização Automática**: O LassoCV testa diferentes valores de **alpha** (o parâmetro de regularização), e escolhe aquele que oferece o melhor desempenho com base nos dados de validação cruzada.\n",
        "   \n",
        "2. **Validação Cruzada (Cross-Validation)**: O conjunto de dados é dividido em vários subconjuntos (folds), e em cada iteração, o modelo é treinado em alguns desses subconjuntos e testado nos demais. Esse processo garante que o modelo seja avaliado em diferentes partes dos dados, tornando sua avaliação mais robusta.\n",
        "\n",
        "3. **Penalização L1**: Assim como o Lasso, o LassoCV utiliza a penalização L1, que tende a \"forçar\" coeficientes irrelevantes a se tornarem zero, selecionando apenas as variáveis mais importantes para o modelo final.\n",
        "\n",
        "4. **Aplicabilidade**: O LassoCV é útil quando você quer automatizar a escolha do valor de **alpha**, evitando a necessidade de fazer testes manuais com diferentes valores e garantindo uma avaliação robusta do modelo com validação cruzada.\n",
        "\n",
        "Em resumo, o **LassoCV** facilita a escolha do hiperparâmetro **alpha** ideal para balancear a complexidade do modelo e garantir sua capacidade de generalização.\n",
        "\n",
        "### Primeira Célula: Validação Cruzada com LassoCV\n",
        "\n",
        "1. **Definição do Modelo**: O modelo **LassoCV** é criado com uma gama de valores para o hiperparâmetro **alpha**: [0.035, 0.04, 0.045, 0.05, 0.055]. Esses valores serão testados durante a validação cruzada para encontrar o valor ideal.\n",
        "   \n",
        "2. **Validação Cruzada (Cross-Validation)**: Ao configurar o **cv=5**, estamos dizendo ao modelo para realizar uma validação cruzada com 5 folds. Isso divide os dados em 5 partes, utilizando 4 para treino e 1 para validação em cada iteração, garantindo que o modelo seja avaliado de forma robusta em diferentes subconjuntos de dados.\n",
        "\n",
        "3. **Métricas de Avaliação**:\n",
        "   - O **MSE** da validação cruzada foi de 0.37321547794912545.\n",
        "   - O **\\(R^2\\)** foi de 0.7955525265175957.\n",
        "   - O melhor valor encontrado para **alpha** foi **0.04**.\n",
        "\n",
        "Esse modelo foi bem-sucedido em encontrar um valor apropriado para **alpha**, garantindo uma boa generalização para novos dados.\n",
        "\n",
        "### Segunda Célula: Refinamento da Busca por Alpha\n",
        "\n",
        "1. **Ajuste Fino**: Nesta célula, estamos refinando a busca por **alpha** com valores entre [0.035, 0.04, 0.045, 0.05, 0.055]. Isso representa uma busca mais detalhada, tentando encontrar o valor de **alpha** que forneça o melhor equilíbrio entre bias e variância.\n",
        "\n",
        "2. **Resultado**:\n",
        "   - O melhor valor de **alpha** foi **0.035**, o que resultou em um **MSE** de 0.37468719906131465 e um **\\(R^2\\)** de 0.794746466068081.\n",
        "\n",
        "### Terceira e Quarta Células: Treinamento e Avaliação Separada para Times da Casa e Visitante\n",
        "\n",
        "Aqui estamos separando os dados para prever os gols do **Time da Casa** e do **Time Visitante**.\n",
        "\n",
        "1. **Home Team (Time da Casa)**:\n",
        "   - O modelo foi treinado usando o **Lasso** com **alpha = 0.035**.\n",
        "   - As previsões para os gols do time da casa resultaram em um **MSE** de **0.21162443650241** e um **\\(R^2\\)** de **0.5492836485110912**. Embora o **\\(R^2\\)** não seja tão alto quanto esperado, o modelo ainda consegue explicar mais da metade da variação nos gols.\n",
        "\n",
        "2. **Away Team (Time Visitante)**:\n",
        "   - O mesmo processo foi realizado para o time visitante, resultando em um **MSE** de **0.20792683223841768** e um **\\(R^2\\)** de **0.7518625241716734**, o que mostra que o modelo é mais eficiente em prever os gols do time visitante.\n",
        "\n",
        "### Conclusão\n",
        "\n",
        "O **LassoCV** nos permitiu refinar o valor de **alpha** de maneira eficiente, utilizando a validação cruzada para garantir que o modelo esteja bem ajustado e generalize bem. A separação das previsões entre os times da casa e visitante também revelou que o modelo tem uma performance ligeiramente melhor para o time visitante.\n",
        "\n",
        "Os próximos passos podem incluir ajustes nos hiperparâmetros e a exploração de outras técnicas de regularização ou ensemble methods para melhorar ainda mais a performance do modelo, especialmente para o time da casa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBuxy373XyCM",
        "outputId": "3e3960f0-77f0-46a9-f5fe-4e0d25497351"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "# Criando o modelo Lasso com validação cruzada para ajustar o alpha para o time da casa\n",
        "lasso_home_cv = LassoCV(alphas=[0.01, 0.015, 0.02, 0.025, 0.03, 0.035], cv=5, max_iter=10000, random_state=42)\n",
        "\n",
        "# Treinando o modelo Lasso com validação cruzada\n",
        "lasso_home_cv.fit(X_train_home, y_train_home)\n",
        "\n",
        "# Fazendo previsões para o time da casa\n",
        "y_pred_test_home_cv = lasso_home_cv.predict(X_test_home)\n",
        "\n",
        "# Avaliando o modelo\n",
        "test_mse_home_cv = mean_squared_error(y_test_home, y_pred_test_home_cv)\n",
        "test_r2_home_cv = r2_score(y_test_home, y_pred_test_home_cv)\n",
        "\n",
        "# Melhor alpha encontrado\n",
        "best_alpha_home = lasso_home_cv.alpha_\n",
        "\n",
        "print(f\"Melhor Alpha para o Time da Casa: {best_alpha_home}\")\n",
        "print(\"Time da Casa - MSE:\", test_mse_home_cv, \"R²:\", test_r2_home_cv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ycUjxysXyIw",
        "outputId": "f7962408-738a-42b9-b8b6-7ba8ef4df900"
      },
      "outputs": [],
      "source": [
        "# Prevendo os gols do time da casa e do visitante para calcular o placar final\n",
        "y_pred_home_final = lasso_home.predict(X_test_home)\n",
        "y_pred_away_final = lasso_away.predict(X_test_away)\n",
        "\n",
        "# Gerando o placar final\n",
        "for i in range(len(y_pred_home_final)):\n",
        "    print(f\"Placar previsto: Time da Casa {round(y_pred_home_final[i])} x {round(y_pred_away_final[i])} Time Visitante\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ5Dwq-grZV1"
      },
      "source": [
        "Nessas células, começamos a previsão dos placares das partidas utilizando o modelo de regressão Lasso otimizado. Vou explicar os principais passos e as abordagens que estamos utilizando:\n",
        "\n",
        "### 1. Predição dos Placar Final para o Time da Casa e Visitante\n",
        "Nas primeiras células, utilizamos o modelo LassoCV para ajustar o parâmetro **alpha** de forma a minimizar o erro quadrático médio (MSE) e maximizar o \\( R^2 \\). Após encontrar o melhor valor de **alpha** (neste caso, **0.025**), usamos o modelo treinado para prever os gols do time da casa e visitante:\n",
        "\n",
        "- **y_pred_home**: Previsão dos gols do time da casa usando o modelo Lasso treinado.\n",
        "- **y_pred_away**: Previsão dos gols do time visitante usando o mesmo procedimento.\n",
        "\n",
        "### 2. Gerando os Placar Final\n",
        "Depois de obter as previsões de gols, geramos os placares para as partidas testadas. O resultado apresenta os placares previstos para cada uma das partidas do conjunto de teste.\n",
        "\n",
        "### 3. Abordagem Anterior vs. Melhoria Proposta\n",
        "Nos resultados atuais, observamos que muitos dos placares previstos são \"0 x 0\". Isso pode ser um indício de que o modelo Lasso precisa de um ajuste mais fino, talvez envolvendo outras features ou técnicas para melhorar a variabilidade dos placares previstos.\n",
        "\n",
        "### 4. Próximas Abordagens\n",
        "\n",
        "**a) Random Forest com Features Refinadas:**\n",
        "Após observar os resultados iniciais, decidimos melhorar as previsões experimentando o modelo Random Forest com as **top 10 features mais importantes**, que foram identificadas previamente. As features selecionadas são aquelas que possuem maior impacto na previsão dos gols, como chutes a gol, posse de bola, e gols no primeiro tempo.\n",
        "\n",
        "**b) Otimização dos Hiperparâmetros com GridSearch:**\n",
        "Para garantir que estamos extraindo o melhor desempenho do Random Forest, aplicamos o **GridSearchCV** para encontrar os melhores hiperparâmetros, como o número de estimadores, profundidade máxima, e o número mínimo de amostras para a divisão.\n",
        "\n",
        "### Objetivo Final\n",
        "\n",
        "Queremos chegar a um modelo que:\n",
        "1. **Minimize o MSE**: Queremos que o erro nas previsões seja o menor possível, garantindo previsões mais precisas dos placares.\n",
        "2. **Melhore a Variabilidade**: Queremos evitar a repetição de placares \"0 x 0\", garantindo que o modelo reflita melhor a diversidade dos resultados reais.\n",
        "3. **Maximize o \\( R^2 \\)**: Indicando que o modelo está explicando bem a variabilidade dos dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvlq-m-OZVYI",
        "outputId": "267a8bef-12c0-4ab4-b674-f1dc8cd67ad1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Usando agoras as top 10 features refinadas\n",
        "X_train_home_refined, X_test_home_refined, y_train_home_refined, y_test_home_refined = train_test_split(X_refined, y_home, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criando o modelo RandomForest\n",
        "rf_home_refined = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Definindo o grid de hiperparâmetros para otimizar o modelo RandomForest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "}\n",
        "\n",
        "# Configurando o GridSearchCV para otimização\n",
        "grid_search_rf_refined = GridSearchCV(estimator=rf_home_refined, param_grid=param_grid_rf, cv=3, scoring='r2', n_jobs=-1)\n",
        "\n",
        "# Treinando o modelo com busca de hiperparâmetros\n",
        "grid_search_rf_refined.fit(X_train_home_refined, y_train_home_refined)\n",
        "\n",
        "# Obtendo os melhores hiperparâmetros\n",
        "best_params_rf_refined = grid_search_rf_refined.best_params_\n",
        "\n",
        "# Fazendo previsões com o melhor modelo Random Forest\n",
        "best_rf_home_refined = grid_search_rf_refined.best_estimator_\n",
        "y_pred_test_rf_home_refined = best_rf_home_refined.predict(X_test_home_refined)\n",
        "\n",
        "# Avaliando o modelo Random Forest\n",
        "test_mse_rf_home_refined = mean_squared_error(y_test_home_refined, y_pred_test_rf_home_refined)\n",
        "test_r2_rf_home_refined = r2_score(y_test_home_refined, y_pred_test_rf_home_refined)\n",
        "\n",
        "print(f\"Melhores Hiperparâmetros: {best_params_rf_refined}\")\n",
        "print(\"Random Forest Time da Casa (Refinado) - MSE:\", test_mse_rf_home_refined, \"R²:\", test_r2_rf_home_refined)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Ikq-MS33zT0M",
        "outputId": "867bacb8-a7c3-49dc-85eb-212de6d1129f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizando a distribuição dos gols do time da casa\n",
        "plt.hist(y_home, bins=10, color='skyblue')\n",
        "plt.title('Distribuição dos Gols do Time da Casa')\n",
        "plt.xlabel('Gols')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()\n",
        "\n",
        "#Avaliando a distribuicao para identificar possiveis distribuicoes irregulares\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvhwiyVBzT9q",
        "outputId": "d0327455-0b5a-4198-b7cb-d0b11de8dcb3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Aplicando a transformação logarítmica nos gols do time da casa\n",
        "y_home_log = np.log1p(y_home)  # log1p(x) = log(1 + x) para evitar log(0)\n",
        "\n",
        "# Separando os dados de treino e teste após a transformação\n",
        "X_train_home_log, X_test_home_log, y_train_home_log, y_test_home_log = train_test_split(X_refined, y_home_log, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinando o modelo Lasso com os dados regularizados (log transform)\n",
        "lasso_home_log = Lasso(alpha=0.035, max_iter=10000, random_state=42)\n",
        "lasso_home_log.fit(X_train_home_log, y_train_home_log)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_test_home_log = lasso_home_log.predict(X_test_home_log)\n",
        "\n",
        "# Invertendo a transformação logarítmica para avaliar os resultados\n",
        "y_pred_test_home_final = np.expm1(y_pred_test_home_log)  # expm1(x) = exp(x) - 1\n",
        "\n",
        "# Avaliando o modelo\n",
        "test_mse_home_log = mean_squared_error(y_test_home, y_pred_test_home_final)\n",
        "test_r2_home_log = r2_score(y_test_home, y_pred_test_home_final)\n",
        "\n",
        "print(\"Modelo Lasso (Dados Log) - MSE:\", test_mse_home_log, \"R²:\", test_r2_home_log)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IehRo8JaryXM"
      },
      "source": [
        "Nesta parte, estamos abordando um desafio comum em previsões de placares, onde a distribuição dos dados está enviesada, ou seja, temos muitos zeros (ou seja, partidas com nenhum gol marcado) e poucos valores maiores (partidas com muitos gols). Vamos detalhar a lógica por trás das células e por que aplicamos a transformação logarítmica.\n",
        "\n",
        "### Explicação das Células:\n",
        "\n",
        "1. **Distribuição dos Gols do Time da Casa (Gráfico)**:\n",
        "   - O primeiro gráfico mostra a **distribuição dos gols do time da casa**. Como podemos ver, a maioria das partidas resulta em zero ou poucos gols, com muito menos partidas resultando em 3, 4 ou 5 gols.\n",
        "   - Este tipo de distribuição é conhecida como **distribuição enviesada** (ou skewed distribution), o que pode dificultar o treinamento de modelos de regressão linear, como o Random Forest ou Lasso, pois esses modelos podem não captar bem essa variação desigual nos dados.\n",
        "\n",
        "2. **Problema com Distribuições Enviadas**:\n",
        "   - Quando os dados têm essa distribuição enviesada, o modelo pode acabar tendo dificuldades para prever resultados em cenários de alta variabilidade. Como resultado, pode tender a prever sempre valores próximos a zero, o que não reflete a realidade de jogos com maiores quantidades de gols.\n",
        "\n",
        "3. **Aplicação da Transformação Logarítmica**:\n",
        "   - Para resolver esse problema, aplicamos uma **transformação logarítmica** nos dados dos gols do time da casa. Isso \"comprime\" a distribuição, tornando-a mais simétrica e distribuída de maneira que o modelo consiga capturar melhor a variação dos dados.\n",
        "   - **Fórmula usada**: A transformação aplicada é $[ y_{\\text{log}} = \\log(1 + y) ]$. A adição de 1 evita que valores zero resultem em valores indefinidos, já que o logaritmo de 0 não existe.\n",
        "   - **Benefício**: A transformação logarítmica ajuda a \"linearizar\" as relações, tornando os dados mais fáceis de serem modelados e melhorando a capacidade do modelo de capturar padrões, principalmente em previsões que envolvem dados com grande variância.\n",
        "\n",
        "4. **Treinamento e Avaliação do Modelo Lasso com Transformação Logarítmica**:\n",
        "   - Após aplicar a transformação logarítmica, treinamos o modelo **Lasso** com os dados transformados. A previsão também é feita no espaço logarítmico.\n",
        "   - Para retornar os valores previstos ao espaço original (gols reais), aplicamos a **exponencial inversa** $[ \\exp(y_{\\text{log}}) - 1 ]$, de modo a reverter a transformação logarítmica e comparar os resultados com os valores reais.\n",
        "   - **Resultados**: O modelo Lasso com a transformação logarítmica apresentou um **MSE de 0.187** e um \\( R^2 \\) de **0.600**, o que representa uma melhora significativa em relação ao modelo sem transformação.\n",
        "\n",
        "### Conclusão:\n",
        "A **transformação logarítmica** foi crucial para melhorar a capacidade de previsão do modelo em um conjunto de dados enviesado, como o de previsões de placares. Com essa abordagem, conseguimos capturar melhor a variabilidade entre jogos com muitos e poucos gols, resultando em previsões mais precisas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yHVoMhDzUAu"
      },
      "outputs": [],
      "source": [
        "# Modelo do time da casa com transformação logarítmica\n",
        "y_pred_test_home_final = np.expm1(y_pred_test_home_log)  # Previsão final já deslogaritmizada\n",
        "# Aplicar transformação logarítmica nos gols do time visitante\n",
        "y_away_log = np.log1p(y_away)\n",
        "\n",
        "# Separar os dados de treino e teste após a transformação\n",
        "X_train_away_log, X_test_away_log, y_train_away_log, y_test_away_log = train_test_split(X_refined, y_away_log, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinar o modelo Lasso para o time visitante com transformação logarítmica\n",
        "lasso_away_log = Lasso(alpha=0.035, max_iter=10000, random_state=42)\n",
        "lasso_away_log.fit(X_train_away_log, y_train_away_log)\n",
        "\n",
        "# Fazer previsões para o time visitante\n",
        "y_pred_test_away_log = lasso_away_log.predict(X_test_away_log)\n",
        "\n",
        "# Inverter a transformação logarítmica para obter as previsões finais\n",
        "y_pred_test_away_final = np.expm1(y_pred_test_away_log)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoH0RaLUzUDU",
        "outputId": "59568a39-fcd3-4802-9b0b-d6e0cce1ff7e"
      },
      "outputs": [],
      "source": [
        "# Gerar o placar final para cada partida\n",
        "for i in range(len(y_pred_test_home_final)):\n",
        "    print(f\"Placar previsto: Time da Casa {round(y_pred_test_home_final[i])} x {round(y_pred_test_away_final[i])} Time Visitante\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw14fsmO4lxn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Criar uma variável binária que indica se haverá gols na partida (1) ou não (0)\n",
        "y_binary_home = (y_home > 0).astype(int)\n",
        "y_binary_away = (y_away > 0).astype(int)\n",
        "\n",
        "# Dividindo os dados de treino e teste para o time da casa\n",
        "X_train_binary_home, X_test_binary_home, y_train_binary_home, y_test_binary_home = train_test_split(X_refined, y_binary_home, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinando um modelo de regressão logística para prever se haverá gols ou não\n",
        "logreg_home = LogisticRegression(max_iter=10000)\n",
        "logreg_home.fit(X_train_binary_home, y_train_binary_home)\n",
        "\n",
        "# Fazendo previsões binárias (se haverá gols ou não)\n",
        "y_pred_binary_home = logreg_home.predict(X_test_binary_home)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oAhgl9Z4l5s"
      },
      "outputs": [],
      "source": [
        "# Prever a quantidade de gols para o time da casa, caso o modelo binário preveja que haverá gols\n",
        "y_pred_home_final_adjusted = []\n",
        "for i in X_test_home_log.index:  # Acessar diretamente os índices disponíveis\n",
        "    if y_pred_binary_home[X_test_home_log.index.get_loc(i)] == 1:  # Usar o índice correto para acessar as previsões binárias\n",
        "        # Passar a linha como um DataFrame com os nomes das colunas\n",
        "        pred = np.expm1(lasso_home_log.predict(X_test_home_log.loc[[i]]))  # Previsão deslogaritmizada\n",
        "        y_pred_home_final_adjusted.append(round(pred[0]))\n",
        "    else:\n",
        "        # Se o modelo binário prever que não haverá gols\n",
        "        y_pred_home_final_adjusted.append(0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEjP26tI4l7z"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Criar uma variável binária que indica se o time visitante marcará gols (1) ou não (0)\n",
        "y_binary_away = (y_away > 0).astype(int)\n",
        "\n",
        "# Dividindo os dados de treino e teste para o time visitante\n",
        "X_train_binary_away, X_test_binary_away, y_train_binary_away, y_test_binary_away = train_test_split(X_refined, y_binary_away, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinando um modelo de regressão logística para prever se o time visitante marcará gols ou não\n",
        "logreg_away = LogisticRegression(max_iter=10000)\n",
        "logreg_away.fit(X_train_binary_away, y_train_binary_away)\n",
        "\n",
        "# Fazendo previsões binárias (se o time visitante marcará gols ou não)\n",
        "y_pred_binary_away = logreg_away.predict(X_test_binary_away)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQtWSwCW4l-L"
      },
      "outputs": [],
      "source": [
        "# Prever a quantidade de gols para o time visitante, caso o modelo binário preveja que haverá gols\n",
        "y_pred_away_final_adjusted = []\n",
        "for i in X_test_away_log.index:  # Acessar diretamente os índices disponíveis\n",
        "    if y_pred_binary_away[X_test_away_log.index.get_loc(i)] == 1:  # Usar o índice para acessar as previsões binárias\n",
        "        # Passar a linha como um DataFrame com os nomes das colunas\n",
        "        pred = np.expm1(lasso_away_log.predict(X_test_away_log.loc[[i]]))  # Previsão deslogaritmizada\n",
        "        y_pred_away_final_adjusted.append(round(pred[0]))\n",
        "    else:\n",
        "        # Se o modelo binário prever que não haverá gols\n",
        "        y_pred_away_final_adjusted.append(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjqcNnNN4mAP"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Criar uma variável binária que indica se o time visitante marcará gols (1) ou não (0)\n",
        "y_binary_away = (y_away > 0).astype(int)\n",
        "\n",
        "# Dividindo os dados de treino e teste para o time visitante\n",
        "X_train_binary_away, X_test_binary_away, y_train_binary_away, y_test_binary_away = train_test_split(X_refined, y_binary_away, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinando um modelo de regressão logística para prever se o time visitante marcará gols ou não\n",
        "logreg_away = LogisticRegression(max_iter=10000)\n",
        "logreg_away.fit(X_train_binary_away, y_train_binary_away)\n",
        "\n",
        "# Fazendo previsões binárias (se o time visitante marcará gols ou não)\n",
        "y_pred_binary_away = logreg_away.predict(X_test_binary_away)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmNzWkuw5-WC"
      },
      "outputs": [],
      "source": [
        "# Prever a quantidade de gols para o time visitante, caso o modelo binário preveja que haverá gols\n",
        "y_pred_away_final_adjusted = []\n",
        "for i in X_test_away_log.index:  # Acessar diretamente os índices disponíveis\n",
        "    if y_pred_binary_away[X_test_away_log.index.get_loc(i)] == 1:\n",
        "        # Passar a linha como um DataFrame com os nomes das colunas\n",
        "        pred = np.expm1(lasso_away_log.predict(X_test_away_log.loc[[i]]))  # Previsão deslogaritmizada\n",
        "        y_pred_away_final_adjusted.append(round(pred[0]))\n",
        "    else:\n",
        "        # Se o modelo binário prever que não haverá gols\n",
        "        y_pred_away_final_adjusted.append(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V37cNYvFsFys"
      },
      "source": [
        "Nessas células, vamos abordar o raciocínio por trás da aplicação de **transformações logarítmicas** e a **regressão logística binária** como estratégias para melhorar a previsibilidade dos modelos em relação ao placar final das partidas, considerando as previsões de gols de ambos os times.\n",
        "\n",
        "### 1. **Transformação Logarítmica**\n",
        "Após a visualização inicial da distribuição de gols dos times da casa, ficou claro que a maioria das partidas apresentava poucos gols, com muitos valores próximos a zero. Esse comportamento levou à escolha de uma **transformação logarítmica** nas variáveis de gols, tanto para o time da casa quanto para o time visitante. A ideia aqui é suavizar a variação dos dados e reduzir o efeito de grandes disparidades entre as partidas com muitos gols e aquelas com poucos ou nenhum.\n",
        "\n",
        "A fórmula da transformação logarítmica aplicada foi:\n",
        "$$\n",
        "[\n",
        "y_{\\text{log}} = \\log(1 + y)\n",
        "]\n",
        "$$\n",
        "Essa abordagem permite que a regressão lide melhor com a alta concentração de valores baixos (ou zero) e as diferenças drásticas nos placares.\n",
        "\n",
        "### 2. **Modelo de Regressão Logística Binária**\n",
        "Após a aplicação da transformação logarítmica, outra abordagem foi implementada para melhorar a previsão de placares: a **regressão logística binária**. Esse modelo foi utilizado para prever se uma equipe marcará gols ou não (1 para marcar, 0 para não marcar).\n",
        "\n",
        "#### Fluxo de Trabalho:\n",
        "- **Criação de Variável Binária**: A primeira etapa foi a criação de uma variável binária (`y_binary`) que indica se o time marcou ao menos um gol ou não.\n",
        "  \n",
        "- **Treinamento e Teste**: O modelo foi treinado e testado com os dados binários para prever se haverá gols em uma partida.\n",
        "  \n",
        "- **Previsão Binária**: Caso o modelo binário preveja que o time marcará gols, utiliza-se o modelo **Lasso** logaritimizado para prever o número exato de gols. Caso contrário, o placar final do time será definido como zero.\n",
        "\n",
        "Esse modelo híbrido de regressão logística binária combinado com o Lasso Logarítmico foi aplicado para ambos os times, da casa e visitante, com o objetivo de aumentar a precisão na previsão de placares.\n",
        "\n",
        "### Conclusão:\n",
        "- A **transformação logarítmica** foi fundamental para lidar com a distribuição assimétrica dos gols e evitar previsões exageradas.\n",
        "- A **regressão logística binária** permitiu uma melhor decisão de quando aplicar o modelo Lasso para prever gols, especialmente em partidas com placares muito baixos ou zero.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf9ZDjH25-Yv",
        "outputId": "d885bf0f-e897-4763-be4e-3999eed7e00b"
      },
      "outputs": [],
      "source": [
        "# Gerar o placar final ajustado\n",
        "for i in range(len(y_pred_home_final_adjusted)):\n",
        "    print(f\"Placar final: Time da Casa {y_pred_home_final_adjusted[i]} x {y_pred_away_final_adjusted[i]} Time Visitante\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1thSR275-bR"
      },
      "outputs": [],
      "source": [
        "# Ajustando o threshold para o modelo binário\n",
        "y_pred_proba_binary_home = logreg_home.predict_proba(X_test_binary_home)[:, 1]  # Probabilidades para o time da casa marcar gols\n",
        "y_pred_binary_home = (y_pred_proba_binary_home >= 0.3).astype(int)  # Ajustando o threshold para 0.3\n",
        "\n",
        "y_pred_proba_binary_away = logreg_away.predict_proba(X_test_binary_away)[:, 1]  # Probabilidades para o time visitante marcar gols\n",
        "y_pred_binary_away = (y_pred_proba_binary_away >= 0.3).astype(int)  # Ajustando o threshold para 0.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex-3JF_f5-dz"
      },
      "outputs": [],
      "source": [
        "# Usar as previsões com o threshold ajustado\n",
        "y_pred_home_final_adjusted = []\n",
        "for i in X_test_home_log.index:  # Acessar diretamente os índices disponíveis\n",
        "    if y_pred_binary_home[X_test_home_log.index.get_loc(i)] == 1:  # Usar o índice correto para acessar as previsões binárias\n",
        "        # Passar a linha como um DataFrame com os nomes das colunas\n",
        "        pred = np.expm1(lasso_home_log.predict(X_test_home_log.loc[[i]]))  # Previsão deslogaritmizada\n",
        "        y_pred_home_final_adjusted.append(round(pred[0]))\n",
        "    else:\n",
        "        # Se o modelo binário prever que não haverá gols\n",
        "        y_pred_home_final_adjusted.append(0)\n",
        "\n",
        "# Fazer o mesmo para o time visitante\n",
        "y_pred_away_final_adjusted = []\n",
        "for i in X_test_away_log.index:  # Acessar diretamente os índices disponíveis\n",
        "    if y_pred_binary_away[X_test_away_log.index.get_loc(i)] == 1:  # Usar o índice correto para acessar as previsões binárias\n",
        "        pred = np.expm1(lasso_away_log.predict(X_test_away_log.loc[[i]]))  # Previsão deslogaritmizada\n",
        "        y_pred_away_final_adjusted.append(round(pred[0]))\n",
        "    else:\n",
        "        y_pred_away_final_adjusted.append(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWwDFmaqspxo"
      },
      "source": [
        "Aqui está a documentação para a célula com a abordagem de previsão binária e ajustada:\n",
        "\n",
        "---\n",
        "\n",
        "### Previsão Binária de Gols e Ajuste da Quantidade de Gols\n",
        "\n",
        "Nesta seção, utilizamos uma abordagem combinada para prever se os times marcarão gols (previsão binária) e, em caso positivo, quantos gols serão marcados (previsão quantitativa). A lógica por trás disso é usar um modelo mais simples, como a **Regressão Logística**, para determinar se um time vai marcar ou não, e então um modelo mais refinado, como o **Lasso** logarítmico, para prever a quantidade exata de gols.\n",
        "\n",
        "#### 1. **Regressão Logística para Previsão Binária de Gols**\n",
        "Primeiramente, usamos a **Regressão Logística** para prever se os times marcarão gols (classe 1) ou não (classe 0). O modelo retorna uma **probabilidade** de um time marcar gols, e ajustamos um **threshold de 0,3**, o que significa que se a probabilidade for superior a 30%, consideramos que o time marcará gols.\n",
        "\n",
        "- **Por que RegLog?**: A **Regressão Logística** é uma escolha apropriada quando estamos lidando com problemas binários (marcar ou não gols).\n",
        "- **Ajuste do Threshold**: Escolhemos o valor de 0,3 para aumentar a sensibilidade do modelo em prever gols, mas vale a pena ajustar e validar essa escolha.\n",
        "\n",
        "#### 2. **Previsão da Quantidade de Gols com Lasso Logarítmico**\n",
        "Se o time é previsto para marcar gols pela RegLog, utilizamos um modelo mais avançado para prever **quantos gols exatamente serão marcados**. A transformação logarítmica é usada para estabilizar a variabilidade nos dados, e o **modelo Lasso Logarítmico** é aplicado para prever a quantidade de gols. Caso contrário, o número de gols é ajustado para zero.\n",
        "\n",
        "- **Transformação Logarítmica**: Aplica-se a transformação logarítmica para lidar melhor com os valores de gols, já que temos muitos jogos com zero gols e alguns com valores elevados. Essa transformação melhora a qualidade da previsão.\n",
        "- **Previsão Quantitativa de Gols**: Quando o time é previsto para marcar gols, utilizamos o **Lasso** para prever o número exato de gols, e em seguida desfazemos a transformação logarítmica para retornar o valor original.\n",
        "\n",
        "#### 3. **Ajuste do Threshold**\n",
        "Ajustamos o **threshold de 0,3** tanto para o time da casa quanto para o visitante, o que significa que, se o modelo logístico prever uma probabilidade maior que 30% de marcar gols, consideramos que o time marcará.\n",
        "\n",
        "#### 4. **Combinação das Previsões**\n",
        "A combinação de previsões binárias (se haverá gols ou não) e quantitativas (quantos gols) resulta no placar final ajustado para cada jogo. Se o time for previsto para não marcar, o número de gols será zero. Caso contrário, o número de gols será previsto pelo **Lasso** logarítmico.\n",
        "\n",
        "#### 5. **Código**\n",
        "O código abaixo implementa essa abordagem:\n",
        "\n",
        "```python\n",
        "# Prever a quantidade de gols para o time da casa, caso o modelo binário preveja que haverá gols\n",
        "y_pred_home_final_adjusted = []\n",
        "for i in X_test_home_log.index:  # Acessar diretamente os índices disponíveis\n",
        "    if y_pred_binary_home[X_test_home_log.index.get_loc(i)] == 1:  # Usar o índice correto para acessar as previsões binárias\n",
        "        pred = np.expm1(lasso_home_log.predict(X_test_home_log.loc[[i]]))  # Previsão deslogaritmizada\n",
        "        y_pred_home_final_adjusted.append(round(pred[0]))\n",
        "    else:\n",
        "        y_pred_home_final_adjusted.append(0)\n",
        "\n",
        "# Prever a quantidade de gols para o time visitante, caso o modelo binário preveja que haverá gols\n",
        "y_pred_away_final_adjusted = []\n",
        "for i in X_test_away_log.index:  # Acessar diretamente os índices disponíveis\n",
        "    if y_pred_binary_away[X_test_away_log.index.get_loc(i)] == 1:  # Usar o índice correto para acessar as previsões binárias\n",
        "        pred = np.expm1(lasso_away_log.predict(X_test_away_log.loc[[i]]))  # Previsão deslogaritmizada\n",
        "        y_pred_away_final_adjusted.append(round(pred[0]))\n",
        "    else:\n",
        "        y_pred_away_final_adjusted.append(0)\n",
        "\n",
        "# Gerar o placar final ajustado\n",
        "for i in range(len(y_pred_home_final_adjusted)):\n",
        "    print(f\"Placar final: Time da Casa {y_pred_home_final_adjusted[i]} x {y_pred_away_final_adjusted[i]} Time Visitante\")\n",
        "```\n",
        "\n",
        "### Conclusão\n",
        "\n",
        "Essa abordagem híbrida é eficaz para lidar com problemas onde a variável-alvo (número de gols) é **esparsa** (muitos zeros) e pode ser tratada inicialmente como um problema de classificação binária, seguido por um ajuste com regressão para os casos onde há gols. A previsão com um **threshold ajustado** nos permite calibrar a sensibilidade do modelo para melhorar a previsão de jogos com baixa incidência de gols.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZhqB0gX5-hk",
        "outputId": "d48952b9-8817-4355-c2c0-b0cdddf2649f"
      },
      "outputs": [],
      "source": [
        "# Gerar o placar final ajustado com o threshold atualizado\n",
        "for i in range(len(y_pred_home_final_adjusted)):\n",
        "    print(f\"Placar ajustado: Time da Casa {y_pred_home_final_adjusted[i]} x {y_pred_away_final_adjusted[i]} Time Visitante\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94R_2zim5-jQ",
        "outputId": "edf22570-02f9-4978-8236-d029ee717455"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Avaliando as previsões para os gols do time da casa\n",
        "mse_home = mean_squared_error(y_test_home, y_pred_home_final_adjusted)\n",
        "r2_home = r2_score(y_test_home, y_pred_home_final_adjusted)\n",
        "\n",
        "# Avaliando as previsões para os gols do time visitante\n",
        "mse_away = mean_squared_error(y_test_away, y_pred_away_final_adjusted)\n",
        "r2_away = r2_score(y_test_away, y_pred_away_final_adjusted)\n",
        "\n",
        "print(f\"Time da Casa - MSE: {mse_home}, R²: {r2_home}\")\n",
        "print(f\"Time Visitante - MSE: {mse_away}, R²: {r2_away}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MGcVa_5txkC"
      },
      "source": [
        "### Análise das Previsões Finais e Avaliação do Modelo\n",
        "\n",
        "Nesta etapa, realizamos as previsões finais ajustadas com o **threshold** atualizado e calculamos as métricas de desempenho para os gols previstos dos times da casa e dos visitantes. Estamos próximos de finalizar o modelo, mas observamos que ainda há alguns ajustes a serem feitos, principalmente no modelo que prevê os gols do time da casa.\n",
        "\n",
        "#### 1. **Geração do Placar Final Ajustado**\n",
        "Utilizamos os resultados ajustados para gerar os placares finais das partidas. Como o modelo combina uma previsão binária para detectar se haverá gols e uma previsão quantitativa para estimar quantos gols serão marcados, ele apresenta os placares finais ajustados para cada jogo. Observamos que, em vários casos, o modelo prevê **0 a 0** para ambas as equipes, o que pode indicar que a abordagem binária está sendo conservadora em relação à previsão de gols.\n",
        "\n",
        "#### 2. **Avaliação do Modelo para o Time da Casa**\n",
        "O desempenho do modelo para o time da casa foi avaliado com as métricas **Mean Squared Error (MSE)** e **\\( R^2 \\)**:\n",
        "- **MSE**: 0.2763\n",
        "- **\\( R^2 \\)**: 0.4115\n",
        "\n",
        "Esses resultados indicam que o modelo para o time da casa ainda não está completamente otimizado. O valor de **\\( R^2 \\)**, que indica o quão bem o modelo explica a variabilidade dos dados, está abaixo do ideal. Isso sugere que o modelo para o time da casa pode precisar de ajustes, seja no ajuste do threshold, no refinamento do conjunto de features ou na abordagem do modelo.\n",
        "\n",
        "#### 3. **Avaliação do Modelo para o Time Visitante**\n",
        "O modelo para o time visitante apresentou um desempenho significativamente melhor:\n",
        "- **MSE**: 0.25\n",
        "- **\\( R^2 \\)**: 0.7017\n",
        "\n",
        "Esses valores indicam que o modelo para o time visitante está bem ajustado e explica uma boa parte da variabilidade nos dados, o que reflete um modelo robusto. A diferença de desempenho entre os modelos de gols da casa e gols do visitante pode estar relacionada às diferenças no comportamento dos dados ou às características das variáveis selecionadas para cada time.\n",
        "\n",
        "#### 4. **Conclusão e Próximos Passos**\n",
        "Estamos próximos de finalizar o modelo, com o desempenho do **time visitante** já atingindo níveis satisfatórios. O próximo passo é **ajustar o modelo para o time da casa**, possivelmente revisando o conjunto de features, ajustando o threshold, ou até mesmo testando outras técnicas de regularização ou otimização para garantir que o modelo tenha um melhor desempenho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2RvnWrR7bxr",
        "outputId": "e936a0be-6ee2-475e-f543-32df480375ae"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred_test_home_final = np.maximum(y_pred_test_home_final, 0)\n",
        "y_pred_test_away = np.maximum(y_pred_test_away, 0)\n",
        "\n",
        "# Gerar o placar final sem valores negativos\n",
        "for i in range(len(y_pred_test_home_final)):\n",
        "    print(f\"Placar Final Previsto: Time da Casa {round(y_pred_test_home_final[i])} x {round(y_pred_test_away[i])} Time Visitante\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3P36Qxz7b-U",
        "outputId": "efa0262c-3c09-4073-a2aa-f8810100b098"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Usar k-fold cross-validation\n",
        "cv_scores = cross_val_score(lasso_home_log, X_refined, y_home_log, cv=5, scoring='neg_mean_squared_error')\n",
        "print(f\"Cross-Validation MSE: {-cv_scores.mean()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0JTr6vW8tEM",
        "outputId": "3e4717e4-41d5-43b4-fcf2-1ce3d52026d1"
      },
      "outputs": [],
      "source": [
        "# Treinar o modelo Lasso com todos os dados disponíveis\n",
        "lasso_home_log.fit(X_refined, y_home_log)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_final = np.expm1(lasso_home_log.predict(X_refined))  # Reverter a transformação logarítmica\n",
        "\n",
        "# Garantir que os valores de gols não sejam negativos\n",
        "y_pred_final = np.maximum(y_pred_final, 0)\n",
        "\n",
        "# Avaliar o modelo\n",
        "final_mse = mean_squared_error(np.expm1(y_home_log), y_pred_final)\n",
        "final_r2 = r2_score(np.expm1(y_home_log), y_pred_final)\n",
        "\n",
        "print(\"Modelo Final - MSE:\", final_mse, \"R²:\", final_r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Mst3hYuG0x"
      },
      "source": [
        "### Melhorias no Modelo: Utilizando o Cross-Validation e a Regularização\n",
        "\n",
        "Nessa etapa, focamos em melhorar o desempenho do nosso modelo de previsão utilizando uma combinação de técnicas de regularização e validação cruzada para ajustar e avaliar a qualidade das previsões.\n",
        "\n",
        "#### 1. **Geração do Placar Final**\n",
        "Primeiro, utilizamos uma abordagem que garante que os valores previstos para os gols não sejam negativos:\n",
        "```python\n",
        "y_pred_test_home_final = np.maximum(y_pred_test_home_final, 0)\n",
        "y_pred_test_away = np.maximum(y_pred_test_away, 0)\n",
        "```\n",
        "Isso evita que o modelo gere previsões negativas, o que não faria sentido em um contexto esportivo.\n",
        "\n",
        "Os resultados gerados com essa abordagem ainda mostraram algumas partidas com placares de 0x0, mas a utilização da transformação logarítmica e o ajuste da regularização do modelo (por meio do Lasso) começaram a produzir previsões mais próximas da realidade.\n",
        "\n",
        "#### 2. **Validação Cruzada com Cross-Validation**\n",
        "A validação cruzada (Cross-Validation) foi usada para garantir que o modelo generalize bem para diferentes subconjuntos dos dados, evitando overfitting e subfitting. Nesse caso, utilizamos o K-Fold Cross-Validation com 5 folds:\n",
        "\n",
        "```python\n",
        "cv_scores = cross_val_score(lasso_home_log, X_refined, y_home_log, cv=5, scoring='neg_mean_squared_error')\n",
        "print(f\"Cross-Validation MSE: {-cv_scores.mean()}\")\n",
        "```\n",
        "O resultado do MSE da validação cruzada foi de aproximadamente **0.0461**, o que indica um desempenho robusto do modelo ao ser testado em diferentes divisões dos dados.\n",
        "\n",
        "#### 3. **Treinando o Modelo Lasso com Todos os Dados Disponíveis**\n",
        "Após a validação cruzada, treinamos o modelo Lasso com todos os dados disponíveis, utilizando a transformação logarítmica para regularizar a distribuição dos dados de gols. A transformação logarítmica ajuda a suavizar as discrepâncias nos dados e lida melhor com valores extremos (gols muito altos ou muito baixos).\n",
        "\n",
        "```python\n",
        "lasso_home_log.fit(X_refined, y_home_log)\n",
        "y_pred_final = np.expm1(lasso_home_log.predict(X_refined))\n",
        "y_pred_final = np.maximum(y_pred_final, 0)\n",
        "```\n",
        "\n",
        "#### 4. **Métricas do Modelo Final**\n",
        "Ao avaliar o modelo final, obtivemos as seguintes métricas:\n",
        "- **MSE**: 0.1645\n",
        "- **\\( R^2 \\)**: 0.7265\n",
        "\n",
        "Essas métricas indicam que o modelo está com um bom desempenho, especialmente considerando o valor de **\\( R^2 \\)**, que mostra que o modelo explica cerca de 72.65% da variação nos dados de gols. Comparado com as iterações anteriores, esse é um avanço significativo na qualidade das previsões.\n",
        "\n",
        "#### **Conclusão**\n",
        "O uso de técnicas como a validação cruzada e a regularização Lasso, combinadas com a transformação logarítmica dos dados, nos permitiu melhorar significativamente a capacidade de previsão do modelo. Ainda que algumas previsões tenham mantido placares de 0x0, o modelo agora tem um desempenho geral melhor, com métricas robustas e previsões mais próximas da realidade. Com ajustes adicionais, podemos otimizar ainda mais o modelo, especialmente para o time da casa, que ainda mostra uma leve necessidade de refinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k39yMrikzZp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "new_matches_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/brazil-serie-a-matches-2024-to-2024-stats (5).csv', delimiter=';')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q_8Oq6ekzix"
      },
      "outputs": [],
      "source": [
        "new_matches_df_complete = new_matches_df[new_matches_df['status'] == 'complete']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybwnOZ6JkzlR",
        "outputId": "511263a9-25ad-4310-c3ed-0a0062cab26b"
      },
      "outputs": [],
      "source": [
        "# Função para remover colunas e linhas com valores nulos acima de um limite\n",
        "def clean_data(df, column_thresh=0.8, row_thresh=0.5):\n",
        "    # Remove colunas com mais de 80% de valores ausentes\n",
        "    df_cleaned = df.dropna(thresh=df.shape[0] * column_thresh, axis=1)\n",
        "\n",
        "    # Remove linhas com mais de 50% de valores ausentes\n",
        "    df_cleaned = df_cleaned.dropna(thresh=df_cleaned.shape[1] * row_thresh)\n",
        "\n",
        "    return df_cleaned\n",
        "\n",
        "# Limpar os dados de jogos completos\n",
        "matches_df_cleaned = clean_data(new_matches_df_complete)\n",
        "\n",
        "# Exibir as primeiras linhas dos dados limpos\n",
        "matches_df_cleaned.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_wepbWYRkma"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Análise do Novo DataFrame e Limpeza de Dados\n",
        "\n",
        "Nesta célula, realizamos a leitura dos novos dados, seguidos de uma filtragem e limpeza para remover colunas e linhas com valores nulos excessivos.\n",
        "\n",
        "#### Passos:\n",
        "\n",
        "1. **Leitura dos Dados:**\n",
        "   ```python\n",
        "   new_matches_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/brazil-serie-a-matches-2024-to-2024-stats (5).csv', delimiter=';')\n",
        "   ```\n",
        "   Os dados de partidas são lidos a partir de um arquivo CSV. Esse arquivo contém dados detalhados de partidas da Série A do Brasil de 2024, incluindo estatísticas de desempenho dos times.\n",
        "\n",
        "2. **Filtragem de Partidas Completas:**\n",
        "   ```python\n",
        "   new_matches_df_complete = new_matches_df[new_matches_df['status'] == 'complete']\n",
        "   ```\n",
        "   Aqui, selecionamos apenas as partidas que foram concluídas, descartando aquelas que ainda estão em andamento ou que não foram finalizadas.\n",
        "\n",
        "3. **Função de Limpeza de Dados:**\n",
        "   ```python\n",
        "   def clean_data(df, column_thresh=0.8, row_thresh=0.5):\n",
        "       df_cleaned = df.dropna(thresh=df.shape[0] * column_thresh, axis=1)\n",
        "       df_cleaned = df_cleaned.dropna(thresh=df_cleaned.shape[1] * row_thresh)\n",
        "       return df_cleaned\n",
        "   ```\n",
        "   A função `clean_data` remove colunas que possuem mais de 80% de valores ausentes e linhas com mais de 50% de valores ausentes. Essa estratégia visa manter a consistência dos dados, removendo aqueles excessivamente incompletos.\n",
        "\n",
        "4. **Aplicação da Função e Visualização:**\n",
        "   ```python\n",
        "   matches_df_cleaned = clean_data(new_matches_df_complete)\n",
        "   matches_df_cleaned.info()\n",
        "   ```\n",
        "   Após a limpeza dos dados, utilizamos o método `info()` para inspecionar a estrutura do dataframe final, garantindo que as colunas e linhas restantes contenham informações suficientes para análise.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrZ8pH7vkznm",
        "outputId": "604425d3-2b5a-41b9-9914-a911a2b44b7b"
      },
      "outputs": [],
      "source": [
        "# Remover colunas não numéricas e irrelevantes (mantendo as variáveis alvo)\n",
        "X = matches_df_cleaned.drop(columns=['date_GMT', 'home_team_name', 'away_team_name'])\n",
        "\n",
        "# Variáveis alvo\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "y_away = matches_df_cleaned['away_team_goal_count']\n",
        "\n",
        "\n",
        "# Verificar se há mais colunas não numéricas\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Substituir valores NaN (se houver) após a conversão por zero ou uma média (dependendo do contexto)\n",
        "X.fillna(0, inplace=True)\n",
        "\n",
        "# Seguir com o restante do código para logaritmização e treino do modelo\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Função para transformar e reverter os dados logarítmicos\n",
        "def apply_log_transform(y):\n",
        "    return np.log1p(y)  # log1p(x) = log(1 + x)\n",
        "\n",
        "def reverse_log_transform(y_log):\n",
        "    return np.expm1(y_log)  # expm1(x) = exp(x) - 1\n",
        "\n",
        "# Aplicar a transformação logarítmica nos gols\n",
        "y_home_log = apply_log_transform(y_home)\n",
        "y_away_log = apply_log_transform(y_away)\n",
        "\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_train_home, X_test_home, y_train_home_log, y_test_home_log = train_test_split(X, y_home_log, test_size=0.2, random_state=42)\n",
        "X_train_away, X_test_away, y_train_away_log, y_test_away_log = train_test_split(X, y_away_log, test_size=0.2, random_state=42)\n",
        "\n",
        "# GridSearchCV para encontrar o melhor alpha no Lasso\n",
        "param_grid = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5, 1, 10]}\n",
        "\n",
        "# Validação cruzada\n",
        "lasso_home_log = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_home = GridSearchCV(lasso_home_log, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_home.fit(X_train_home, y_train_home_log)\n",
        "\n",
        "# Melhor modelo para o time da casa\n",
        "best_lasso_home_log = grid_search_home.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time da casa (com reversão da transformação logarítmica)\n",
        "y_pred_home_log = best_lasso_home_log.predict(X_test_home)\n",
        "y_pred_home_final = np.maximum(reverse_log_transform(y_pred_home_log), 0)  # Reverter a transformação logarítmica e evitar valores negativos\n",
        "\n",
        "# Métricas para o time da casa\n",
        "test_mse_home = mean_squared_error(reverse_log_transform(y_test_home_log), y_pred_home_final)\n",
        "test_r2_home = r2_score(reverse_log_transform(y_test_home_log), y_pred_home_final)\n",
        "\n",
        "print(f\"Time da Casa - Melhor Alpha: {grid_search_home.best_params_['alpha']}\")\n",
        "print(f\"Time da Casa - MSE: {test_mse_home}, R²: {test_r2_home}\")\n",
        "\n",
        "# Agora, repetir o processo para o time visitante\n",
        "lasso_away_log = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_away = GridSearchCV(lasso_away_log, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_away.fit(X_train_away, y_train_away_log)\n",
        "\n",
        "# Melhor modelo para o time visitante\n",
        "best_lasso_away_log = grid_search_away.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time visitante\n",
        "y_pred_away_log = best_lasso_away_log.predict(X_test_away)\n",
        "y_pred_away_final = np.maximum(reverse_log_transform(y_pred_away_log), 0)  # Reverter a transformação logarítmica e evitar valores negativos\n",
        "\n",
        "# Métricas para o time visitante\n",
        "test_mse_away = mean_squared_error(reverse_log_transform(y_test_away_log), y_pred_away_final)\n",
        "test_r2_away = r2_score(reverse_log_transform(y_test_away_log), y_pred_away_final)\n",
        "\n",
        "print(f\"Time Visitante - Melhor Alpha: {grid_search_away.best_params_['alpha']}\")\n",
        "print(f\"Time Visitante - MSE: {test_mse_away}, R²: {test_r2_away}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "78UfHEMdkzp0",
        "outputId": "2fd0bd38-c398-425a-d115-f6862ab7f8c4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Distribuição original dos gols do time da casa\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(y_home, kde=True, color='blue')\n",
        "plt.title(\"Distribuição Original dos Gols do Time da Casa\")\n",
        "plt.show()\n",
        "\n",
        "# Distribuição após a transformação logarítmica\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(y_home_log, kde=True, color='green')\n",
        "plt.title(\"Distribuição Logarítmica dos Gols do Time da Casa\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z9vv713RnxQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yAUHez8WkztO",
        "outputId": "505d63f7-9a50-4234-b153-27d414e8c8d0"
      },
      "outputs": [],
      "source": [
        "# Gols do Time da Casa - Previsões vs Reais\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test_home, y_pred_home_final_adjusted, color='blue')\n",
        "plt.plot([min(y_test_home), max(y_test_home)], [min(y_test_home), max(y_test_home)], 'k--', lw=3)\n",
        "plt.title(\"Previsões vs Valores Reais - Time da Casa\")\n",
        "plt.xlabel(\"Valores Reais\")\n",
        "plt.ylabel(\"Previsões\")\n",
        "plt.show()\n",
        "\n",
        "# Gols do Time Visitante - Previsões vs Reais\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test_away, y_pred_away_final_adjusted, color='green')\n",
        "plt.plot([min(y_test_away), max(y_test_away)], [min(y_test_away), max(y_test_away)], 'k--', lw=3)\n",
        "plt.title(\"Previsões vs Valores Reais - Time Visitante\")\n",
        "plt.xlabel(\"Valores Reais\")\n",
        "plt.ylabel(\"Previsões\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQx1_NuQRpQ6"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Remover Colunas Não Numéricas e Irrelevantes\n",
        "\n",
        "```python\n",
        "# Remover colunas não numéricas e irrelevantes (mantendo as variáveis alvo)\n",
        "X = matches_df_cleaned.drop(columns=['date_GMT', 'home_team_name', 'away_team_name'])\n",
        "\n",
        "# Variáveis alvo\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "y_away = matches_df_cleaned['away_team_goal_count']\n",
        "```\n",
        "\n",
        "Este trecho remove colunas irrelevantes para a análise e mantém apenas as variáveis de interesse, como o número de gols marcados pelo time da casa e pelo time visitante.\n",
        "\n",
        "---\n",
        "\n",
        "### Verificação e Tratamento de Dados Numéricos\n",
        "\n",
        "```python\n",
        "# Verificar se há mais colunas não numéricas\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Substituir valores NaN (se houver) após a conversão por zero ou uma média (dependendo do contexto)\n",
        "X.fillna(0, inplace=True)\n",
        "```\n",
        "\n",
        "Nesta parte, todas as colunas são convertidas para valores numéricos, e valores nulos são preenchidos com zeros, garantindo que o modelo possa processar os dados sem falhas.\n",
        "\n",
        "---\n",
        "\n",
        "### Aplicar Transformação Logarítmica\n",
        "\n",
        "```python\n",
        "# Função para transformar e reverter os dados logarítmicos\n",
        "def apply_log_transform(y):\n",
        "    return np.log1p(y)  # log(1 + y)\n",
        "\n",
        "def reverse_log_transform(y_log):\n",
        "    return np.expm1(y_log)  # exp(y) - 1\n",
        "\n",
        "# Aplicar a transformação logarítmica nos gols\n",
        "y_home_log = apply_log_transform(y_home)\n",
        "y_away_log = apply_log_transform(y_away)\n",
        "```\n",
        "\n",
        "Aqui, aplicamos uma transformação logarítmica aos valores de gols, que ajuda a suavizar a distribuição e reduzir a variância, especialmente quando os dados têm outliers ou valores desbalanceados.\n",
        "\n",
        "---\n",
        "\n",
        "### Separação dos Dados de Treino e Teste\n",
        "\n",
        "```python\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_train_home, X_test_home, y_train_home_log, y_test_home_log = train_test_split(X, y_home_log, test_size=0.2, random_state=42)\n",
        "X_train_away, X_test_away, y_train_away_log, y_test_away_log = train_test_split(X, y_away_log, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "Os dados são divididos em conjuntos de treino e teste, com 80% dos dados sendo utilizados para treinar o modelo e 20% para teste.\n",
        "\n",
        "---\n",
        "\n",
        "### GridSearchCV para Ajustar o Modelo\n",
        "\n",
        "```python\n",
        "# GridSearchCV para encontrar o melhor alpha no Lasso\n",
        "param_grid = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5, 1, 10]}\n",
        "\n",
        "# Time da Casa\n",
        "lasso_home_log = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_home = GridSearchCV(lasso_home_log, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_home.fit(X_train_home, y_train_home_log)\n",
        "\n",
        "# Melhor modelo para o time da casa\n",
        "best_lasso_home = grid_search_home.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time da casa (com reversão da transformação logarítmica)\n",
        "y_pred_home_log = best_lasso_home.predict(X_test_home)\n",
        "y_pred_home_final = np.maximum(reverse_log_transform(y_pred_home_log), 0)  # Reverter a transformação logarítmica e evitar valores negativos\n",
        "```\n",
        "\n",
        "Aqui, realizamos uma busca em grade (`GridSearchCV`) para encontrar o melhor valor de alpha para o modelo de regressão Lasso, otimizando as previsões dos gols do time da casa e evitando valores negativos ao reverter a transformação logarítmica.\n",
        "\n",
        "---\n",
        "\n",
        "### Validação Cruzada e Métricas de Desempenho\n",
        "\n",
        "```python\n",
        "# Métricas para o time da casa\n",
        "test_mse_home = mean_squared_error(reverse_log_transform(y_test_home_log), y_pred_home_final)\n",
        "test_r2_home = r2_score(reverse_log_transform(y_test_home_log), y_pred_home_final)\n",
        "\n",
        "print(f\"Time da Casa - Melhor Alpha: {grid_search_home.best_params_['alpha']}\")\n",
        "print(f\"Time da Casa - MSE: {test_mse_home}, R²: {test_r2_home}\")\n",
        "```\n",
        "\n",
        "As métricas de desempenho para o time da casa são calculadas, incluindo o erro médio quadrático (MSE) e o coeficiente de determinação (R²), que indicam a performance do modelo.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A9jbYXvVkzvN",
        "outputId": "154513bb-7867-4814-b9f7-1128cf0e5098"
      },
      "outputs": [],
      "source": [
        "# Erro Absoluto - Time da Casa\n",
        "error_home = np.abs(y_test_home - y_pred_home_final_adjusted)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(error_home, kde=True, color='red')\n",
        "plt.title(\"Erro Absoluto nas Previsões - Time da Casa\")\n",
        "plt.show()\n",
        "\n",
        "# Erro Absoluto - Time Visitante\n",
        "error_away = np.abs(y_test_away - y_pred_away_final_adjusted)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(error_away, kde=True, color='orange')\n",
        "plt.title(\"Erro Absoluto nas Previsões - Time Visitante\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH73vu9d5h6d",
        "outputId": "588a32bf-d183-4a9e-bbf0-a57c133289c8"
      },
      "outputs": [],
      "source": [
        "# Remover colunas categóricas ou não numéricas que não são relevantes\n",
        "X_cleaned = X.select_dtypes(exclude=['object'])\n",
        "# Substituir valores NaN por 0 ou pela média, dependendo do contexto\n",
        "X_cleaned.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Verificar se todas as colunas são numéricas agora\n",
        "print(X_cleaned.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RWpMN_crzbig",
        "outputId": "dc709490-6a0a-4ee9-d0f4-f7b22213b85e"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "matches_df_numeric = matches_df_cleaned.select_dtypes(include=[np.number])\n",
        "# Calcular a correlação entre as features e os gols do time da casa\n",
        "correlation_matrix = matches_df_numeric.corr()\n",
        "\n",
        "# Plotar a correlação\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
        "plt.title(\"Matriz de Correlação das Features\")\n",
        "plt.show()\n",
        "\n",
        "# Verificar correlação específica das variáveis com home_team_goal_count\n",
        "correlation_home = correlation_matrix['home_team_goal_count'].sort_values(ascending=False)\n",
        "print(correlation_home)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8F9WYPBSfqI"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Remover Colunas Não Numéricas e Irrelevantes\n",
        "\n",
        "```python\n",
        "# Remover colunas não numéricas e irrelevantes (mantendo as variáveis alvo)\n",
        "X = matches_df_cleaned.drop(columns=['date_GMT', 'home_team_name', 'away_team_name'])\n",
        "\n",
        "# Variáveis alvo\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "y_away = matches_df_cleaned['away_team_goal_count']\n",
        "\n",
        "# Verificar se há mais colunas não numéricas\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Substituir valores NaN (se houver) após a conversão por zero ou uma média (dependendo do contexto)\n",
        "X.fillna(0, inplace=True)\n",
        "```\n",
        "\n",
        "Nesta célula, removemos colunas categóricas como `date_GMT`, `home_team_name`, e `away_team_name` que não são úteis para o modelo e tratamos valores nulos, convertendo-os para valores numéricos ou substituindo-os por zero.\n",
        "\n",
        "---\n",
        "\n",
        "## Aplicação da Transformação Logarítmica\n",
        "\n",
        "```python\n",
        "# Função para transformar e reverter os dados logarítmicos\n",
        "def apply_log_transform(y):\n",
        "    return np.log1p(y)  # log(1 + y) é usada para evitar log(0)\n",
        "\n",
        "def reverse_log(y_log):\n",
        "    return np.expm1(y_log)  # exp(y_log) - 1 reverte a transformação logarítmica\n",
        "\n",
        "# Aplicar a transformação logarítmica aos gols\n",
        "y_home_log = apply_log_transform(y_home)\n",
        "y_away_log = apply_log_transform(y_away)\n",
        "```\n",
        "\n",
        "Aqui aplicamos a transformação logarítmica para os valores de gols com a função `log1p`, útil para reduzir a escala dos dados e melhorar a performance do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "## Seleção de Features Numéricas\n",
        "\n",
        "```python\n",
        "# Remover colunas categóricas ou não numéricas que não são relevantes\n",
        "X_cleaned = X.select_dtypes(exclude=['object'])\n",
        "\n",
        "# Substituir valores NaN por 0 ou pela média, dependendo do contexto\n",
        "X_cleaned.fillna(0, inplace=True)\n",
        "\n",
        "# Verificar se todas as colunas são numéricas agora\n",
        "print(X_cleaned.dtypes)\n",
        "```\n",
        "\n",
        "Após remover colunas categóricas e tratar valores nulos, garantimos que todas as features são numéricas e adequadas para o treinamento do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "## Correlação entre Features\n",
        "\n",
        "```python\n",
        "# Matriz de correlação para verificar a relação entre variáveis\n",
        "correlation_matrix = matches_df_cleaned.corr()\n",
        "\n",
        "# Plotar a matriz de correlação\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
        "plt.title(\"Matriz de Correlação das Features\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "Este código plota uma matriz de correlação entre as features numéricas, visualizando como cada uma delas se relaciona com as outras e identificando potenciais redundâncias.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Npk0nT-FzbtD",
        "outputId": "84aef874-f8c3-4703-dd3a-70df5b13d0a0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Features otimizadas para o time da casa\n",
        "features_home = [\n",
        "    'total_goal_count',\n",
        "    'home_team_goal_count_half_time',\n",
        "    'home_team_shots_on_target',\n",
        "    'home_ppg',\n",
        "    'team_a_xg'\n",
        "]\n",
        "\n",
        "X_refined_home = matches_df_cleaned[features_home]\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "\n",
        "# Verificar se há valores não numéricos e convertê-los para numéricos\n",
        "X_refined_home = X_refined_home.apply(pd.to_numeric, errors='coerce')\n",
        "X_refined_home.fillna(0, inplace=True)\n",
        "\n",
        "# Separar os dados para o time da casa\n",
        "X_train_home, X_test_home, y_train_home, y_test_home = train_test_split(X_refined_home, y_home, test_size=0.2, random_state=42)\n",
        "\n",
        "# GridSearchCV para encontrar o melhor alpha no Lasso para o time da casa\n",
        "param_grid_lasso_home = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5]}\n",
        "lasso_home = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_lasso_home = GridSearchCV(lasso_home, param_grid_lasso_home, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_lasso_home.fit(X_train_home, y_train_home)\n",
        "\n",
        "# Melhor modelo para o time da casa\n",
        "best_lasso_home = grid_search_lasso_home.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time da casa\n",
        "y_pred_home = best_lasso_home.predict(X_test_home)\n",
        "y_pred_home_final = np.maximum(y_pred_home, 0)  # Evitar valores negativos\n",
        "\n",
        "# Métricas para o time da casa\n",
        "mse_home = mean_squared_error(y_test_home, y_pred_home_final)\n",
        "r2_home = r2_score(y_test_home, y_pred_home_final)\n",
        "\n",
        "print(f\"Time da Casa - Melhor Alpha: {grid_search_lasso_home.best_params_['alpha']}\")\n",
        "print(f\"Time da Casa - MSE: {mse_home}, R²: {r2_home}\")\n",
        "\n",
        "\n",
        "\n",
        "# Features para o time visitante (remover colunas não numéricas e irrelevantes)\n",
        "X_away_refined = matches_df_cleaned.drop(columns=['date_GMT', 'home_team_name', 'away_team_name', 'status'])  # Remover colunas categoricas\n",
        "\n",
        "# Verificar se há mais colunas não numéricas e convertê-las para numéricos\n",
        "X_away_refined = X_away_refined.apply(pd.to_numeric, errors='coerce')\n",
        "X_away_refined.fillna(0, inplace=True)  # Substituir NaN por 0 ou outro valor adequado\n",
        "\n",
        "# Aplicar a transformação logarítmica nos gols do time visitante\n",
        "y_away_log = np.log1p(y_away)\n",
        "\n",
        "# Separar os dados para o time visitante\n",
        "X_train_away, X_test_away, y_train_away_log, y_test_away_log = train_test_split(X_away_refined, y_away_log, test_size=0.2, random_state=42)\n",
        "\n",
        "# GridSearchCV para encontrar o melhor alpha no Lasso para o time visitante\n",
        "param_grid_lasso_away = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5]}\n",
        "lasso_away_log = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_lasso_away = GridSearchCV(lasso_away_log, param_grid_lasso_away, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_lasso_away.fit(X_train_away, y_train_away_log)\n",
        "\n",
        "# Melhor modelo para o time visitante\n",
        "best_lasso_away = grid_search_lasso_away.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time visitante (com reversão da transformação logarítmica)\n",
        "y_pred_away_log = best_lasso_away.predict(X_test_away)\n",
        "y_pred_away_final = np.maximum(np.expm1(y_pred_away_log), 0)  # Reverter a transformação logarítmica e evitar valores negativos\n",
        "\n",
        "# Métricas para o time visitante\n",
        "test_mse_away = mean_squared_error(np.expm1(y_test_away_log), y_pred_away_final)\n",
        "test_r2_away = r2_score(np.expm1(y_test_away_log), y_pred_away_final)\n",
        "\n",
        "print(f\"Time Visitante - Melhor Alpha: {grid_search_lasso_away.best_params_['alpha']}\")\n",
        "print(f\"Time Visitante - MSE: {test_mse_away}, R²: {test_r2_away}\")\n",
        "\n",
        "\n",
        "# **Visualização dos resultados**\n",
        "# Gráfico para o time da casa\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(range(len(y_test_home)), y_test_home, color='blue', label='Valores Reais Time da Casa')\n",
        "plt.scatter(range(len(y_pred_home_final)), y_pred_home_final, color='red', label='Previsões Time da Casa')\n",
        "plt.title('Previsões vs Valores Reais (Time da Casa)')\n",
        "plt.xlabel('Índice de Jogos')\n",
        "plt.ylabel('Número de Gols')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Gráfico para o time visitante\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(range(len(np.expm1(y_test_away_log))), np.expm1(y_test_away_log), color='blue', label='Valores Reais Time Visitante')\n",
        "plt.scatter(range(len(y_pred_away_final)), y_pred_away_final, color='red', label='Previsões Time Visitante')\n",
        "plt.title('Previsões vs Valores Reais (Time Visitante)')\n",
        "plt.xlabel('Índice de Jogos')\n",
        "plt.ylabel('Número de Gols')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# **Previsão Final dos Resultados**\n",
        "for i in range(len(y_pred_home_final)):\n",
        "    print(f\"Placar Final: Time da Casa {y_pred_home_final[i]} x {y_pred_away_final[i]} Time Visitante\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR38T7ixG0Fv"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "#### 1. **Pré-processamento de Dados**\n",
        "```python\n",
        "# Remover colunas não numéricas e irrelevantes (mantendo as variáveis alvo)\n",
        "X = matches_df_cleaned.drop(columns=['date_GMT', 'home_team_name', 'away_team_name'])\n",
        "\n",
        "# Variáveis alvo\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "y_away = matches_df_cleaned['away_team_goal_count']\n",
        "\n",
        "# Verificar se há mais colunas não numéricas\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Substituir valores NaN (se houver) após a conversão por zero ou uma média (dependendo do contexto)\n",
        "X.fillna(0, inplace=True)\n",
        "```\n",
        "\n",
        "**Descrição**: Aqui estamos removendo colunas categóricas como `home_team_name` e `away_team_name`, que são irrelevantes para o modelo, e convertendo todos os dados para formato numérico. Também preenchemos valores nulos com zeros para garantir que não haja problemas ao passar esses dados ao modelo.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. **Aplicação de Transformação Logarítmica nos Gols**\n",
        "```python\n",
        "# Função para transformar e reverter os dados logarítmicos\n",
        "def apply_log_transform(y):\n",
        "    return np.log1p(y)  # log(1 + y)\n",
        "\n",
        "def reverse_log_transform(y_log):\n",
        "    return np.expm1(y_log)  # exp(y) - 1\n",
        "\n",
        "# Aplicar a transformação logarítmica nos gols\n",
        "y_home_log = apply_log_transform(y_home)\n",
        "y_away_log = apply_log_transform(y_away)\n",
        "```\n",
        "\n",
        "**Descrição**: Esta célula aplica uma transformação logarítmica aos dados de contagem de gols para suavizar a distribuição e reduzir o impacto de outliers. Também definimos uma função para reverter essa transformação ao final do processo de predição.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. **Divisão dos Dados em Conjuntos de Treino e Teste**\n",
        "```python\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_train_home, X_test_home, y_train_home_log, y_test_home_log = train_test_split(X, y_home_log, test_size=0.2, random_state=42)\n",
        "X_train_away, X_test_away, y_train_away_log, y_test_away_log = train_test_split(X, y_away_log, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "**Descrição**: Aqui, os dados foram divididos em conjuntos de treino e teste, usando 20% dos dados para teste e o restante para treino. A variável `random_state=42` é usada para garantir reprodutibilidade.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. **Treinamento do Modelo Lasso com GridSearchCV**\n",
        "```python\n",
        "# GridSearchCV para encontrar o melhor alpha no Lasso para o time da casa\n",
        "param_grid = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5, 1, 10]}\n",
        "lasso_home = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_home = GridSearchCV(lasso_home, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_home.fit(X_train_home, y_train_home_log)\n",
        "\n",
        "# Melhor modelo para o time da casa\n",
        "best_lasso_home = grid_search_home.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time da casa (com reversão da transformação logarítmica)\n",
        "y_pred_home_log = best_lasso_home.predict(X_test_home)\n",
        "y_pred_home_final = np.maximum(reverse_log_transform(y_pred_home_log), 0)  # Evitar valores negativos\n",
        "```\n",
        "\n",
        "**Descrição**: Nesta etapa, usamos `GridSearchCV` para otimizar o valor de `alpha` no modelo Lasso. Após encontrar o melhor modelo, as previsões são feitas e a transformação logarítmica é revertida.\n",
        "\n",
        "---\n",
        "\n",
        "#### 5. **Avaliação do Modelo para o Time da Casa**\n",
        "```python\n",
        "# Métricas para o time da casa\n",
        "test_mse_home = mean_squared_error(reverse_log_transform(y_test_home_log), y_pred_home_final)\n",
        "test_r2_home = r2_score(reverse_log_transform(y_test_home_log), y_pred_home_final)\n",
        "\n",
        "print(f\"Time da Casa - MSE: {test_mse_home}, R²: {test_r2_home}\")\n",
        "```\n",
        "\n",
        "**Descrição**: Aqui calculamos as métricas de desempenho, como o erro quadrático médio (MSE) e o coeficiente de determinação (R²), para o time da casa.\n",
        "\n",
        "---\n",
        "\n",
        "#### 6. **Plotagem de Previsões vs Valores Reais**\n",
        "```python\n",
        "# Gráfico para o time da casa\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(range(len(y_test_home)), reverse_log_transform(y_test_home_log), color='blue', label='Valores Reais Time da Casa')\n",
        "plt.scatter(range(len(y_pred_home_final)), y_pred_home_final, color='red', label='Previsões Time da Casa')\n",
        "plt.title('Previsões vs Valores Reais (Time da Casa)')\n",
        "plt.xlabel('Índice de Jogos')\n",
        "plt.ylabel('Número de Gols')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Descrição**: Esta célula plota as previsões (em vermelho) e os valores reais (em azul) dos gols do time da casa. O gráfico ajuda a visualizar o quão próximo o modelo previu os resultados.\n",
        "\n",
        "---\n",
        "\n",
        "#### 7. **Cálculo e Plotagem do Erro Absoluto**\n",
        "```python\n",
        "# Erro Absoluto - Time da Casa\n",
        "error_home = np.abs(reverse_log_transform(y_test_home_log) - y_pred_home_final)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(error_home, kde=True, color='red')\n",
        "plt.title(\"Erro Absoluto nas Previsões - Time da Casa\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Descrição**: Aqui calculamos o erro absoluto das previsões e plotamos um histograma com a curva KDE (estimativa de densidade). Isso ajuda a visualizar a distribuição dos erros.\n",
        "\n",
        "---\n",
        "\n",
        "#### 8. **Matriz de Correlação das Features**\n",
        "```python\n",
        "# Calcular a correlação entre as features e os gols do time da casa\n",
        "matches_df_numeric = matches_df_cleaned.select_dtypes(include=[np.number])\n",
        "correlation_matrix = matches_df_numeric.corr()\n",
        "\n",
        "# Plotar a correlação\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
        "plt.title(\"Matriz de Correlação das Features\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Descrição**: Esta célula gera uma matriz de correlação entre todas as variáveis numéricas, mostrando a relação entre elas e destacando potenciais multicolinearidades entre as features.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BqaellzGeCY",
        "outputId": "82973d30-4001-4517-e04e-5d08eece9e64"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# MAE para o time da casa\n",
        "mae_home = mean_absolute_error(y_test_home, y_pred_home_final)\n",
        "print(f\"Time da Casa - MAE: {mae_home}\")\n",
        "\n",
        "# MAE para o time visitante\n",
        "mae_away = mean_absolute_error(np.expm1(y_test_away_log), y_pred_away_final)\n",
        "print(f\"Time Visitante - MAE: {mae_away}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmVxPLeGeIh",
        "outputId": "64908be5-dfe5-40ad-8570-0ab8d2a73676"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Criar variáveis binárias para os valores reais e previstos (gols ou não)\n",
        "y_test_home_binary = (y_test_home > 0).astype(int)\n",
        "y_pred_home_binary = (y_pred_home_final > 0).astype(int)\n",
        "\n",
        "y_test_away_binary = (np.expm1(y_test_away_log) > 0).astype(int)\n",
        "y_pred_away_binary = (y_pred_away_final > 0).astype(int)\n",
        "\n",
        "# Calcular a precisão para o time da casa\n",
        "precision_home = precision_score(y_test_home_binary, y_pred_home_binary)\n",
        "print(f\"Precision Time da Casa: {precision_home}\")\n",
        "\n",
        "# Calcular a precisão para o time visitante\n",
        "precision_away = precision_score(y_test_away_binary, y_pred_away_binary)\n",
        "print(f\"Precision Time Visitante: {precision_away}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4QkXDO6GWHh",
        "outputId": "5b8e1a3f-730c-4a19-e417-1eaa2357c61a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import Lasso\n",
        "import numpy as np\n",
        "\n",
        "# Configurações do Lasso\n",
        "lasso = Lasso(max_iter=10000, random_state=42, alpha=0.01)  # Alpha ajustado\n",
        "\n",
        "# Aplicando Cross Validation\n",
        "# Usamos o scoring de neg_mean_squared_error porque é o inverso do MSE (que o Lasso usa internamente)\n",
        "cv_scores_home = cross_val_score(lasso, X_refined_home, y_home, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_scores_away = cross_val_score(lasso, X_away_refined, y_away, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Calcular o MSE médio com Cross Validation (transformando de negativo para positivo)\n",
        "mse_cv_home = -np.mean(cv_scores_home)\n",
        "mse_cv_away = -np.mean(cv_scores_away)\n",
        "\n",
        "# Printar os resultados\n",
        "print(f\"Time da Casa - Cross Validation MSE médio: {mse_cv_home}\")\n",
        "print(f\"Time Visitante - Cross Validation MSE médio: {mse_cv_away}\")\n",
        "\n",
        "# Treinando o modelo após Cross Validation\n",
        "lasso.fit(X_refined_home, y_home)\n",
        "y_pred_home_cv = lasso.predict(X_refined_home)\n",
        "\n",
        "lasso.fit(X_away_refined, y_away)\n",
        "y_pred_away_cv = lasso.predict(X_away_refined)\n",
        "\n",
        "# Ajustar previsões e evitar valores negativos\n",
        "y_pred_home_cv_final = np.maximum(np.round(y_pred_home_cv), 0)\n",
        "y_pred_away_cv_final = np.maximum(np.round(y_pred_away_cv), 0)\n",
        "\n",
        "# Agora podemos calcular o R² também\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2_home_cv = r2_score(y_home, y_pred_home_cv_final)\n",
        "r2_away_cv = r2_score(y_away, y_pred_away_cv_final)\n",
        "\n",
        "print(f\"Time da Casa - R² após Cross Validation: {r2_home_cv}\")\n",
        "print(f\"Time Visitante - R² após Cross Validation: {r2_away_cv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "736iV2jnHjGc",
        "outputId": "8a022334-8154-4a5c-9c24-5403695e5d6d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Gráfico para o Time da Casa\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test_home, y_pred_home_final, color='red', label='Previsões')\n",
        "plt.plot([y_test_home.min(), y_test_home.max()], [y_test_home.min(), y_test_home.max()], 'k--', lw=2, label=\"Reta de identidade\")\n",
        "plt.title(f'Previsões vs Valores Reais (Time da Casa) - $R^2 = {r2_home:.2f}$')\n",
        "plt.xlabel('Valores Reais')\n",
        "plt.ylabel('Previsões')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Gráfico para o Time Visitante\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(np.expm1(y_test_away_log), y_pred_away_final, color='red', label='Previsões')\n",
        "plt.plot([np.expm1(y_test_away_log).min(), np.expm1(y_test_away_log).max()],\n",
        "         [np.expm1(y_test_away_log).min(), np.expm1(y_test_away_log).max()],\n",
        "         'k--', lw=2, label=\"Reta de identidade\")\n",
        "plt.title(f'Previsões vs Valores Reais (Time Visitante) - $R^2 = {test_r2_away:.2f}$')\n",
        "plt.xlabel('Valores Reais')\n",
        "plt.ylabel('Previsões')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1QNIduiH-AG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Avaliação de Erros Absolutos (MAE)\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# MAE para o time da casa\n",
        "mae_home = mean_absolute_error(y_test_home, y_pred_home_final)\n",
        "print(f\"Time da Casa - MAE: {mae_home}\")\n",
        "\n",
        "# MAE para o time visitante\n",
        "mae_away = mean_absolute_error(np.expm1(y_test_away_log), y_pred_away_final)\n",
        "print(f\"Time Visitante - MAE: {mae_away}\")\n",
        "```\n",
        "\n",
        "**Análise**:\n",
        "- O erro absoluto médio (MAE) para os times da casa e visitantes é calculado para verificar a precisão das previsões em termos de erros médios absolutos.\n",
        "\n",
        "---\n",
        "\n",
        "### Avaliação da Precisão Binária\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Criar variáveis binárias para os valores reais e previstos (gols ou não)\n",
        "y_test_home_binary = (y_test_home > 0).astype(int)\n",
        "y_pred_home_binary = (y_pred_home_final > 0).astype(int)\n",
        "\n",
        "y_test_away_binary = (np.expm1(y_test_away_log) > 0).astype(int)\n",
        "y_pred_away_binary = (y_pred_away_final > 0).astype(int)\n",
        "\n",
        "# Calcular a precisão para o time da casa\n",
        "precision_home = precision_score(y_test_home_binary, y_pred_home_binary)\n",
        "print(f\"Precision Time da Casa: {precision_home}\")\n",
        "\n",
        "# Calcular a precisão para o time visitante\n",
        "precision_away = precision_score(y_test_away_binary, y_pred_away_binary)\n",
        "print(f\"Precision Time Visitante: {precision_away}\")\n",
        "```\n",
        "\n",
        "**Análise**:\n",
        "- Esta célula calcula a precisão para prever corretamente se haverá ou não gols para os times da casa e visitantes.\n",
        "- Avalia a capacidade de distinguir se um time marcará ou não.\n",
        "\n",
        "---\n",
        "\n",
        "### Aplicação de Validação Cruzada e Ajuste do Modelo Lasso\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import Lasso\n",
        "import numpy as np\n",
        "\n",
        "# Configurações do Lasso\n",
        "lasso = Lasso(max_iter=10000, random_state=42, alpha=0.01)  # Alpha ajustado\n",
        "\n",
        "# Aplicando Cross Validation\n",
        "cv_scores_home = cross_val_score(lasso, X_refined_home, y_home, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_scores_away = cross_val_score(lasso, X_away_refined, y_away, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Calcular o MSE médio com Cross Validation (transformando de negativo para positivo)\n",
        "mse_cv_home = np.mean(cv_scores_home)\n",
        "mse_cv_away = np.mean(cv_scores_away)\n",
        "\n",
        "# Imprimir os resultados\n",
        "print(f\"Time da Casa - Cross Validation MSE médio: {mse_cv_home}\")\n",
        "print(f\"Time Visitante - Cross Validation MSE médio: {mse_cv_away}\")\n",
        "```\n",
        "\n",
        "**Análise**:\n",
        "- Essa célula utiliza validação cruzada para verificar a robustez do modelo Lasso.\n",
        "- O Mean Squared Error (MSE) médio é calculado após o cross-validation para ambos os times, ajudando a evitar overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### Previsão de Resultados e Gráficos Comparativos\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Gráfico para o time da casa\n",
        "plt.figure(figsize=[10, 6])\n",
        "plt.scatter(range(len(y_test_home)), y_pred_home_final, color='red', label='Previsões')\n",
        "plt.plot([y_test_home.min(), y_test_home.max()], [y_test_home.min(), y_test_home.max()], 'k--', lw=2, label=\"Reta de identidade\")\n",
        "plt.title(f'Previsões vs Valores Reais (Time da Casa) - $R^2$ = {r2_home:.2f}')\n",
        "plt.xlabel('Valores Reais')\n",
        "plt.ylabel('Previsões')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Gráfico para o time visitante\n",
        "plt.figure(figsize=[10, 6])\n",
        "plt.scatter(range(len(np.expm1(y_test_away_log))), y_pred_away_final, color='red', label='Previsões')\n",
        "plt.plot([np.expm1(y_test_away_log).min(), np.expm1(y_test_away_log).max()], [np.expm1(y_test_away_log).min(), np.expm1(y_test_away_log).max()], 'k--', lw=2, label=\"Reta de identidade\")\n",
        "plt.title(f'Previsões vs Valores Reais (Time Visitante) - $R^2$ = {r2_away:.2f}')\n",
        "plt.xlabel('Valores Reais')\n",
        "plt.ylabel('Previsões')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Análise**:\n",
        "- Esta célula gera gráficos de dispersão que comparam as previsões de gols com os valores reais, tanto para o time da casa quanto para o time visitante.\n",
        "- A linha de identidade (reta preta tracejada) indica a linha perfeita onde previsões exatas se alinhariam.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "RVUhwcWPHjLW",
        "outputId": "fc90c66e-3955-4614-acc9-626d5e782d48"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Features otimizadas para o time da casa (incluir novas features)\n",
        "features_home = [\n",
        "    'total_goal_count',\n",
        "    'home_team_goal_count_half_time',\n",
        "    'home_team_shots_on_target',\n",
        "    'home_ppg',\n",
        "    'team_a_xg',\n",
        "    'home_team_possession',  # Nova feature - posse de bola do time da casa\n",
        "    'home_team_fouls',       # Nova feature - faltas cometidas pelo time da casa\n",
        "    'home_team_shots_off_target',  # Nova feature - chutes fora do alvo\n",
        "]\n",
        "\n",
        "X_refined_home = matches_df_cleaned[features_home]\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "\n",
        "# Verificar se há valores não numéricos e convertê-los para numéricos\n",
        "X_refined_home = X_refined_home.apply(pd.to_numeric, errors='coerce')\n",
        "X_refined_home.fillna(0, inplace=True)\n",
        "\n",
        "# Separar os dados para o time da casa\n",
        "X_train_home, X_test_home, y_train_home, y_test_home = train_test_split(X_refined_home, y_home, test_size=0.2, random_state=42)\n",
        "\n",
        "# GridSearchCV para encontrar o melhor alpha no Lasso para o time da casa\n",
        "param_grid_lasso_home = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5]}\n",
        "lasso_home = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_lasso_home = GridSearchCV(lasso_home, param_grid_lasso_home, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_lasso_home.fit(X_train_home, y_train_home)\n",
        "\n",
        "# Melhor modelo para o time da casa\n",
        "best_lasso_home = grid_search_lasso_home.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time da casa\n",
        "y_pred_home = best_lasso_home.predict(X_test_home)\n",
        "y_pred_home_final = np.maximum(y_pred_home, 0)  # Evitar valores negativos\n",
        "\n",
        "# Métricas para o time da casa\n",
        "mse_home = mean_squared_error(y_test_home, y_pred_home_final)\n",
        "r2_home = r2_score(y_test_home, y_pred_home_final)\n",
        "\n",
        "print(f\"Time da Casa - Melhor Alpha: {grid_search_lasso_home.best_params_['alpha']}\")\n",
        "print(f\"Time da Casa - MSE: {mse_home}, R²: {r2_home}\")\n",
        "\n",
        "# Importância das features\n",
        "importance = permutation_importance(best_lasso_home, X_test_home, y_test_home, n_repeats=10, random_state=42)\n",
        "sorted_idx = importance.importances_mean.argsort()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(np.array(features_home)[sorted_idx], importance.importances_mean[sorted_idx])\n",
        "plt.xlabel('Importância das Features')\n",
        "plt.title('Importância das Features para o Time da Casa')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUa1CgZDf0ex",
        "outputId": "a603f7f6-d282-4015-897f-875ff36f846f"
      },
      "outputs": [],
      "source": [
        "# Selecionar apenas colunas numéricas\n",
        "numeric_columns = matches_df_cleaned.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Substituir valores nulos pela média da coluna apenas nas colunas numéricas\n",
        "matches_df_cleaned[numeric_columns].fillna(matches_df_cleaned[numeric_columns].mean(), inplace=True)\n",
        "\n",
        "# Verificar novamente se os valores nulos foram preenchidos\n",
        "print(matches_df_cleaned.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rPJkoaL0Tian",
        "outputId": "caea767a-c4a0-4c3d-f654-bfae07b70dfd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Exibir box plot para verificar outliers em gols do time da casa\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=matches_df_cleaned['home_team_goal_count'])\n",
        "plt.title('Box Plot - Gols do Time da Casa')\n",
        "plt.show()\n",
        "\n",
        "# Exibir box plot para verificar outliers em gols do time visitante\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=matches_df_cleaned['away_team_goal_count'])\n",
        "plt.title('Box Plot - Gols do Time Visitante')\n",
        "plt.show()\n",
        "\n",
        "# Função para remover outliers usando z-score (limite de 3)\n",
        "def remove_outliers_zscore(df, column, threshold=3):\n",
        "    z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())\n",
        "    return df[z_scores < threshold]\n",
        "\n",
        "# Remover outliers das colunas de gols\n",
        "matches_df_cleaned = remove_outliers_zscore(matches_df_cleaned, 'home_team_goal_count')\n",
        "matches_df_cleaned = remove_outliers_zscore(matches_df_cleaned, 'away_team_goal_count')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18pM4hOiI63R"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Análise de Previsões e Importância das Features\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Features otimizadas para o time da casa (incluir novas features)\n",
        "features_home = [\n",
        "    'total_goal_count',\n",
        "    'home_team_goal_count_half_time',\n",
        "    'home_team_shots_on_target',\n",
        "    'home_ppg',\n",
        "    'team_a_xg',\n",
        "    'home_team_possession', # Nova feature - posse de bola do time da casa\n",
        "    'home_team_fouls', # Nova feature - faltas cometidas pelo time da casa\n",
        "    'home_team_shots_off_target' # Nova feature - chutes fora do alvo\n",
        "]\n",
        "\n",
        "X_refined_home = matches_df_cleaned[features_home]\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "\n",
        "# Verificar se há valores não numéricos e convertê-los para numéricos\n",
        "X_refined_home = X_refined_home.apply(pd.to_numeric, errors='coerce')\n",
        "X_refined_home.fillna(0, inplace=True)\n",
        "\n",
        "# Separar os dados para o time da casa\n",
        "X_train_home, X_test_home, y_train_home, y_test_home = train_test_split(X_refined_home, y_home, test_size=0.2, random_state=42)\n",
        "\n",
        "# GridSearchCV para encontrar o melhor alpha no Lasso para o time da casa\n",
        "param_grid_lasso_home = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5]}\n",
        "lasso_home = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_lasso_home = GridSearchCV(lasso_home, param_grid_lasso_home, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_lasso_home.fit(X_train_home, y_train_home)\n",
        "\n",
        "# Melhor modelo para o time da casa\n",
        "best_lasso_home = grid_search_lasso_home.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time da casa\n",
        "y_pred_home = best_lasso_home.predict(X_test_home)\n",
        "y_pred_home_final = np.maximum(y_pred_home, 0)  # Evitar valores negativos\n",
        "\n",
        "# Métricas para o time da casa\n",
        "mse_home = mean_squared_error(y_test_home, y_pred_home_final)\n",
        "r2_home = r2_score(y_test_home, y_pred_home_final)\n",
        "\n",
        "print(f\"Time da Casa - Melhor Alpha: {grid_search_lasso_home.best_params_['alpha']}\")\n",
        "print(f\"Time da Casa - MSE: {mse_home}, R²: {r2_home}\")\n",
        "\n",
        "# Importância das features\n",
        "importance = permutation_importance(best_lasso_home, X_test_home, y_test_home, n_repeats=10, random_state=42)\n",
        "sorted_idx = importance.importances_mean.argsort()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(np.array(features_home)[sorted_idx], importance.importances_mean[sorted_idx])\n",
        "plt.xlabel('Importância das Features')\n",
        "plt.title('Importância das Features para o Time da Casa')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "- **Descrição**: Essa célula ajusta o modelo Lasso para o time da casa, utilizando um conjunto de features otimizadas e novas adições, como posse de bola e faltas. Ela realiza a previsão dos gols, calcula as métricas MSE e R², e, por fim, exibe um gráfico de importância das features baseado na permutação de valores.\n",
        "\n",
        "---\n",
        "\n",
        "### Limpeza de Dados Numéricos\n",
        "\n",
        "```python\n",
        "# Selecionar apenas colunas numéricas\n",
        "numeric_columns = matches_df_cleaned.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Substituir valores nulos pela média da coluna apenas nas colunas numéricas\n",
        "matches_df_cleaned[numeric_columns].fillna(matches_df_cleaned[numeric_columns].mean(), inplace=True)\n",
        "\n",
        "# Verificar novamente se os valores nulos foram preenchidos\n",
        "print(matches_df_cleaned.isnull().sum())\n",
        "```\n",
        "\n",
        "- **Descrição**: Esta célula seleciona todas as colunas numéricas do dataset e preenche os valores nulos com a média dessas colunas. Depois, realiza uma verificação para garantir que todos os valores foram preenchidos corretamente.\n",
        "\n",
        "---\n",
        "\n",
        "### Detecção e Remoção de Outliers\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Exibir box plot para verificar outliers em gols do time da casa\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=matches_df_cleaned['home_team_goal_count'])\n",
        "plt.title('Box Plot - Gols do Time da Casa')\n",
        "plt.show()\n",
        "\n",
        "# Exibir box plot para verificar outliers em gols do time visitante\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=matches_df_cleaned['away_team_goal_count'])\n",
        "plt.title('Box Plot - Gols do Time Visitante')\n",
        "plt.show()\n",
        "\n",
        "# Função para remover outliers usando Z-score (limite de 3)\n",
        "def remove_outliers_zscore(df, column, threshold=3):\n",
        "    z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())\n",
        "    return df[z_scores < threshold]\n",
        "\n",
        "# Remover outliers das colunas de gols\n",
        "matches_df_cleaned = remove_outliers_zscore(matches_df_cleaned, 'home_team_goal_count')\n",
        "matches_df_cleaned = remove_outliers_zscore(matches_df_cleaned, 'away_team_goal_count')\n",
        "```\n",
        "\n",
        "- **Descrição**: Esta célula exibe os outliers nos dados de gols por meio de box plots e implementa uma função de remoção de outliers com base no Z-score (limite de 3 desvios-padrão). Após a detecção, os outliers são removidos para melhorar a qualidade dos dados.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5c4_dqOet8o"
      },
      "outputs": [],
      "source": [
        "# Criar uma nova feature de diferença de gols em casa e fora em jogos anteriores\n",
        "matches_df_cleaned['home_goal_diff'] = matches_df_cleaned['home_team_goal_count'] - matches_df_cleaned['away_team_goal_count']\n",
        "matches_df_cleaned['away_goal_diff'] = matches_df_cleaned['away_team_goal_count'] - matches_df_cleaned['home_team_goal_count']\n",
        "\n",
        "# Criar uma nova feature de taxa de conversão de chutes (gols/chutes a gol)\n",
        "matches_df_cleaned['home_shot_conversion'] = matches_df_cleaned['home_team_goal_count'] / matches_df_cleaned['home_team_shots_on_target'].replace(0, 1)\n",
        "matches_df_cleaned['away_shot_conversion'] = matches_df_cleaned['away_team_goal_count'] / matches_df_cleaned['away_team_shots_on_target'].replace(0, 1)\n",
        "\n",
        "# Criar uma nova feature de desempenho recente (últimos 5 jogos)\n",
        "matches_df_cleaned['home_recent_form'] = matches_df_cleaned['home_team_goal_count'].rolling(window=5).mean().fillna(0)\n",
        "matches_df_cleaned['away_recent_form'] = matches_df_cleaned['away_team_goal_count'].rolling(window=5).mean().fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP_ci1Sget-w",
        "outputId": "c6228f15-6857-488a-d292-2592e01e56a1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Features separadas para o time da casa e visitante\n",
        "features_home = [\n",
        "    'home_goal_diff', 'home_shot_conversion', 'home_recent_form',\n",
        "    'home_ppg', 'home_team_shots_on_target'\n",
        "]\n",
        "features_away = [\n",
        "    'away_goal_diff', 'away_shot_conversion', 'away_recent_form',\n",
        "    'away_ppg', 'away_team_shots_on_target'\n",
        "]\n",
        "\n",
        "# Separando os dados\n",
        "X_home = matches_df_cleaned[features_home]\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "\n",
        "X_away = matches_df_cleaned[features_away]\n",
        "y_away = matches_df_cleaned['away_team_goal_count']\n",
        "\n",
        "# Dividir os dados em treino e teste\n",
        "X_train_home, X_test_home, y_train_home, y_test_home = train_test_split(X_home, y_home, test_size=0.2, random_state=42)\n",
        "X_train_away, X_test_away, y_train_away, y_test_away = train_test_split(X_away, y_away, test_size=0.2, random_state=42)\n",
        "\n",
        "# GridSearchCV para encontrar o melhor alpha no Lasso para o time da casa\n",
        "param_grid_lasso_home = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5]}\n",
        "lasso_home = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_lasso_home = GridSearchCV(lasso_home, param_grid_lasso_home, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_lasso_home.fit(X_train_home, y_train_home)\n",
        "\n",
        "# Melhor modelo para o time da casa\n",
        "best_lasso_home = grid_search_lasso_home.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time da casa\n",
        "y_pred_home = best_lasso_home.predict(X_test_home)\n",
        "\n",
        "# Métricas para o time da casa\n",
        "mse_home = mean_squared_error(y_test_home, y_pred_home)\n",
        "r2_home = r2_score(y_test_home, y_pred_home)\n",
        "\n",
        "print(f\"Time da Casa - MSE: {mse_home}, R²: {r2_home}\")\n",
        "\n",
        "# Repetir o processo para o time visitante\n",
        "param_grid_lasso_away = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5]}\n",
        "lasso_away = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_lasso_away = GridSearchCV(lasso_away, param_grid_lasso_away, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_lasso_away.fit(X_train_away, y_train_away)\n",
        "\n",
        "# Melhor modelo para o time visitante\n",
        "best_lasso_away = grid_search_lasso_away.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time visitante\n",
        "y_pred_away = best_lasso_away.predict(X_test_away)\n",
        "\n",
        "# Métricas para o time visitante\n",
        "mse_away = mean_squared_error(y_test_away, y_pred_away)\n",
        "r2_away = r2_score(y_test_away, y_pred_away)\n",
        "\n",
        "print(f\"Time Visitante - MSE: {mse_away}, R²: {r2_away}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qilnJcf6dEHt",
        "outputId": "619baf64-619f-4aea-e36a-56f837e976f5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Gráfico para o time da casa\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(range(len(y_test_home)), y_test_home, color='blue', label='Valores Reais Time da Casa')\n",
        "plt.scatter(range(len(y_pred_home)), y_pred_home, color='red', label='Previsões Time da Casa')\n",
        "plt.title('Previsões vs Valores Reais (Time da Casa)')\n",
        "plt.xlabel('Índice de Jogos')\n",
        "plt.ylabel('Número de Gols')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Gráfico para o time visitante\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(range(len(y_test_away)), y_test_away, color='blue', label='Valores Reais Time Visitante')\n",
        "plt.scatter(range(len(y_pred_away)), y_pred_away, color='red', label='Previsões Time Visitante')\n",
        "plt.title('Previsões vs Valores Reais (Time Visitante)')\n",
        "plt.xlabel('Índice de Jogos')\n",
        "plt.ylabel('Número de Gols')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tzsnHbA2kRce",
        "outputId": "330e066e-d2f3-4c33-f9ae-2669419d5585"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Features separadas para o time da casa e visitante\n",
        "features_home = [\n",
        "    'home_goal_diff', 'home_shot_conversion', 'home_recent_form',\n",
        "    'home_ppg', 'home_team_shots_on_target'\n",
        "]\n",
        "features_away = [\n",
        "    'away_goal_diff', 'away_shot_conversion', 'away_recent_form',\n",
        "    'away_ppg', 'away_team_shots_on_target'\n",
        "]\n",
        "\n",
        "# Separar os dados\n",
        "X_home = matches_df_cleaned[features_home]\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "\n",
        "X_away = matches_df_cleaned[features_away]\n",
        "y_away = matches_df_cleaned['away_team_goal_count']\n",
        "\n",
        "# Dividir os dados em treino e teste\n",
        "X_train_home, X_test_home, y_train_home, y_test_home = train_test_split(X_home, y_home, test_size=0.2, random_state=42)\n",
        "X_train_away, X_test_away, y_train_away, y_test_away = train_test_split(X_away, y_away, test_size=0.2, random_state=42)\n",
        "\n",
        "# Função para exibir resultados de validação cruzada e resíduos\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test, team_label):\n",
        "    # Validação cruzada\n",
        "    mse_scorer = make_scorer(mean_squared_error)\n",
        "    cv_mse_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=mse_scorer)\n",
        "    cv_r2_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
        "\n",
        "    # Ajustar o modelo e fazer previsões\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Métricas\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Exibir resultados\n",
        "    print(f\"{team_label} - MSE médio (Cross Validation): {np.mean(cv_mse_scores)}\")\n",
        "    print(f\"{team_label} - R² médio (Cross Validation): {np.mean(cv_r2_scores)}\")\n",
        "    print(f\"{team_label} - MSE: {mse}, R²: {r2}\")\n",
        "\n",
        "    # Gráfico de resíduos\n",
        "    residuals = y_test - y_pred\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(range(len(residuals)), residuals, color='purple')\n",
        "    plt.axhline(0, color='black', linestyle='--')\n",
        "    plt.title(f'Resíduos - {team_label}')\n",
        "    plt.xlabel('Índice')\n",
        "    plt.ylabel('Erro (Resíduo)')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Modelo para o time da casa\n",
        "lasso_home = Lasso(alpha=0.01, max_iter=10000, random_state=42)\n",
        "evaluate_model(lasso_home, X_train_home, y_train_home, X_test_home, y_test_home, \"Time da Casa\")\n",
        "\n",
        "# Modelo para o time visitante\n",
        "lasso_away = Lasso(alpha=0.01, max_iter=10000, random_state=42)\n",
        "evaluate_model(lasso_away, X_train_away, y_train_away, X_test_away, y_test_away, \"Time Visitante\")\n",
        "\n",
        "# Importância das features para o time da casa\n",
        "importance_home = np.abs(lasso_home.coef_)\n",
        "sorted_indices_home = np.argsort(importance_home)[::-1]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(X_train_home.columns[sorted_indices_home], importance_home[sorted_indices_home], color='blue')\n",
        "plt.xlabel(\"Importância das Features\")\n",
        "plt.title(\"Importância das Features para o Time da Casa\")\n",
        "plt.show()\n",
        "\n",
        "# Importância das features para o time visitante\n",
        "importance_away = np.abs(lasso_away.coef_)\n",
        "sorted_indices_away = np.argsort(importance_away)[::-1]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(X_train_away.columns[sorted_indices_away], importance_away[sorted_indices_away], color='green')\n",
        "plt.xlabel(\"Importância das Features\")\n",
        "plt.title(\"Importância das Features para o Time Visitante\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sCBUMJwMNHX"
      },
      "source": [
        "---\n",
        "\n",
        "### Célula 1: **Treinamento do Modelo Lasso com GridSearchCV para o Time da Casa**\n",
        "\n",
        "**Descrição:**\n",
        "Esta célula realiza o treinamento do modelo Lasso com GridSearchCV para o time da casa. As features escolhidas incluem a diferença de gols no primeiro tempo, chutes ao alvo e posse de bola, entre outras. O modelo é treinado após a divisão dos dados em treino e teste, e o melhor valor de alpha é selecionado usando a técnica de GridSearchCV. A célula também inclui o cálculo de métricas como MSE e R², além da plotagem da importância das features para o modelo.\n",
        "\n",
        "**Análise:**\n",
        "- O uso de **GridSearchCV** para otimizar o hiperparâmetro alpha do Lasso é um bom ponto de partida para garantir que o modelo não esteja nem subajustando nem sobreajustando.\n",
        "- As features selecionadas são relevantes para prever o número de gols do time da casa, como posse de bola e chutes ao alvo, que têm uma correlação direta com o desempenho ofensivo.\n",
        "- O gráfico de **importância das features** é fundamental para entender quais variáveis estão contribuindo mais para o desempenho do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### Célula 2: **Seleção de Colunas Numéricas e Tratamento de Nulos**\n",
        "\n",
        "**Descrição:**\n",
        "Nesta célula, as colunas numéricas do DataFrame são selecionadas e os valores nulos são substituídos pela média da coluna correspondente. Além disso, são gerados gráficos de boxplot para identificar possíveis outliers nas colunas de gols dos times. Posteriormente, uma função é implementada para remover outliers usando Z-score.\n",
        "\n",
        "**Análise:**\n",
        "- O processo de **preenchimento de valores nulos** com a média é uma abordagem eficiente quando os valores ausentes são esparsos, mas deve-se tomar cuidado ao analisar o impacto no desempenho do modelo.\n",
        "- A visualização por **boxplots** é importante para identificar outliers que possam distorcer o desempenho do modelo.\n",
        "- O uso do **Z-score** para remover outliers ajuda a melhorar a qualidade dos dados de treino, eliminando valores atípicos que podem interferir nas previsões.\n",
        "\n",
        "---\n",
        "\n",
        "### Célula 3: **Treinamento e Previsões com Novas Features para o Time da Casa e Visitante**\n",
        "\n",
        "**Descrição:**\n",
        "Essa célula introduz features novas, como a taxa de conversão de chutes em gols e o desempenho recente dos times nos últimos 5 jogos. O modelo Lasso é novamente ajustado para ambos os times (casa e visitante), usando GridSearchCV para otimizar o valor de alpha.\n",
        "\n",
        "**Análise:**\n",
        "- A inclusão de novas features, como a **taxa de conversão de chutes em gols**, traz insights adicionais para o modelo. Esses fatores são críticos no desempenho de um time em campo.\n",
        "- A divisão de treino e teste e o uso de **validação cruzada** garantem que o modelo seja avaliado de maneira robusta e menos suscetível a overfitting.\n",
        "- As previsões para o time visitante mostraram-se particularmente boas, com um **R² elevado**, sugerindo que o modelo está capturando bem a dinâmica dos jogos do visitante.\n",
        "\n",
        "---\n",
        "\n",
        "### Célula 4: **Visualização de Resultados e Avaliação do Modelo**\n",
        "\n",
        "**Descrição:**\n",
        "Essa célula é responsável por gerar os gráficos de dispersão que comparam os valores reais com os previstos para o time da casa e visitante. Além disso, são exibidas as métricas de desempenho como MSE e R².\n",
        "\n",
        "**Análise:**\n",
        "- Os gráficos de **valores previstos versus valores reais** são essenciais para avaliar visualmente o desempenho do modelo. A proximidade dos pontos com a linha de identidade (reta) indica a precisão das previsões.\n",
        "- Embora o modelo para o time da casa apresente um **R² razoável** (cerca de 0.70), o time visitante se sai melhor, com um R² em torno de 0.85, indicando que o modelo lida de forma mais eficaz com os dados dos visitantes.\n",
        "\n",
        "---\n",
        "\n",
        "### Célula 5: **Treinamento com Validação Cruzada e Importância das Features**\n",
        "\n",
        "**Descrição:**\n",
        "Aqui, os modelos para ambos os times são treinados com **validação cruzada** e os gráficos de resíduos são plotados. Também é feita a análise da importância das features.\n",
        "\n",
        "**Análise:**\n",
        "- A inclusão da **validação cruzada** com 5 folds é um ponto positivo, pois garante que o modelo esteja generalizando bem e evita o overfitting.\n",
        "- O gráfico de **resíduos** é importante para verificar se há padrões ou tendências nos erros de previsão. Um bom modelo deve ter resíduos distribuídos de maneira aleatória.\n",
        "- A análise da **importância das features** permite identificar quais variáveis têm maior peso nas previsões e, assim, ajustar ou refinar o modelo conforme necessário.\n",
        "\n",
        "---\n",
        "\n",
        "### Célula 6: **Finalização do Modelo com Novas Features e Visualização de Importância**\n",
        "\n",
        "**Descrição:**\n",
        "Nesta célula, o processo final de ajuste de features é implementado. As novas variáveis são aplicadas no modelo e os gráficos de importância das features são plotados, tanto para o time da casa quanto para o visitante.\n",
        "\n",
        "**Análise:**\n",
        "- A **adição de novas variáveis**, como \"chutes fora do alvo\", contribui para melhorar a acurácia do modelo, trazendo um contexto mais amplo sobre o desempenho do time.\n",
        "- Os gráficos de **importância das features** são úteis para ajustar o foco do modelo nas variáveis que realmente impactam as previsões. Features como \"home_team_goal_count_half_time\" e \"total_goal_count\" continuam a ser cruciais para as previsões.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDToEs2ox55P"
      },
      "outputs": [],
      "source": [
        "matches_df_cleaned['home_team_shot_conversion'] = matches_df_cleaned['home_team_goal_count'] / matches_df_cleaned['home_team_shots_on_target']\n",
        "matches_df_cleaned['away_team_shot_conversion'] = matches_df_cleaned['away_team_goal_count'] / matches_df_cleaned['away_team_shots_on_target']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "id": "kaTPUBhMoG9L",
        "outputId": "144fa0ab-d0cb-49e7-cd71-48c3fa804a89"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Atualizar as features incluindo novas métricas de desempenho\n",
        "features_home = [\n",
        "    'home_goal_diff', 'home_shot_conversion', 'home_recent_form',\n",
        "    'home_ppg', 'home_team_shots_on_target', 'home_team_corner_count',\n",
        "    'home_team_possession', 'home_team_fouls', 'home_team_yellow_cards',\n",
        "]\n",
        "\n",
        "features_away = [\n",
        "    'away_goal_diff', 'away_shot_conversion', 'away_recent_form',\n",
        "    'away_ppg', 'away_team_shots_on_target', 'away_team_corner_count',\n",
        "    'away_team_possession', 'away_team_fouls', 'away_team_yellow_cards',\n",
        "]\n",
        "\n",
        "# Separando os dados\n",
        "X_home = matches_df_cleaned[features_home]\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "\n",
        "X_away = matches_df_cleaned[features_away]\n",
        "y_away = matches_df_cleaned['away_team_goal_count']\n",
        "\n",
        "# Dividir os dados em treino e teste\n",
        "X_train_home, X_test_home, y_train_home, y_test_home = train_test_split(X_home, y_home, test_size=0.2, random_state=42)\n",
        "X_train_away, X_test_away, y_train_away, y_test_away = train_test_split(X_away, y_away, test_size=0.2, random_state=42)\n",
        "\n",
        "# GridSearchCV para encontrar o melhor alpha no Lasso para o time da casa\n",
        "param_grid_lasso_home = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5]}\n",
        "lasso_home = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_lasso_home = GridSearchCV(lasso_home, param_grid_lasso_home, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_lasso_home.fit(X_train_home, y_train_home)\n",
        "\n",
        "# Melhor modelo para o time da casa\n",
        "best_lasso_home = grid_search_lasso_home.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time da casa\n",
        "y_pred_home = best_lasso_home.predict(X_test_home)\n",
        "\n",
        "# Métricas para o time da casa\n",
        "mse_home = mean_squared_error(y_test_home, y_pred_home)\n",
        "r2_home = r2_score(y_test_home, y_pred_home)\n",
        "\n",
        "print(f\"Time da Casa - MSE: {mse_home}, R²: {r2_home}\")\n",
        "\n",
        "# Repetir o processo para o time visitante\n",
        "param_grid_lasso_away = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5]}\n",
        "lasso_away = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_lasso_away = GridSearchCV(lasso_away, param_grid_lasso_away, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_lasso_away.fit(X_train_away, y_train_away)\n",
        "\n",
        "# Melhor modelo para o time visitante\n",
        "best_lasso_away = grid_search_lasso_away.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time visitante\n",
        "y_pred_away = best_lasso_away.predict(X_test_away)\n",
        "\n",
        "# Métricas para o time visitante\n",
        "mse_away = mean_squared_error(y_test_away, y_pred_away)\n",
        "r2_away = r2_score(y_test_away, y_pred_away)\n",
        "\n",
        "print(f\"Time Visitante - MSE: {mse_away}, R²: {r2_away}\")\n",
        "\n",
        "# Passo 2: Verificação de outliers\n",
        "# Plotando novamente os boxplots para revisar outliers\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.boxplot(y_home)\n",
        "plt.title('Box Plot - Gols do Time da Casa')\n",
        "plt.ylabel('home_team_goal_count')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.boxplot(y_away)\n",
        "plt.title('Box Plot - Gols do Time Visitante')\n",
        "plt.ylabel('away_team_goal_count')\n",
        "plt.show()\n",
        "\n",
        "# Passo 3: Teste de outras abordagens de validação cruzada (10-fold)\n",
        "mse_scorer = make_scorer(mean_squared_error)\n",
        "\n",
        "# Aplicar a validação cruzada para o Time da Casa com 10 folds\n",
        "cv_mse_scores_home = cross_val_score(lasso_home, X_home, y_home, cv=10, scoring=mse_scorer)\n",
        "cv_r2_scores_home = cross_val_score(lasso_home, X_home, y_home, cv=10, scoring='r2')\n",
        "\n",
        "# Resultados Time da Casa com 10-fold\n",
        "print(f\"Time da Casa - MSE médio (Cross Validation): {np.mean(cv_mse_scores_home)}\")\n",
        "print(f\"Time da Casa - R² médio (Cross Validation): {np.mean(cv_r2_scores_home)}\")\n",
        "\n",
        "# Aplicar a validação cruzada para o Time Visitante com 10 folds\n",
        "cv_mse_scores_away = cross_val_score(lasso_away, X_away, y_away, cv=10, scoring=mse_scorer)\n",
        "cv_r2_scores_away = cross_val_score(lasso_away, X_away, y_away, cv=10, scoring='r2')\n",
        "\n",
        "# Resultados Time Visitante com 10-fold\n",
        "print(f\"Time Visitante - MSE médio (Cross Validation): {np.mean(cv_mse_scores_away)}\")\n",
        "print(f\"Time Visitante - R² médio (Cross Validation): {np.mean(cv_r2_scores_away)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Duo3Zf1wxlI5"
      },
      "outputs": [],
      "source": [
        "# Nova feature: diferença de posse de bola entre os dois times\n",
        "matches_df_cleaned['possession_diff'] = matches_df_cleaned['home_team_possession'] - matches_df_cleaned['away_team_possession']\n",
        "\n",
        "# Nova feature: soma de faltas e cartões para capturar indisciplina\n",
        "matches_df_cleaned['home_discipline'] = matches_df_cleaned['home_team_fouls'] + matches_df_cleaned['home_team_yellow_cards']\n",
        "matches_df_cleaned['away_discipline'] = matches_df_cleaned['away_team_fouls'] + matches_df_cleaned['away_team_yellow_cards']\n",
        "\n",
        "# Nova feature: soma de chutes a gol e posse de bola como proxy para pressão ofensiva\n",
        "matches_df_cleaned['home_offensive_pressure'] = matches_df_cleaned['home_team_shots_on_target'] + matches_df_cleaned['home_team_possession']\n",
        "matches_df_cleaned['away_offensive_pressure'] = matches_df_cleaned['away_team_shots_on_target'] + matches_df_cleaned['away_team_possession']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAxPpmntxlLQ",
        "outputId": "4163e2d6-0339-43d5-803b-ee38123326bd"
      },
      "outputs": [],
      "source": [
        "# Features atualizadas para o time da casa e visitante\n",
        "features_home = [\n",
        "    'home_goal_diff', 'home_shot_conversion', 'home_recent_form', 'home_ppg',\n",
        "    'home_team_shots_on_target', 'home_offensive_pressure', 'home_discipline', 'possession_diff'\n",
        "]\n",
        "\n",
        "features_away = [\n",
        "    'away_goal_diff', 'away_shot_conversion', 'away_recent_form', 'away_ppg',\n",
        "    'away_team_shots_on_target', 'away_offensive_pressure', 'away_discipline', 'possession_diff'\n",
        "]\n",
        "\n",
        "# Separando os dados\n",
        "X_home = matches_df_cleaned[features_home]\n",
        "y_home = matches_df_cleaned['home_team_goal_count']\n",
        "\n",
        "X_away = matches_df_cleaned[features_away]\n",
        "y_away = matches_df_cleaned['away_team_goal_count']\n",
        "\n",
        "# Dividir os dados em treino e teste\n",
        "X_train_home, X_test_home, y_train_home, y_test_home = train_test_split(X_home, y_home, test_size=0.2, random_state=42)\n",
        "X_train_away, X_test_away, y_train_away, y_test_away = train_test_split(X_away, y_away, test_size=0.2, random_state=42)\n",
        "\n",
        "# GridSearchCV para encontrar o melhor alpha no Lasso\n",
        "param_grid_lasso_home = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5]}\n",
        "lasso_home = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_lasso_home = GridSearchCV(lasso_home, param_grid_lasso_home, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_lasso_home.fit(X_train_home, y_train_home)\n",
        "\n",
        "# Melhor modelo para o time da casa\n",
        "best_lasso_home = grid_search_lasso_home.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time da casa\n",
        "y_pred_home = best_lasso_home.predict(X_test_home)\n",
        "\n",
        "# Métricas para o time da casa\n",
        "mse_home = mean_squared_error(y_test_home, y_pred_home)\n",
        "r2_home = r2_score(y_test_home, y_pred_home)\n",
        "\n",
        "print(f\"Time da Casa - MSE: {mse_home}, R²: {r2_home}\")\n",
        "\n",
        "# Repetir para o time visitante\n",
        "param_grid_lasso_away = {'alpha': [0.01, 0.03, 0.05, 0.1, 0.5]}\n",
        "lasso_away = Lasso(max_iter=10000, random_state=42)\n",
        "grid_search_lasso_away = GridSearchCV(lasso_away, param_grid_lasso_away, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_lasso_away.fit(X_train_away, y_train_away)\n",
        "\n",
        "# Melhor modelo para o time visitante\n",
        "best_lasso_away = grid_search_lasso_away.best_estimator_\n",
        "\n",
        "# Previsão dos gols do time visitante\n",
        "y_pred_away = best_lasso_away.predict(X_test_away)\n",
        "\n",
        "# Métricas para o time visitante\n",
        "mse_away = mean_squared_error(y_test_away, y_pred_away)\n",
        "r2_away = r2_score(y_test_away, y_pred_away)\n",
        "\n",
        "print(f\"Time Visitante - MSE: {mse_away}, R²: {r2_away}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWWnC4eHkRjn",
        "outputId": "5890c4c3-a341-4f5f-cbe5-7616e8c00310"
      },
      "outputs": [],
      "source": [
        "# Prever os placares para os jogos de teste\n",
        "y_pred_home_final = best_lasso_home.predict(X_test_home)\n",
        "y_pred_away_final = best_lasso_away.predict(X_test_away)\n",
        "\n",
        "# Arredondar os resultados para evitar valores decimais nos gols\n",
        "y_pred_home_final = np.maximum(np.round(y_pred_home_final), 0)  # Garantir que não haja gols negativos\n",
        "y_pred_away_final = np.maximum(np.round(y_pred_away_final), 0)\n",
        "\n",
        "# Imprimir os placares previstos\n",
        "for i in range(len(y_pred_home_final)):\n",
        "    print(f\"Placar Final: Time da Casa {y_pred_home_final[i]} x {y_pred_away_final[i]} Time Visitante\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWzNF2lZMyIg"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Seção 1: Criação de Features Derivadas\n",
        "Nesta célula, criamos **novas features** para os times da casa e visitante, baseadas em dados brutos existentes, como:\n",
        "- `home_goal_diff` e `away_goal_diff`: diferença de gols em partidas anteriores.\n",
        "- `home_shot_conversion` e `away_shot_conversion`: taxa de conversão de chutes a gol.\n",
        "- `home_recent_form` e `away_recent_form`: forma recente do time (média dos últimos 5 jogos).\n",
        "\n",
        "Essas features foram incluídas para enriquecer o modelo com variáveis que possam capturar a tendência de desempenho recente e conversão de finalizações em gols.\n",
        "\n",
        "---\n",
        "\n",
        "### Seção 2: Treinamento e Avaliação do Modelo com Lasso\n",
        "Nesta célula, fazemos a separação dos dados de treino e teste para **time da casa** e **time visitante**. Em seguida, utilizamos o **GridSearchCV** para otimizar o valor do parâmetro `alpha` no modelo de regressão Lasso, buscando o melhor ajuste possível para prever o número de gols de cada time.\n",
        "\n",
        "Os principais passos são:\n",
        "1. Separação dos dados em treino e teste.\n",
        "2. Aplicação do **GridSearchCV** para encontrar o melhor valor de `alpha`.\n",
        "3. Avaliação do modelo para o time da casa e visitante, com o cálculo das métricas **MSE** e **R²**.\n",
        "\n",
        "**Resultado**:\n",
        "- Time da Casa: `MSE` = 0.22248, `R²` = 0.70586\n",
        "- Time Visitante: `MSE` = 0.13496, `R²` = 0.85885\n",
        "\n",
        "---\n",
        "\n",
        "### Seção 3: Visualização dos Resultados de Previsão\n",
        "Aqui, visualizamos as previsões do modelo Lasso comparando os **valores reais** e **valores previstos** para os gols dos times da casa e visitante. Isso foi feito usando gráficos de dispersão, o que permite identificar se as previsões seguem de perto os valores reais dos gols.\n",
        "\n",
        "Essa visualização é crucial para verificar visualmente o desempenho do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### Seção 4: Ajustes Finais e Previsão dos Placares\n",
        "Na última parte, aplicamos o modelo para prever os placares dos jogos de teste. Também garantimos que não haja valores negativos ou com muitos decimais nos gols previstos, arredondando-os para inteiros.\n",
        "\n",
        "Após isso, os resultados dos **placares finais** foram impressos, mostrando os gols previstos para o time da casa e visitante em cada jogo.\n",
        "\n",
        "**Resultado**:\n",
        "Impressão dos placares previstos para cada jogo, o que representa a funcionalidade principal de previsão de resultados do modelo.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "nqGq2XWEb6gO",
        "outputId": "7b79af74-c055-4afe-eeaa-f20433320b6e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd  # Certifique-se de ter importado o pandas\n",
        "\n",
        "# Função auxiliar para garantir que temos um array numpy\n",
        "def to_numpy_array(data):\n",
        "    if isinstance(data, pd.Series):\n",
        "        return data.to_numpy()\n",
        "    elif isinstance(data, np.ndarray):\n",
        "        return data\n",
        "    else:\n",
        "        return np.array(data)\n",
        "\n",
        "# Converter as variáveis para arrays numpy\n",
        "y_test_home_array = to_numpy_array(y_test_home)\n",
        "y_pred_home_array = to_numpy_array(y_pred_home_final)\n",
        "\n",
        "y_test_away_array = to_numpy_array(y_test_away)\n",
        "y_pred_away_array = to_numpy_array(y_pred_away_final)\n",
        "\n",
        "# Encontrar índices onde a previsão é igual ao valor real para o time da casa\n",
        "indices_acertos_home = [i for i in range(len(y_test_home_array)) if y_test_home_array[i] == y_pred_home_array[i]]\n",
        "\n",
        "# Encontrar índices onde a previsão é igual ao valor real para o time visitante\n",
        "indices_acertos_away = [i for i in range(len(y_test_away_array)) if y_test_away_array[i] == y_pred_away_array[i]]\n",
        "\n",
        "# Criar uma figura com dois subplots lado a lado\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Primeiro subplot: Time da Casa\n",
        "axs[0].scatter(range(len(y_test_home_array)), y_test_home_array, color='blue', marker='o', label='Valor Real', alpha=0.6)\n",
        "axs[0].scatter(range(len(y_pred_home_array)), y_pred_home_array, color='red', marker='x', label='Previsão', alpha=0.6)\n",
        "# Destacar previsões assertivas\n",
        "axs[0].scatter(indices_acertos_home, [y_test_home_array[i] for i in indices_acertos_home], color='gold', marker='*', s=100, label='Previsão Assertiva')\n",
        "\n",
        "axs[0].set_title('Previsões vs Valores Reais (Time da Casa)')\n",
        "axs[0].set_xlabel('Índice dos Jogos')\n",
        "axs[0].set_ylabel('Número de Gols')\n",
        "# Legenda explicando a sobreposição\n",
        "axs[0].legend(loc='upper right', title=\"Legenda:\\nO = Valor Real\\nX = Previsão\\n* = Previsão Assertiva\")\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Segundo subplot: Time Visitante\n",
        "axs[1].scatter(range(len(y_test_away_array)), y_test_away_array, color='green', marker='o', label='Valor Real', alpha=0.6)\n",
        "axs[1].scatter(range(len(y_pred_away_array)), y_pred_away_array, color='purple', marker='x', label='Previsão', alpha=0.6)\n",
        "# Destacar previsões assertivas\n",
        "axs[1].scatter(indices_acertos_away, [y_test_away_array[i] for i in indices_acertos_away], color='gold', marker='*', s=100, label='Previsão Assertiva')\n",
        "\n",
        "axs[1].set_title('Previsões vs Valores Reais (Time Visitante)')\n",
        "axs[1].set_xlabel('Índice dos Jogos')\n",
        "axs[1].set_ylabel('Número de Gols')\n",
        "# Legenda explicando a sobreposição\n",
        "axs[1].legend(loc='upper right', title=\"Legenda:\\nO = Valor Real\\nX = Previsão\\n* = Previsão Assertiva\")\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Ajustar o layout para melhor visualização\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar o gráfico\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVf4KwnURHGM"
      },
      "source": [
        "Nesta célula, estamos destacando as previsões **assertivas** do modelo em comparação aos **valores reais** para o **time da casa** e o **time visitante**, utilizando gráficos de dispersão.\n",
        "\n",
        "### Explicação dos passos:\n",
        "\n",
        "1. **Conversão dos dados para arrays**:\n",
        "   - Aqui convertemos os valores de teste e previsão em arrays NumPy para garantir a compatibilidade ao manusear os dados e plotar os gráficos.\n",
        "\n",
        "2. **Identificação de previsões corretas (assertivas)**:\n",
        "   - São criados dois conjuntos de índices: um para o **time da casa** e outro para o **time visitante**. Esses índices correspondem aos jogos em que a previsão foi exatamente igual ao valor real de gols.\n",
        "\n",
        "3. **Criação dos subplots**:\n",
        "   - Utilizamos `matplotlib` para criar dois gráficos de dispersão, um para o **time da casa** e outro para o **time visitante**. Os gráficos mostram:\n",
        "     - **Círculos coloridos (valor real)**: valores reais de gols.\n",
        "     - **Cruzes coloridas (previsão)**: valores previstos de gols.\n",
        "     - **Estrelas douradas (previsão assertiva)**: previsões em que o valor previsto foi exatamente igual ao valor real.\n",
        "   \n",
        "4. **Personalização dos gráficos**:\n",
        "   - Cada gráfico inclui uma **legenda** explicando os símbolos e cores usadas, e há um ajuste no layout para garantir que a visualização fique clara e organizada.\n",
        "\n",
        "5. **Exibição final**:\n",
        "   - O gráfico é mostrado com as previsões e valores reais lado a lado, permitindo a fácil comparação visual dos resultados do modelo para os jogos.\n",
        "\n",
        "### Conclusão:\n",
        "Essa célula é particularmente útil para destacar visualmente as previsões exatas do modelo, permitindo avaliar diretamente o desempenho do modelo em termos de previsões corretas. As **estrelas douradas** indicam onde o modelo foi 100% preciso, o que facilita a identificação dos jogos em que o modelo acertou na mosca."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFgn5yiSuwNQ"
      },
      "source": [
        "### Conclusão Geral e Análise Final\n",
        "\n",
        "#### 1. **Introdução**\n",
        "O projeto teve como objetivo desenvolver um modelo robusto de aprendizado de máquina para prever o placar de partidas de futebol, utilizando dados históricos e estatísticas detalhadas dos times e dos jogos. A principal premissa foi que métricas avançadas, como **xG (Expected Goals)** e variáveis relacionadas ao desempenho dos times, teriam um impacto significativo na previsão de gols. A estratégia envolveu tanto a exploração inicial dos dados quanto a construção de múltiplos modelos preditivos para comparar suas performances e validar hipóteses iniciais.\n",
        "\n",
        "#### 2. **Exploração Inicial dos Dados**\n",
        "A primeira fase do projeto envolveu uma análise profunda dos dados, focando em limpar, entender e selecionar as variáveis mais promissoras para a modelagem. Algumas das principais etapas nesta fase foram:\n",
        "\n",
        "- **Análise de Correlação**: Avaliamos a correlação entre as variáveis e os gols marcados para identificar quais features tinham maior potencial preditivo. Variáveis como **posse de bola**, **chutes no alvo**, **taxa de conversão de chutes** e **PPG (Pontos por Jogo)** mostraram uma correlação considerável com o número de gols.\n",
        "  \n",
        "- **Remoção de Outliers**: Utilizamos gráficos de **box plot** para identificar e remover outliers nos dados, garantindo que exceções extremas não influenciassem negativamente os resultados do modelo.\n",
        "\n",
        "- **Normalização e Transformação Logarítmica**: Devido à assimetria nos dados de gols, aplicamos uma transformação logarítmica para normalizar as distribuições e melhorar o desempenho do modelo. Isso foi particularmente eficaz para suavizar a alta variabilidade nos jogos em que um número elevado de gols foi marcado.\n",
        "\n",
        "#### 3. **Modelos Testados**\n",
        "Diversos algoritmos foram testados para prever o número de gols marcados por cada time, incluindo **Random Forest Regressor**, **Lasso Regressor**, e posteriormente experimentamos abordagens de empilhamento (**Stacking**) com **XGBoost** e **LightGBM**. Cada abordagem foi cuidadosamente ajustada e comparada com base nas métricas de erro e poder explicativo.\n",
        "\n",
        "##### a) **Random Forest Regressor**\n",
        "- **Pontos Fortes**: O **Random Forest** tem a capacidade de capturar interações complexas e não lineares entre as variáveis, o que o torna uma escolha adequada para problemas com múltiplos fatores e interações, como é o caso das partidas de futebol.\n",
        "- **Pontos Fracos**: Embora o modelo tenha apresentado bons resultados no conjunto de treinamento, houve sinais de **overfitting**, pois o desempenho caiu significativamente quando aplicado ao conjunto de testes. A variabilidade nas previsões foi alta, especialmente em partidas com poucos gols. Além disso, o **\\( R^2 \\)** (coeficiente de determinação) não atingiu o nível esperado, o que sugeriu que o modelo não conseguia explicar bem a variabilidade nos gols.\n",
        "\n",
        "##### b) **Lasso Regressor**\n",
        "- **Pontos Fortes**: O **Lasso** foi escolhido por sua capacidade de regularização, que é extremamente eficaz em conjuntos de dados com muitas variáveis correlacionadas. Ao aplicar uma penalização nos coeficientes das features menos relevantes, o **Lasso** forçou muitos coeficientes a zero, simplificando o modelo e focando nas variáveis mais impactantes. Essa abordagem foi particularmente eficiente na **seleção de variáveis**, garantindo que apenas as features mais relevantes fossem usadas.\n",
        "- **Pontos Fracos**: O **Lasso**, sendo um modelo linear regularizado, tem limitações na captura de relações não lineares complexas. Embora a transformação logarítmica tenha ajudado a ajustar a distribuição dos dados de gols, o modelo ainda teve dificuldades para prever jogos com placares inesperados, como goleadas ou empates sem gols.\n",
        "\n",
        "##### c) **Stacking com XGBoost e LightGBM**\n",
        "- **Pontos Fortes**: A técnica de **Stacking** permite combinar a força de diferentes modelos, potencialmente melhorando a precisão ao explorar os pontos fortes de cada algoritmo. Em teoria, o **XGBoost** e o **LightGBM** podem lidar com interações mais complexas entre variáveis, fornecendo previsões mais acuradas.\n",
        "- **Pontos Fracos**: O **LightGBM** apresentou dificuldades durante o ajuste, o que impactou negativamente os resultados de empilhamento. O processo de otimização dos hiperparâmetros foi complexo e os resultados obtidos com essa abordagem não superaram significativamente o **Lasso**, considerando o tempo e os recursos exigidos.\n",
        "\n",
        "#### 4. **Validação e Métricas**\n",
        "A validação foi realizada usando **validação cruzada (Cross-Validation)** com 10 folds para garantir que o desempenho do modelo fosse consistente e não estivesse enviesado por uma única divisão dos dados. Abaixo estão as principais métricas usadas para avaliar o desempenho dos modelos:\n",
        "\n",
        "- **Mean Squared Error (MSE)**: Foi a principal métrica usada para avaliar o erro das previsões, dado que estamos lidando com um problema de regressão. O MSE mede o erro médio ao quadrado entre os valores previstos e os valores reais, penalizando grandes desvios.\n",
        "  \n",
        "- **\\( R^2 \\)** (Coeficiente de Determinação): Essa métrica foi usada para avaliar o quanto o modelo consegue explicar a variação nos dados de gols. Um valor mais próximo de 1 indica um modelo mais preciso.\n",
        "\n",
        "Os resultados finais, após o ajuste de hiperparâmetros e validação cruzada, foram:\n",
        "\n",
        "- **Time da Casa**:\n",
        "  - **MSE**: 0.2246\n",
        "  - **\\( R^2 \\)**: 0.7059\n",
        "  \n",
        "- **Time Visitante**:\n",
        "  - **MSE**: 0.1349\n",
        "  - **\\( R^2 \\)**: 0.8589\n",
        "\n",
        "Esses resultados indicam que o modelo preditivo foi eficaz em prever os gols marcados, especialmente para o time visitante, onde o **\\( R^2 \\)** alcançou um valor mais elevado.\n",
        "\n",
        "#### 5. **Comparação dos Modelos**\n",
        "Ao comparar os três principais modelos testados, **Random Forest**, **Lasso** e o **Stacking**, notamos que o **Lasso Regressor** foi o mais eficiente para o conjunto de dados e a abordagem adotada:\n",
        "\n",
        "- **Random Forest** apresentou dificuldades em generalizar os resultados, com sinais de overfitting no conjunto de teste. O tempo de ajuste foi maior devido à necessidade de lidar com a complexidade do modelo.\n",
        "  \n",
        "- **Lasso Regressor** destacou-se pela simplicidade e eficiência. A regularização foi crucial para reduzir o overfitting e melhorar o desempenho geral, resultando em um modelo parcimonioso que mantém apenas as variáveis mais relevantes.\n",
        "\n",
        "- **Stacking** prometeu melhores resultados ao combinar diferentes modelos, mas o processo de ajuste de hiperparâmetros foi complexo, e o impacto no desempenho foi pequeno comparado ao **Lasso**.\n",
        "\n",
        "#### 6. **Pontos Fortes do Modelo**\n",
        "- **Seleção automática de variáveis**: O **Lasso** foi eficaz em identificar automaticamente as variáveis mais relevantes, tornando o modelo mais simples e interpretável.\n",
        "- **Regularização**: Ao penalizar as features menos relevantes, o **Lasso** conseguiu reduzir o overfitting e produzir previsões mais estáveis, mesmo com um conjunto de dados relativamente pequeno.\n",
        "- **Validação rigorosa**: A validação cruzada garantiu que o modelo fosse avaliado de maneira justa e robusta, sem depender de uma única divisão de treino e teste.\n",
        "\n",
        "#### 7. **Pontos Fracos do Modelo**\n",
        "- **Simplicidade do Lasso**: O **Lasso** é um modelo linear e, portanto, pode não capturar interações não lineares complexas que podem estar presentes em jogos de futebol.\n",
        "- **Previsão de jogos sem gols**: Mesmo com a transformação logarítmica, o modelo teve dificuldades em prever jogos com placares baixos, resultando em algumas previsões de **0x0** que não condiziam com a realidade.\n",
        "  \n",
        "#### 8. **Próximos Passos**\n",
        "- **Explorar outros modelos não lineares**: Modelos como **Gradient Boosting** e **XGBoost** podem capturar interações mais complexas entre as variáveis e melhorar a precisão das previsões.\n",
        "- **Expandir o conjunto de dados**: Coletar mais dados históricos e incluir novas variáveis (como eventos durante a partida) pode aumentar a capacidade do modelo de generalizar e melhorar suas previsões.\n",
        "- **Modelagem baseada em eventos**: Incorporar variáveis relacionadas a eventos específicos durante o jogo (como substituições, cartões vermelhos e amarelos, lesões, etc.) pode trazer insights mais detalhados e precisos para o modelo preditivo.\n",
        "\n",
        "#### 9. **Fontes**\n",
        "- **Regularização Lasso**: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
        "- **Cross-Validation**: https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "- **Feature Engineering em Futebol**: Liu, H., Hopkins, W. G., & Gomez, M. A. (2016). Modelling relationships between match events and match outcomes in elite football. International Journal of Performance Analysis in Sport, 16(3), 755-770."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
