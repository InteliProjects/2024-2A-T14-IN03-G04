{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2BVu2oYRuef"
      },
      "source": [
        "# **Modelo para prever Gol no Primeiro Tempo**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzwIUxiVR905"
      },
      "source": [
        "## Modelagem do problema\n",
        "### **Contexto de Uso**\n",
        "Este modelo será demonstrado no camarote da IBM no Allianz Parque, durante partidas de futebol. Um vendedor da IBM usará as previsões em tempo real para impressionar leads e clientes, demonstrando como as tecnologias de IA da IBM podem resolver problemas complexos e imprevisíveis, como prever gols no primeiro tempo. O objetivo é mostrar a capacidade computacional da IBM e seu valor em aplicações de negócios, visando conquistar novos clientes.\n",
        "Neste contexto de mercado, a confiança nas previsões é fundamental. O cliente final verá apenas as previsões do modelo, enquanto o time técnico da IBM terá acesso às métricas detalhadas de desempenho. Portanto, é essencial que o modelo apresente resultados robustos e confiáveis, garantindo que o cliente final tenha uma experiência positiva e confiável.\n",
        "\n",
        "### **Problema a Ser Modelado**\n",
        "O desafio é construir um modelo que, com base em variáveis numéricas derivadas de estatísticas de jogos anteriores, possa prever se o time da casa ou visitante marcará um gol no primeiro tempo. O problema é uma classificação binária, com as classes 1 (Gol no primeiro tempo) e 0 (Sem gol no primeiro tempo). Dado o cenário de uso, é crucial que o modelo seja altamente preciso, equilibrando corretamente F1-Score, AUC-ROC, e Log Loss, as métricas principais que garantirão a confiança do cliente nas previsões.\n",
        "Como o problema envolve somente variáveis numéricas, o modelo deve ser ajustado de forma que capture as relações entre essas variáveis e a ocorrência de gols, utilizando técnicas que aproveitem esse tipo de dado para maximizar a precisão das previsões. O modelo precisa ser eficiente e interpretável, garantindo que qualquer ajuste necessário possa ser feito com base nas importâncias das features e que suas previsões sejam precisas o suficiente para suportar a apresentação.\n",
        "\n",
        "### **Contexto do Projeto**\n",
        "O projeto tem como objetivo o desenvolvimento de um modelo preditivo para identificar se um dos times fará ou não um gol no primeiro tempo de uma partida de futebol. O problema é modelado como uma classificação binária, onde o objetivo é prever \"gol no primeiro tempo\" (1) ou \"sem gol no primeiro tempo\" (0). As previsões são feitas com base em dados históricos e estatísticos da Série A do Campeonato Brasileiro de 2024.\n",
        "A metodologia adotada para o desenvolvimento é o CRISP-DM (Cross Industry Standard Process for Data Mining), amplamente utilizada em projetos de mineração de dados, e combinada com Metodologias Ágeis, permitindo flexibilidade e entregas contínuas ao longo do projeto.\n",
        "\n",
        "### **Tecnologias e Metodologias**\n",
        "O Random Forest foi escolhido como o modelo inicial, dada sua eficácia em lidar com grandes conjuntos de variáveis numéricas. Esse algoritmo, além de robusto em problemas de classificação binária, fornece uma análise clara da importância das features, permitindo ajustes nas variáveis selecionadas para otimizar o desempenho do modelo.\n",
        "Combinando essas tecnologias com técnicas de validação cruzada e ajustes de hiperparâmetros, o objetivo é entregar um modelo ajustado, robusto e de alta confiança, adequado ao contexto do mercado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF5oFToKVY5W"
      },
      "source": [
        "## Organização dos Dados\n",
        "Os dados disponibilizados pelo parceiro incluem dados históricos de jogadores e suas estatísticas, além de variáveis associadas aos jogos, como times da casa e visitantes. Nesse sentido, os dados foram organizados da seguinte forma:\n",
        "\n",
        "**Conjunto de Treinamento:** Dados separados para o treinamento do modelo; nesse momento, cerca de 80% dos dados foram destinados ao conjunto de treinamento, visto que temos acesso a um conjunto de dados limitado.\n",
        "\n",
        "**Conjunto de Validação:** Nesse caso, não necessariamente define um novo subconjunto ao lado dos de treinamento e de testes, mas são os subconjuntos de dados utilizados durante o treinamento para verificar o desempenho do modelo e ajustar hiperparâmetros, garantindo que ele não sofra de overfitting. Nesse sentido, foi utilizada a validação cruzada para reconhecimento da consistência de performance do modelo, com ajuste manual e arbritário de folds (subconjuntos ainda menores criados para a realização de treinamentos intensivos e aproveitamento maior dos dados durante treinamento, o que auxilia em casos de bases de dados reduzidas).\n",
        "\n",
        "**Conjunto de Testes:** Um conjunto de dados separado que o modelo não vê durante o treinamento. Ele é usado para avaliar a performance real do modelo em dados novos e garantir uma avaliação justa de seu desempenho. Nesse momento, cerca de 20% dos dados está destinada aos testes.\n",
        "\n",
        "Os dados principais incluíram variáveis como:\n",
        "\n",
        "**Quantidade de gols pelo time da casa (home_team_goal_count_half_time):** Representa se o time da casa fez (ou não) gol no primeiro tempo da partida\n",
        "\n",
        "**Quantidade de gols pelo time visitante (away_team_goal_count_half_time):** Representa se o time visitante fez (ou não) gol no primeiro tempo da partida\n",
        "\n",
        "Por fim, conforme a modelagem do problema apresentada anteriormente, essas colunas, que eram inicialmente numéricas, foram tratadas para representar um problema de classificação binária. Dessa forma, a anterior quantidade de gols foi substituída por 0 ou 1, para representar somente a ocorrência de gols durante o primeiro tempo regular da partida.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSq2r8U7Z56Q"
      },
      "source": [
        "## Escolha de Métricas e Justificativa\n",
        "\n",
        "### **F1-Score**\n",
        "**O que é:** Média harmônica entre precisão e revocação, proporcionando uma visão equilibrada da performance do modelo.\n",
        "\n",
        "**Importância:** Garante equilíbrio entre identificação correta de gols e minimização de erros, assegurando robustez.\n",
        "\n",
        "**Valores:** Máximo: 1 (perfeito), Mínimo: 0 (nenhuma precisão/revocação).\n",
        "\n",
        "**Interpretação:** F1-Score alto mostra equilíbrio entre identificar gols e evitar erros. F1-Score baixo indica ajuste inadequado, afetando a confiança.\n",
        "\n",
        "**Justificativa:** Escolhido por balancear precisão e revocação, essencial para garantir previsões robustas e confiáveis ao cliente final.\n",
        "\n",
        "### **AUC-ROC**\n",
        "**O que é:** Mede a capacidade do modelo de distinguir entre classes, plotando verdadeiros positivos contra falsos positivos.\n",
        "\n",
        "**Importância:** Avalia a eficácia geral do modelo em diferenciar gols de não gols, aumentando a confiança no modelo.\n",
        "\n",
        "**Valores:** Máximo: 1 (perfeito), Mínimo: 0.5 (aleatório).\n",
        "\n",
        "**Interpretação:** AUC-ROC alto indica boa discriminação entre classes, essencial para lidar com a complexidade das partidas.\n",
        "\n",
        "**Justificativa:** Mostra a capacidade do modelo de diferenciar entre classes em vários limiares, reforçando a confiança nas previsões.\n",
        "\n",
        "### **Log Loss**\n",
        "**O que é:** Mede a qualidade das previsões probabilísticas, penalizando previsões erradas mais quanto mais confiantes forem.\n",
        "\n",
        "**Importância:** Avalia a confiança do modelo, garantindo previsões precisas e confiáveis.\n",
        "\n",
        "**Valores:** Máximo: ∞ (pior modelo), Mínimo: 0 (perfeito).\n",
        "\n",
        "**Interpretação:** Log Loss baixo reflete alta confiança nas previsões corretas, crucial para demonstrar confiabilidade.\n",
        "\n",
        "**Justificativa:** Log Loss reforça a qualidade das previsões, essencial para demonstrar credibilidade ao cliente.\n",
        "\n",
        "### **Conclusão**\n",
        "Essas métricas garantem um modelo robusto e confiável para apresentação ao cliente final. O F1-Score equilibra performance, o AUC-ROC demonstra discriminação, e o Log Loss avalia a qualidade probabilística, essenciais para previsões confiáveis e convincentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK0ag16AUfgy"
      },
      "source": [
        "## Entendimento e Análise Exploratória dos Dados\n",
        "Nesta etapa, o código carrega um arquivo CSV contendo dados sobre partidas de futebol da Série A de 2024 e realiza uma análise exploratória inicial. Ele utiliza bibliotecas como pandas para manipular dataframes e seaborn e matplotlib.pyplot para visualizações gráficas.\n",
        "\n",
        "O primeiro passo é filtrar as partidas com status \"complete\", garantindo que apenas os jogos concluídos sejam considerados para análise. Em seguida, verifica-se a contagem dos diferentes status dos jogos, assegurando que o dataset está corretamente formatado. Algumas colunas irrelevantes, como horário e nome do estádio, são eliminadas para evitar ruído no modelo, focando apenas nas informações úteis para a predição de gols no primeiro tempo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6W5ie6xUZQz"
      },
      "outputs": [],
      "source": [
        "# Importa as bibliotecas necessárias\n",
        "import pandas as pd  # Manipulação de dados em dataframes\n",
        "import seaborn as sns  # Visualização de dados baseada em gráficos\n",
        "import matplotlib.pyplot as plt  # Biblioteca de gráficos\n",
        "import numpy as np  # Biblioteca para manipulação numérica, arrays e operações matemáticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6jnnPFXUfrt"
      },
      "outputs": [],
      "source": [
        "# Carrega o arquivo CSV contendo o histórico de partidas de futebol da Série A 2024\n",
        "df = pd.read_csv(\"/content/brazil-serie-a-matches-2024-to-2024-stats (5).csv\", delimiter=\";\", on_bad_lines='skip')\n",
        "# Lê o arquivo CSV usando ';' como delimitador e ignora linhas com problemas no formato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "collapsed": true,
        "id": "G23Wesj-UiIR",
        "outputId": "649218c3-5889-455e-8e44-fffea6f13c04"
      },
      "outputs": [],
      "source": [
        "# Filtra as partidas que estão completas\n",
        "df = df[df[\"status\"] == \"complete\"]\n",
        "# Filtra o DataFrame, mantendo apenas as partidas cujo status é \"complete\" (jogos terminados)\n",
        "\n",
        "# Conta quantas vezes cada status aparece na coluna \"status\"\n",
        "df[\"status\"].value_counts()\n",
        "# Verifica se os status das partidas estão corretos e quantos jogos estão completos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O15od6a4UkEM"
      },
      "outputs": [],
      "source": [
        "# Remove colunas inadequadas para a modelagem\n",
        "df = df.drop(columns=[\"timestamp\", \"date_GMT\", \"status\", \"attendance\", \"referee\", \"home_team_goal_timings\",\n",
        "                      \"away_team_goal_timings\", \"stadium_name\", \"Game Week\", \"home_team_goal_count\", \"away_team_goal_count\",\n",
        "                      \"total_goal_count\", \"total_goals_at_half_time\", \"away_team_goal_count_half_time\", \"home_team_second_half_cards\", \"away_team_second_half_cards\"])\n",
        "# Elimina colunas que não são necessárias para o modelo, como informações de horário, público e árbitro\n",
        "# Remove colunas relacionadas ao número de gols (contagem total e por time), pois essas são estatísticas obtidas somente após o término do jogo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWKcrf4hF6GF",
        "outputId": "2e41e5a0-44b3-4e9f-a88f-c1d419758239"
      },
      "outputs": [],
      "source": [
        "df.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXfvYvNGUvy9"
      },
      "source": [
        "## Pré-Processamento dos Dados\n",
        "O pré-processamento inclui a limpeza dos dados, transformando-os em um formato adequado para o modelo de machine learning.\n",
        "\n",
        "Um passo importante aqui é a transformação da coluna de gols do time da casa no primeiro tempo em uma variável binária (1: Gol, 0: Sem Gol), tornando o problema de classificação binária.\n",
        "\n",
        "Também é realizado o tratamento de variáveis categóricas, como os nomes dos times, utilizando pd.get_dummies, que cria variáveis dummy (0 ou 1) para representar as equipes. Esta transformação é crucial para que o modelo possa lidar com essas variáveis de forma numérica.\n",
        "\n",
        "Além disso, o código identifica valores ausentes e realiza a normalização das variáveis independentes, ajustando os dados para uma média de 0 e desvio padrão de 1 com StandardScaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9jrVk40HUt2o",
        "outputId": "4b77dac4-39ca-464d-f300-b3f3a2ccaa8b"
      },
      "outputs": [],
      "source": [
        "# Conta o número de valores nulos por coluna no dataframe\n",
        "missing_values_count = df.isnull().sum()\n",
        "print(missing_values_count)\n",
        "# Exibe a quantidade de valores ausentes (nulos) em cada coluna, para identificar a necessidade de tratamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "cMq8QE2DVs9F",
        "outputId": "04298c93-50f4-469d-e8e2-8595f78d9193"
      },
      "outputs": [],
      "source": [
        "# Aplica uma transformação binária à coluna de gols no 1º tempo do time da casa\n",
        "df[\"home_team_goal_count_half_time\"] = df[\"home_team_goal_count_half_time\"].apply(lambda x: 1 if x > 0 else 0)\n",
        "# Converte a coluna que contém o número de gols do time da casa no 1º tempo em uma variável binária (1: Gol, 0: Sem Gol)\n",
        "\n",
        "# Conta os valores únicos na nova coluna binária\n",
        "df[\"home_team_goal_count_half_time\"].value_counts()\n",
        "# Exibe quantas partidas resultaram em gol (1) ou não (0) no 1º tempo para o time da casa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oLw58r3bOGL"
      },
      "outputs": [],
      "source": [
        "# Converte colunas categóricas (nomes dos times) em variáveis dummy (variáveis binárias) para o modelo\n",
        "df = pd.get_dummies(df, columns=['home_team_name', 'away_team_name'])\n",
        "# Transforma os nomes dos times em colunas com valores binários (0 ou 1) para que possam ser usadas no modelo preditivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh6YnUAsYUfN",
        "outputId": "d82f8d4d-5a2c-4158-ead2-b9adac29a194"
      },
      "outputs": [],
      "source": [
        "outliers_index_list = []\n",
        "\n",
        "for col in df.select_dtypes(include=np.number).columns:\n",
        "  Q1 = df[col].quantile(0.25)\n",
        "  Q3 = df[col].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  # Definir limites para outliers\n",
        "  lower_bound = Q1 - 1.5 * IQR\n",
        "  upper_bound = Q3 + 1.5 * IQR\n",
        "  # Identificar outliers\n",
        "  outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "\n",
        "  # Imprimir resultados\n",
        "  if outliers.empty:\n",
        "    print(col, \": \")\n",
        "    print(f\"Nenhum outlier encontrado em {col}\\n\")\n",
        "  else:\n",
        "    # Armazenar o índice do dicionário\n",
        "    outliers_index_list.extend(outliers.index.tolist())\n",
        "    print(col, \": \")\n",
        "    print(outliers[col])\n",
        "    print(f\"Mediana de {col}: \", df[col].median(), \"\\n\")\n",
        "\n",
        "# Remove duplicatas e ordena em ordem crescente\n",
        "outliers_index_list = set(outliers_index_list)\n",
        "outliers_index_list = sorted(outliers_index_list)\n",
        "\n",
        "# # Criar um dataframe com as linhas com o índice reconhecido ! ! !\n",
        "print(\"Linhas com outliers: \")\n",
        "print(outliers_index_list)\n",
        "\n",
        "outliers_df = pd.DataFrame()\n",
        "\n",
        "for index in outliers_index_list:\n",
        "  outlier_row = pd.Series(df.loc[index])\n",
        "  outliers_df = pd.concat([outliers_df, outlier_row.to_frame().T], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "b1fH6CEkI1mL",
        "outputId": "9c39a5f1-a6d7-466f-a408-6abaad106406"
      },
      "outputs": [],
      "source": [
        "# Lista de colunas que você deseja ajustar para outliers\n",
        "cols_to_adjust = [\n",
        "    \"home_team_corner_count\",\n",
        "    \"away_team_corner_count \",\n",
        "    \"away_team_yellow_cards\",\n",
        "    \"home_team_shots \",\n",
        "    \"away_team_shots \",\n",
        "    \"away_team_shots_on_target\",\n",
        "    \"home_team_shots_off_target\",\n",
        "    \"away_team_shots_off_target\",\n",
        "]\n",
        "\n",
        "# Substituir outliers pela média nas colunas especificadas\n",
        "for col in cols_to_adjust:\n",
        "    if col in df.columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        # Definir limites para outliers\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Identificar índices dos outliers\n",
        "        outliers_indices = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
        "\n",
        "        # Calcular a média para substituir os outliers\n",
        "        mean_value = df[col].mean()\n",
        "\n",
        "        # Substituir os outliers pela média\n",
        "        df.loc[outliers_indices, col] = mean_value\n",
        "\n",
        "# Exibir o DataFrame atualizado\n",
        "print(\"DataFrame após substituição de outliers:\")\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "ZIxbCFCYYpo7",
        "outputId": "af9dcec3-f9be-4561-d5d9-24fc6e7001e0"
      },
      "outputs": [],
      "source": [
        "# Retira 20 linhas em que as métricas inconsistentes estão afetando a performance do modelo\n",
        "df = df.loc[19:245]\n",
        "# Exibe o DataFrame\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "i7Blit1fEMUp",
        "outputId": "a85f3191-a791-4e2e-f112-0b7e09819f69"
      },
      "outputs": [],
      "source": [
        "# Confere se as classes da coluna alvo (classificação binária) estão equilibradas\n",
        "df[\"home_team_goal_count_half_time\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJE9z56ZGJwG"
      },
      "source": [
        "### Tratamento de outliers\n",
        "Reavaliando a presença de outliers, após a exclusão de linhas com métricas inconsistentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-D6k7wAGIyE",
        "outputId": "e9a91fe6-f1c1-4cc5-ff80-ffa65166e664"
      },
      "outputs": [],
      "source": [
        "outliers_index_list = []\n",
        "\n",
        "for col in df.select_dtypes(include=np.number).columns:\n",
        "  Q1 = df[col].quantile(0.25)\n",
        "  Q3 = df[col].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  # Definir limites para outliers\n",
        "  lower_bound = Q1 - 1.5 * IQR\n",
        "  upper_bound = Q3 + 1.5 * IQR\n",
        "  # Identificar outliers\n",
        "  outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "\n",
        "  # Imprimir resultados\n",
        "  if outliers.empty:\n",
        "    print(col, \": \")\n",
        "    print(f\"Nenhum outlier encontrado em {col}\\n\")\n",
        "  else:\n",
        "    # Armazenar o índice do dicionário\n",
        "    outliers_index_list.extend(outliers.index.tolist())\n",
        "    print(col, \": \")\n",
        "    print(outliers[col])\n",
        "    print(f\"Mediana de {col}: \", df[col].median(), \"\\n\")\n",
        "\n",
        "# Remove duplicatas e ordena em ordem crescente\n",
        "outliers_index_list = set(outliers_index_list)\n",
        "outliers_index_list = sorted(outliers_index_list)\n",
        "\n",
        "# # Criar um dataframe com as linhas com o índice reconhecido ! ! !\n",
        "print(\"Linhas com outliers: \")\n",
        "print(outliers_index_list)\n",
        "\n",
        "outliers_df = pd.DataFrame()\n",
        "\n",
        "for index in outliers_index_list:\n",
        "  outlier_row = pd.Series(df.loc[index])\n",
        "  outliers_df = pd.concat([outliers_df, outlier_row.to_frame().T], axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlSrxR0mU0Gu"
      },
      "source": [
        "## Engenharia de features com Random Forest Importance\n",
        "### **Relevância das features**:\n",
        "A técnica de Random Forest Importance avalia a relevância de cada feature com base na sua contribuição para a redução da impureza nas árvores de decisão que compõem o Random Forest. Cada árvore avalia um subconjunto aleatório das features e, durante o processo de treinamento, calcula-se a redução de impureza (geralmente usando Gini ou Entropia) gerada por uma feature ao dividir os dados.\n",
        "\n",
        "A importância de uma feature é a média da redução de impureza acumulada em todas as árvores do modelo. Assim, quanto maior a redução, mais relevante é a feature para a predição.\n",
        "\n",
        "### **Seleção das features**:\n",
        "O método SelectFromModel com o parâmetro prefit=True é usado para realizar a seleção automática de features com base na importância calculada pelo modelo que já foi ajustado (neste caso, o RandomForestClassifier). Esse método permite selecionar as features mais importantes, ou seja, aquelas que contribuem mais para a capacidade preditiva do modelo.\n",
        "\n",
        "Após o ajuste do modelo rf_selector, o SelectFromModel avalia as importâncias de cada feature e seleciona automaticamente aquelas cujos valores estão acima de um determinado limiar, eliminando as menos relevantes. Isso ajuda a simplificar o modelo e a reduzir o risco de overfitting, mantendo apenas as features mais impactantes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih6AYZDjVy8y"
      },
      "outputs": [],
      "source": [
        "# Importa a função para dividir os dados em treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define as variáveis independentes (X) e a dependente (y)\n",
        "X = df.drop(columns=[\"home_team_goal_count_half_time\"])  # X contém as features (todas menos o alvo)\n",
        "y = df[\"home_team_goal_count_half_time\"]  # y é a variável alvo (gol no 1º tempo do time da casa)\n",
        "\n",
        "# Divide os dados em conjuntos de treino e teste (80% treino, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Realiza a divisão dos dados, garantindo que 20% sejam reservados para teste e os 80% restantes para treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4dgld83V1OE"
      },
      "outputs": [],
      "source": [
        "# Importa a biblioteca para normalizar os dados\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cria o objeto StandardScaler para normalização\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajusta o scaler aos dados de treino e transforma os dados\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Normaliza as features (X), ajustando os dados para que tenham média 0 e desvio padrão 1, para evitar discrepâncias entre escalas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u03ZguElaYwZ"
      },
      "outputs": [],
      "source": [
        "# Importa as bibliotecas para seleção de features e o classificador Random Forest\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Treina um modelo de Random Forest para selecionar as melhores features\n",
        "rf_selector = RandomForestClassifier(random_state=42)\n",
        "rf_selector.fit(X_train_scaled, y_train)\n",
        "# Ajusta o classificador Random Forest com os dados de treino, identificando a importância de cada feature\n",
        "\n",
        "# Seleciona as features mais relevantes com base no modelo Random Forest\n",
        "selector = SelectFromModel(rf_selector, prefit=True)\n",
        "X_train_selected = selector.transform(X_train_scaled)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "# Transforma os dados de treino e teste para conter apenas as features mais importantes, segundo o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "wcegPB0lvCM8",
        "outputId": "fff4176d-88cc-479e-ed0e-7c96584a2f35"
      },
      "outputs": [],
      "source": [
        "# Obter as importâncias das features\n",
        "importances = rf_selector.feature_importances_\n",
        "\n",
        "# Obter os nomes das features originais\n",
        "features = X.columns\n",
        "\n",
        "# Filtrar as features selecionadas\n",
        "selected_features = features[selector.get_support()]\n",
        "\n",
        "feature_importance_list = []\n",
        "\n",
        "# Exibir as features mais importantes e suas importâncias\n",
        "for feature, importance in zip(selected_features, importances[selector.get_support()]):\n",
        "    feature_importance_list.append((feature, importance))\n",
        "\n",
        "# Ordena as features por importância\n",
        "feature_importance_list.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# print(feature_importance_list[:20])\n",
        "# Retorna o nome das features para criar uma lista com o nome das features\n",
        "\n",
        "features_names = [\"Mais de 1.5 gols no primeiro tempo em Porcentagem (Pré-Partida)\",\n",
        "                  \"Mais de 1.5 gols no primeiro tempo em Porcentagem (Pré-Partida)\",\n",
        "                  \"Faltas para o Time da Casa\", \"Posse de bola do Time da Casa\",\n",
        "                  \"Gols esperados para Time da Casa\", \"Ambos times marcam gol em Porcentagem (Pré-Partida)\",\n",
        "                  \"Chutes do Time da Casa\", \"Média de gols por partida (Pré-Partida)\",\n",
        "                  \"Mais de 0.5 gol no segundo tempo em Porcentagem (Pré-Partida)\", \"Gols esperados para Time da Casa (Pré-Partida)\",\n",
        "                  \"Média de cartões por partida (Pré-Partida)\", \"Gols esperados para Time Visitante (Pré-Partida)\",\n",
        "                  \"Chutes fora do gol do Time Visitante\", \"Gols esperados para Time Visitante\",\n",
        "                  \"Chutes ao gol pelo Time da Casa\", \"Pontos por jogo do Time da Casa (Atual)\",\n",
        "                  \"Chutes fora do gol do Time da Casa\", \"Pontos por jogo do Time da Casa (Pré-Partida)\",\n",
        "                  \"Média de escanteios por partida (Pré-Partida)\"]\n",
        "\n",
        "# Create a new list with the desired structure\n",
        "feature_importance_list_updated = [(features_names[i], feature_importance_list[i][1]) for i in range(len(features_names))]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Use the updated list for plotting\n",
        "plt.barh(y=[x[0] for x in feature_importance_list_updated], width=[x[1] for x in feature_importance_list_updated])\n",
        "plt.xticks(np.arange(0, 0.06, 0.005))\n",
        "plt.ylabel('Features')\n",
        "plt.xlabel('Importância relativa para predição')\n",
        "plt.title('Importância das features para predição do primeiro gol da partida pelo Time da Casa')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "vDaVNpXHJOob",
        "outputId": "c83db636-2449-45d8-f5c1-91e86922475c"
      },
      "outputs": [],
      "source": [
        "feature_importance_df = pd.DataFrame(feature_importance_list[:20], columns=[\"variável\",\"relevância\"])\n",
        "feature_importance_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5-2RWaEU4vv"
      },
      "source": [
        "## Treinamento do Modelo\n",
        "O modelo preditivo escolhido é o RandomForestClassifier, um algoritmo de aprendizado de ensemble que combina o poder de múltiplas árvores de decisão para criar um modelo mais robusto e estável. O algoritmo constrói diversas árvores utilizando amostras diferentes dos dados de treino e seleciona subgrupos aleatórios de features em cada nó, aumentando a diversidade entre as árvores e reduzindo o risco de overfitting. O RandomForestClassifier é conhecido por sua resistência a dados ruidosos e pela capacidade de capturar interações complexas entre variáveis, o que o torna uma escolha ideal para problemas preditivos complexos, como prever se haverá um gol no primeiro tempo de uma partida.\n",
        "\n",
        "## Validação Cruzada\n",
        "Para garantir que o modelo seja avaliado de forma consistente e generalizável, foi utilizada a técnica de Validação Cruzada com 5 folds. Essa abordagem divide o conjunto de dados em 5 partes iguais, onde o modelo é treinado em 4 dessas partes e testado na parte restante. Esse processo é repetido 5 vezes, garantindo que cada parte seja usada como conjunto de teste uma vez. A validação cruzada fornece uma avaliação mais confiável do desempenho do modelo ao evitar que o resultado dependa de uma única divisão dos dados.\n",
        "\n",
        "Durante a validação, o modelo é avaliado utilizando métricas essenciais como Acurácia, Precisão, Recall, F1-Score, AUC-ROC e Log Loss. Essas métricas fornecem uma visão abrangente sobre o desempenho, medindo desde a capacidade do modelo em prever corretamente as classes (gols ou não no 1º tempo), até a taxa de falsos positivos e a qualidade geral das previsões probabilísticas.\n",
        "\n",
        "Após o processo de validação, o modelo é treinado no conjunto completo de dados e as previsões são geradas no conjunto de teste, permitindo uma análise final do seu desempenho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyFf_FJCLAbA"
      },
      "outputs": [],
      "source": [
        "# Define o modelo Random Forest que será usado para treinar e avaliar\n",
        "rf_model = RandomForestClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAQbN_K1bY67"
      },
      "outputs": [],
      "source": [
        "# Dicionário para armazenar os resultados da validação cruzada para o Random Forest\n",
        "cv_results_dict = {\n",
        "    'Modelo': [],\n",
        "    'Acurácia (CV)': [],\n",
        "    'Precisão (CV)': [],\n",
        "    'Recall (CV)': [],\n",
        "    'F1-Score (CV)': [],\n",
        "    'AUC-ROC (CV)': [],\n",
        "    'Log Loss (CV)': []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jVjDqIWKusy"
      },
      "outputs": [],
      "source": [
        "# Importa função para realizar validação cruzada\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Define o número de folds (divisões) para a validação cruzada\n",
        "n_folds = 10\n",
        "\n",
        "# Realiza validação cruzada com diferentes métricas para o modelo Random Forest\n",
        "cv_results = cross_validate(rf_model, X_train_selected, y_train, cv=n_folds,\n",
        "                            scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'neg_log_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9t2kt1bVpC7"
      },
      "outputs": [],
      "source": [
        "# Armazena os resultados médios das métricas no dicionário\n",
        "cv_results_dict['Modelo'].append('Random Forest')\n",
        "cv_results_dict['Acurácia (CV)'].append(cv_results['test_accuracy'].mean())\n",
        "cv_results_dict['Precisão (CV)'].append(cv_results['test_precision'].mean())\n",
        "cv_results_dict['Recall (CV)'].append(cv_results['test_recall'].mean())\n",
        "cv_results_dict['F1-Score (CV)'].append(cv_results['test_f1'].mean())\n",
        "cv_results_dict['AUC-ROC (CV)'].append(cv_results['test_roc_auc'].mean())\n",
        "cv_results_dict['Log Loss (CV)'].append(-cv_results['test_neg_log_loss'].mean())\n",
        "# Valida o modelo Random Forest com 5 folds e calcula as métricas de desempenho, como acurácia, precisão, recall, F1-Score, AUC-ROC e Log Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "UEF1PJ8YLx82",
        "outputId": "3b681107-8b4b-46d1-b2b2-0927e624e74b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Treina o modelo com todo o conjunto de treino\n",
        "rf_model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Realiza previsões no conjunto de teste\n",
        "y_pred = rf_model.predict(X_test_selected)\n",
        "\n",
        "# Supondo que 'y_true' e 'y_pred' são as verdadeiras e preditas classes\n",
        "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "\n",
        "# Plotando a matriz de confusão normalizada\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, annot=True, fmt='.2', cmap='Blues')\n",
        "plt.title('Matriz de Confusão Normalizada')\n",
        "plt.ylabel('Classe Real')\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "FgUjl-9XLNlp",
        "outputId": "45f811ef-5cd5-4662-c292-d5670674dfc6"
      },
      "outputs": [],
      "source": [
        "# Converte os resultados da validação cruzada para um DataFrame para facilitar a visualização\n",
        "cv_results_df = pd.DataFrame(cv_results_dict)\n",
        "\n",
        "# Exibe os resultados de validação cruzada\n",
        "print(\"\\nDesempenho do Modelo Random Forest com Validação Cruzada:\")\n",
        "cv_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsySc6c4U9LR"
      },
      "source": [
        "## Discussão dos Resultados do Modelo e Conclusões\n",
        "### **Comparação com o Contexto de Mercado**\n",
        "Dado o cenário de demonstração ao vivo no camarote da IBM no Allianz Parque, a confiança e robustez das previsões são fundamentais para impressionar leads e clientes, demonstrando o poder das tecnologias da IBM. No entanto, as métricas atuais indicam que o modelo não está suficientemente refinado para garantir essa confiança:\n",
        "#### - **F1-Score (0.57):**\n",
        "Reflete um equilíbrio mediano entre a identificação de jogos com gols e a minimização de falsos positivos. No contexto de mercado, um F1-Score mais alto seria preferível para demonstrar que o modelo tem precisão e capacidade de recuperação adequadas, garantindo que o cliente veja previsões mais certeiras e menos falhas.\n",
        "#### - **AUC-ROC (0.6):**\n",
        "Esta métrica revela que o modelo consegue discriminar entre jogos com e sem gols, mas com uma performance ligeiramente acima do acaso. Para garantir que o modelo é confiável e robusto o suficiente para uma apresentação ao vivo, uma AUC-ROC acima de 0.7 seria recomendada, proporcionando mais confiança na capacidade do modelo de distinguir entre as classes (gol/no gol).\n",
        "#### - **Log Loss (0.69):**\n",
        "Indica que o modelo ainda não está fazendo previsões probabilísticas com alta confiança. Idealmente, um valor de Log Loss mais próximo de 0 garantiria que o modelo está não apenas prevendo corretamente, mas também gerando previsões confiáveis, o que é essencial em um ambiente de demonstração onde cada previsão errada pode afetar a credibilidade da IBM.\n",
        "### **Oportunidades de Melhoria**\n",
        "Dado que o desempenho atual é razoável, mas longe do ideal para um ambiente de vendas com alto impacto, os próximos passos devem incluir uma comparação com outros modelos preditivos, como Gradient Boosting e XG Boost, para identificar qual deles oferece o melhor desempenho para o problema de classificação binária de gols no primeiro tempo. Além disso, ajustes de hiperparâmetros e uso de técnicas avançadas de validação cruzada podem ajudar a melhorar as métricas escolhidas, principalmente no aumento do F1-Score e da AUC-ROC, além da redução do Log Loss.\n",
        "### **Foco nas Métricas para Apresentação ao Cliente**\n",
        "Portanto, melhorias nessas métricas são imprescindíveis para elevar a qualidade do modelo a um nível em que a IBM possa apresentar previsões com mais confiança e precisão, consolidando a credibilidade de suas tecnologias perante os leads e clientes durante as demonstrações no Allianz Parque.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POTz0t8OAH8f"
      },
      "source": [
        "# Treinamento e Comparação dos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJvkcHCfBBkr"
      },
      "source": [
        " Realiza-se a avaliação de múltiplos modelos de classificação utilizando validação cruzada com 5 folds. Ele inclui modelos como Regressão Logística, K-Nearest Neighbors, SVM, Árvores de Decisão, Random Forest, Gradient Boosting, AdaBoost, XGBoost, LightGBM, Extra Trees, Gaussian Naive Bayes, LDA e QDA, todos com random_state=42 (para garantir reprodutibilidade) e seus hiperparâmetros padrão. Os resultados da validação cruzada são calculados para métricas como Acurácia, Precisão, Recall, F1-Score, AUC-ROC e Log Loss, e são armazenados em um dicionário, que é convertido em um DataFrame e ordenado de forma crescente por Log Loss para análise comparativa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "bv7vLF-xAOya",
        "outputId": "c08614cc-70df-4125-a66b-72c3b6040c6b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Definir os modelos a serem testados com hiperparâmetros default\n",
        "model_dict = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Support Vector Machine': SVC(probability=True, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    'LightGBM': LGBMClassifier(verbose=-1, random_state=42),\n",
        "    'Extra Trees': ExtraTreesClassifier(random_state=42),\n",
        "    'Gaussian Naive Bayes': GaussianNB(),\n",
        "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
        "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis()\n",
        "}\n",
        "\n",
        "# Inicializar um dicionário para armazenar os resultados de validação cruzada\n",
        "cv_results_dict = {\n",
        "    'Modelo': [],\n",
        "    'Acurácia (CV)': [],\n",
        "    'Precisão (CV)': [],\n",
        "    'Recall (CV)': [],\n",
        "    'F1-Score (CV)': [],\n",
        "    'AUC-ROC (CV)': [],\n",
        "    'Log Loss (CV)': []\n",
        "}\n",
        "\n",
        "# Número de folds para validação cruzada\n",
        "n_folds = 5\n",
        "\n",
        "# Treinar e avaliar cada modelo com validação cruzada\n",
        "for model_name, model in model_dict.items():\n",
        "    # Executar validação cruzada\n",
        "    cv_results = cross_validate(model, X_train_selected, y_train, cv=n_folds,\n",
        "                                scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'neg_log_loss'])\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    cv_results_dict['Modelo'].append(model_name)\n",
        "    cv_results_dict['Acurácia (CV)'].append(cv_results['test_accuracy'].mean())\n",
        "    cv_results_dict['Precisão (CV)'].append(cv_results['test_precision'].mean())\n",
        "    cv_results_dict['Recall (CV)'].append(cv_results['test_recall'].mean())\n",
        "    cv_results_dict['F1-Score (CV)'].append(cv_results['test_f1'].mean())\n",
        "    cv_results_dict['AUC-ROC (CV)'].append(cv_results['test_roc_auc'].mean())\n",
        "    cv_results_dict['Log Loss (CV)'].append(-cv_results['test_neg_log_loss'].mean())\n",
        "\n",
        "# Converter os resultados de validação cruzada em DataFrame\n",
        "cv_results_df = pd.DataFrame(cv_results_dict)\n",
        "\n",
        "# Ordenar os resultados por Log Loss (CV)\n",
        "cv_results_df = cv_results_df.sort_values(by='Log Loss (CV)', ascending=True)\n",
        "\n",
        "# Exibir os resultados de validação cruzada\n",
        "print(\"\\nDesempenho dos Modelos com Validação Cruzada:\")\n",
        "cv_results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYwTefhwAaMh"
      },
      "source": [
        "# Otimização de hiperparâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt7EXRe_-cga"
      },
      "source": [
        "GridSearch é um método de otimização de hiperparâmetros utilizado para encontrar a melhor combinação de parâmetros de um modelo de machine learning. Ele realiza uma busca exaustiva ao testar todas as possíveis combinações de um conjunto pré-definido de valores para os hiperparâmetros especificados. O objetivo é identificar a configuração que maximiza o desempenho do modelo de acordo com uma métrica de avaliação, como acurácia, precisão, recall ou F1-score.\n",
        "\n",
        "O processo envolve a criação de uma \"grade\" de parâmetros, onde cada combinação é avaliada por meio de uma técnica de validação cruzada, garantindo que o modelo seja testado em diferentes divisões do conjunto de dados, reduzindo o risco de overfitting. Uma vez concluída a busca, o GridSearch retorna a combinação de parâmetros com o melhor desempenho.\n",
        "\n",
        "Apesar de eficaz, o GridSearch pode ser computacionalmente custoso, pois sua complexidade cresce exponencialmente com o número de parâmetros e valores testados. Por isso, em casos com muitas opções de parâmetros, métodos alternativos como RandomizedSearch podem ser mais eficientes.\n",
        "\n",
        "No contexto do projeto, pela disponibilidade de capacidade computacional, o algoritmo GridSearch foi aplicado para diferentes modelos, em todos os casos nos quais a otimização de hiperparâmetros foi considerada relevante ou produtiva.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS9jqFsnAi8D"
      },
      "source": [
        "### Modelos Random Forest, Logistic Regression, Gradient Boosting\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73NkTiIdYVIp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# Parâmetros para otimização de Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Parâmetros para otimização de Logistic Regression\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Parâmetros para otimização de Gradient Boosting\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Função para realizar a busca de hiperparâmetros\n",
        "def optimize_model(model, param_grid, X_train, y_train):\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                               cv=5, scoring='neg_log_loss', n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(f\"Melhores parâmetros para {model.__class__.__name__}: {grid_search.best_params_}\")\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Aplicar a otimização de hiperparâmetros para cada modelo\n",
        "best_rf = optimize_model(RandomForestClassifier(random_state=42), param_grid_rf, X_train_selected, y_train)\n",
        "best_lr = optimize_model(LogisticRegression(random_state=42), param_grid_lr, X_train_selected, y_train)\n",
        "best_gb = optimize_model(GradientBoostingClassifier(random_state=42), param_grid_gb, X_train_selected, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik_v5fOxAsjZ"
      },
      "source": [
        "### Modelo KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jEoi3Mkbzum"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, log_loss\n",
        "\n",
        "# Definir os parâmetros a serem otimizados\n",
        "knn_param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "# Instanciar o modelo\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Grid Search com validação cruzada\n",
        "knn_grid_search = GridSearchCV(estimator=knn_model, param_grid=knn_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Ajustar aos dados de treinamento\n",
        "knn_grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_knn = knn_grid_search.predict(X_test_selected)\n",
        "y_prob_knn = knn_grid_search.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "recall_knn = recall_score(y_test, y_pred_knn)\n",
        "roc_auc_knn = roc_auc_score(y_test, y_prob_knn)\n",
        "logloss_knn = log_loss(y_test, y_prob_knn)\n",
        "\n",
        "# Exibir os melhores parâmetros e resultados\n",
        "print(\"Melhores Parâmetros para K-Nearest Neighbors:\", knn_grid_search.best_params_)\n",
        "print(f\"Accuracy: {accuracy_knn}, Recall: {recall_knn}, AUC-ROC: {roc_auc_knn}, Log Loss: {logloss_knn}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KusM9SDQyOh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, log_loss # import metrics functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPQhIYP4Ax9-"
      },
      "source": [
        "### Modelo Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J__r5YGUoz7Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definir os parâmetros a serem otimizados\n",
        "svm_param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Instanciar o modelo\n",
        "svm_model = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Grid Search com validação cruzada\n",
        "svm_grid_search = GridSearchCV(estimator=svm_model, param_grid=svm_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Ajustar aos dados de treinamento\n",
        "svm_grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_svm = svm_grid_search.predict(X_test_selected)\n",
        "y_prob_svm = svm_grid_search.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "roc_auc_svm = roc_auc_score(y_test, y_prob_svm)\n",
        "logloss_svm = log_loss(y_test, y_prob_svm)\n",
        "\n",
        "# Exibir os melhores parâmetros e resultados\n",
        "print(\"Melhores Parâmetros para Support Vector Machine:\", svm_grid_search.best_params_)\n",
        "print(f\"Accuracy: {accuracy_svm}, Recall: {recall_svm}, AUC-ROC: {roc_auc_svm}, Log Loss: {logloss_svm}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdyqjEUpA1yc"
      },
      "source": [
        "### Modelo Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l_qqoHSRKvc"
      },
      "outputs": [],
      "source": [
        "# Definir os parâmetros a serem otimizados\n",
        "dt_param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 6]\n",
        "}\n",
        "\n",
        "# Instanciar o modelo\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Grid Search com validação cruzada\n",
        "dt_grid_search = GridSearchCV(estimator=dt_model, param_grid=dt_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Ajustar aos dados de treinamento\n",
        "dt_grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_dt = dt_grid_search.predict(X_test_selected)\n",
        "y_prob_dt = dt_grid_search.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "recall_dt = recall_score(y_test, y_pred_dt)\n",
        "roc_auc_dt = roc_auc_score(y_test, y_prob_dt)\n",
        "logloss_dt = log_loss(y_test, y_prob_dt)\n",
        "\n",
        "# Exibir os melhores parâmetros e resultados\n",
        "print(\"Melhores Parâmetros para Decision Tree:\", dt_grid_search.best_params_)\n",
        "print(f\"Accuracy: {accuracy_dt}, Recall: {recall_dt}, AUC-ROC: {roc_auc_dt}, Log Loss: {logloss_dt}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vVT_fBBA4pK"
      },
      "source": [
        "### Modelo AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M27CNdwLRPZk"
      },
      "outputs": [],
      "source": [
        "# Definir os parâmetros a serem otimizados\n",
        "ada_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# Instanciar o modelo\n",
        "ada_model = AdaBoostClassifier(random_state=42)\n",
        "\n",
        "# Grid Search com validação cruzada\n",
        "ada_grid_search = GridSearchCV(estimator=ada_model, param_grid=ada_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Ajustar aos dados de treinamento\n",
        "ada_grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_ada = ada_grid_search.predict(X_test_selected)\n",
        "y_prob_ada = ada_grid_search.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
        "recall_ada = recall_score(y_test, y_pred_ada)\n",
        "roc_auc_ada = roc_auc_score(y_test, y_prob_ada)\n",
        "logloss_ada = log_loss(y_test, y_prob_ada)\n",
        "\n",
        "# Exibir os melhores parâmetros e resultados\n",
        "print(\"Melhores Parâmetros para AdaBoost:\", ada_grid_search.best_params_)\n",
        "print(f\"Accuracy: {accuracy_ada}, Recall: {recall_ada}, AUC-ROC: {roc_auc_ada}, Log Loss: {logloss_ada}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO99Qr93A7hZ"
      },
      "source": [
        "### Modelo XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82-m_TLORRIw"
      },
      "outputs": [],
      "source": [
        "# Definir os parâmetros a serem otimizados\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Instanciar o modelo\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Grid Search com validação cruzada\n",
        "xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Ajustar aos dados de treinamento\n",
        "xgb_grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_xgb = xgb_grid_search.predict(X_test_selected)\n",
        "y_prob_xgb = xgb_grid_search.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
        "roc_auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
        "logloss_xgb = log_loss(y_test, y_prob_xgb)\n",
        "\n",
        "# Exibir os melhores parâmetros e resultados\n",
        "print(\"Melhores Parâmetros para XGBoost:\", xgb_grid_search.best_params_)\n",
        "print(f\"Accuracy: {accuracy_xgb}, Recall: {recall_xgb}, AUC-ROC: {roc_auc_xgb}, Log Loss: {logloss_xgb}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP6FAhlgA-r2"
      },
      "source": [
        "### Modelo LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCtQmtymRTdZ"
      },
      "outputs": [],
      "source": [
        "# Definir os parâmetros a serem otimizados\n",
        "lgbm_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'num_leaves': [31, 40, 50],\n",
        "    'subsample': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Instanciar o modelo\n",
        "lgbm_model = LGBMClassifier(random_state=42)\n",
        "\n",
        "# Grid Search com validação cruzada\n",
        "lgbm_grid_search = GridSearchCV(estimator=lgbm_model, param_grid=lgbm_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Ajustar aos dados de treinamento\n",
        "lgbm_grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_lgbm = lgbm_grid_search.predict(X_test_selected)\n",
        "y_prob_lgbm = lgbm_grid_search.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
        "recall_lgbm = recall_score(y_test, y_pred_lgbm)\n",
        "roc_auc_lgbm = roc_auc_score(y_test, y_prob_lgbm)\n",
        "logloss_lgbm = log_loss(y_test, y_prob_lgbm)\n",
        "\n",
        "# Exibir os melhores parâmetros e resultados\n",
        "print(\"Melhores Parâmetros para LightGBM:\", lgbm_grid_search.best_params_)\n",
        "print(f\"Accuracy: {accuracy_lgbm}, Recall: {recall_lgbm}, AUC-ROC: {roc_auc_lgbm}, Log Loss: {logloss_lgbm}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CA-Cqv4BEDS"
      },
      "source": [
        "### Modelo Extra Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYK6cmJoRq_I"
      },
      "outputs": [],
      "source": [
        "# Definir os parâmetros a serem otimizados\n",
        "et_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Instanciar o modelo\n",
        "et_model = ExtraTreesClassifier(random_state=42)\n",
        "\n",
        "# Grid Search com validação cruzada\n",
        "et_grid_search = GridSearchCV(estimator=et_model, param_grid=et_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Ajustar aos dados de treinamento\n",
        "et_grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_et = et_grid_search.predict(X_test_selected)\n",
        "y_prob_et = et_grid_search.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy_et = accuracy_score(y_test, y_pred_et)\n",
        "recall_et = recall_score(y_test, y_pred_et)\n",
        "roc_auc_et = roc_auc_score(y_test, y_prob_et)\n",
        "logloss_et = log_loss(y_test, y_prob_et)\n",
        "\n",
        "# Exibir os melhores parâmetros e resultados\n",
        "print(\"Melhores Parâmetros para Extra Trees:\", et_grid_search.best_params_)\n",
        "print(f\"Accuracy: {accuracy_et}, Recall: {recall_et}, AUC-ROC: {roc_auc_et}, Log Loss: {logloss_et}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi1GT0FanGGG"
      },
      "source": [
        "### Modelo Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfW_RQc-nLGz",
        "outputId": "a0d845b8-21cf-4b1f-964d-18b6e6da946c"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Modelo LDA\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Hiperparâmetros a serem ajustados\n",
        "param_grid_lda = {\n",
        "    'solver': ['svd', 'lsqr', 'eigen'],\n",
        "    'shrinkage': [None, 'auto', 0.5, 1.0]\n",
        "}\n",
        "\n",
        "# Otimização com GridSearchCV\n",
        "grid_search_lda = GridSearchCV(estimator=lda, param_grid=param_grid_lda, cv=5)\n",
        "grid_search_lda.fit(X_train, y_train)\n",
        "\n",
        "# Melhor modelo LDA\n",
        "melhor_lda = grid_search_lda.best_estimator_\n",
        "print(\"Melhor LDA:\", melhor_lda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF6my9aVnM5T"
      },
      "source": [
        "### Modelo Quadratic Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3AY2-U2nREM",
        "outputId": "f7d75a35-3a2b-4464-f69a-b35f8c1d5963"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Modelo QDA\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "# Hiperparâmetro a ser ajustado\n",
        "param_grid_qda = {\n",
        "    'reg_param': [0.0, 0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "# Otimização com GridSearchCV\n",
        "grid_search_qda = GridSearchCV(estimator=qda, param_grid=param_grid_qda, cv=5)\n",
        "grid_search_qda.fit(X_train, y_train)\n",
        "\n",
        "# Melhor modelo QDA\n",
        "melhor_qda = grid_search_qda.best_estimator_\n",
        "print(\"Melhor QDA:\", melhor_qda)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB2n9CqxnheC"
      },
      "source": [
        "### Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOMexRbCngrt",
        "outputId": "b7d12269-7782-4ade-9bc5-5130a6f6451c"
      },
      "outputs": [],
      "source": [
        "# Definir os parâmetros a serem otimizados\n",
        "gnb_param_grid = {\n",
        "    'var_smoothing': np.logspace(0, -9, num=100)\n",
        "}\n",
        "\n",
        "# Instanciar o modelo\n",
        "gnb_model = GaussianNB()\n",
        "\n",
        "# Grid Search com validação cruzada\n",
        "gnb_grid_search = GridSearchCV(estimator=gnb_model, param_grid=gnb_param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Ajustar aos dados de treinamento\n",
        "gnb_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_gnb = gnb_grid_search.predict(X_test)\n",
        "y_prob_gnb = gnb_grid_search.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
        "recall_gnb = recall_score(y_test, y_pred_gnb)\n",
        "roc_auc_gnb = roc_auc_score(y_test, y_prob_gnb)\n",
        "logloss_gnb = log_loss(y_test, y_prob_gnb)\n",
        "\n",
        "# Exibir os melhores parâmetros e resultados\n",
        "print(\"Melhores Parâmetros para Gaussian Naive Bayes:\", gnb_grid_search.best_params_)\n",
        "print(f\"Accuracy: {accuracy_gnb}, Recall: {recall_gnb}, AUC-ROC: {roc_auc_gnb}, Log Loss: {logloss_gnb}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b0-hl9MmHYH"
      },
      "source": [
        "Dessa forma, foram encontrados os melhores hiperparâmetros para cada modelo, com a aplicação do algoritmo GridSearchCV."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iNaI-JXBwew"
      },
      "source": [
        "# Treinamento após o ajuste de hiperparâmetros\n",
        "Após a descoberta e o ajuste dos hiperparâmetros otimizados, com o GridSearch, o seguinte código realiza novamente a avaliação comparativa de vários algoritmos de classificação utilizando validação cruzada. O processo é semelhante ao realizado anteriormente, mas agora, com a mudança dos hiperparâmetros aplicada, a fim de melhorar a performance dos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "oroyHZZrP2fO",
        "outputId": "c4868c6a-b73e-4abf-bcbb-b00c6e9796d3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Definir os modelos a serem testados com os melhores hiperparâmetros encontrados\n",
        "model_dict = {\n",
        "    'Logistic Regression': LogisticRegression(C=0.1, penalty=\"l2\", solver='liblinear', random_state=42),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(metric='manhattan', n_neighbors=5, weights='uniform'),\n",
        "    'Support Vector Machine': SVC(C=1, gamma='scale', kernel='linear', probability=True, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_leaf=1, min_samples_split=20, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100, random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(learning_rate=0.01, n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBClassifier(colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0, use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    'LightGBM': LGBMClassifier(learning_rate=0.01, max_depth=3, n_estimators=100, num_leaves=31, subsample=0.6, verbose=-1,random_state=42),\n",
        "    'Extra Trees': ExtraTreesClassifier(max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300, random_state=42),\n",
        "    'Gaussian Naive Bayes': GaussianNB(),\n",
        "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
        "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis()\n",
        "}\n",
        "\n",
        "# Inicializar um dicionário para armazenar os resultados de validação cruzada\n",
        "cv_results_dict = {\n",
        "    'Modelo': [],\n",
        "    'Acurácia (CV)': [],\n",
        "    'Precisão (CV)': [],\n",
        "    'Recall (CV)': [],\n",
        "    'F1-Score (CV)': [],\n",
        "    'AUC-ROC (CV)': [],\n",
        "    'Log Loss (CV)': []\n",
        "}\n",
        "\n",
        "# Número de folds para validação cruzada\n",
        "n_folds = 10\n",
        "\n",
        "# Treinar e avaliar cada modelo com validação cruzada\n",
        "for model_name, model in model_dict.items():\n",
        "    # Executar validação cruzada\n",
        "    cv_results = cross_validate(model, X_train_selected, y_train, cv=n_folds,\n",
        "                                scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'neg_log_loss'])\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    cv_results_dict['Modelo'].append(model_name)\n",
        "    cv_results_dict['Acurácia (CV)'].append(cv_results['test_accuracy'].mean())\n",
        "    cv_results_dict['Precisão (CV)'].append(cv_results['test_precision'].mean())\n",
        "    cv_results_dict['Recall (CV)'].append(cv_results['test_recall'].mean())\n",
        "    cv_results_dict['F1-Score (CV)'].append(cv_results['test_f1'].mean())\n",
        "    cv_results_dict['AUC-ROC (CV)'].append(cv_results['test_roc_auc'].mean())\n",
        "    cv_results_dict['Log Loss (CV)'].append(-cv_results['test_neg_log_loss'].mean())\n",
        "\n",
        "# Converter os resultados de validação cruzada em DataFrame\n",
        "cv_results_df = pd.DataFrame(cv_results_dict)\n",
        "\n",
        "# Ordenar os resultados por Log Loss (CV)\n",
        "cv_results_df = cv_results_df.sort_values(by='Log Loss (CV)', ascending=True)\n",
        "\n",
        "# Exibir os resultados de validação cruzada\n",
        "print(\"\\nDesempenho dos Modelos com Validação Cruzada:\")\n",
        "cv_results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "594VutOuFFu1"
      },
      "source": [
        "## Discussão dos resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0gZcW-BLcbu"
      },
      "source": [
        "**Discussão de Resultados**\n",
        "\n",
        "Os resultados apresentados para diferentes algoritmos de classificação indicam um panorama diversificado de desempenho, com destaque para três modelos: Logistic Regression, XGBoost, e agora Gradient Boosting. Esses modelos se sobressaem em termos de Log Loss, F1-score e AUC-ROC, que são métricas críticas no contexto de mercado onde a confiança nas previsões é essencial para o sucesso da aplicação.\n",
        "\n",
        "**Desempenho Geral**\n",
        "\n",
        "Os modelos foram avaliados por meio de validação cruzada, permitindo uma comparação robusta em termos de três métricas principais: Log Loss, F1-score, e AUC-ROC.\n",
        "\n",
        "- **Log Loss**: Em geral, os valores de Log Loss ficaram em um intervalo considerável, variando entre 0.640 e 1.239, com os melhores resultados próximos de 0.640, indicando previsões probabilísticas de alta confiança. Valores mais elevados, acima de 1.200, sugerem baixa precisão e pouca confiabilidade nas previsões. Essa métrica se mostrou crucial para penalizar modelos que não conseguiam fornecer previsões confiáveis em um cenário de tempo real, onde cada previsão incorreta pode impactar negativamente o fechamento de uma venda.\n",
        "\n",
        "- **F1-score**: Os F1-scores alcançados variaram entre 0.450 e 0.660. Modelos que obtiveram F1-scores acima de 0.650 mostraram uma excelente capacidade de balancear precisão e recall, o que é essencial em problemas binários como este, onde a detecção correta tanto de falsos positivos quanto de verdadeiros positivos é crítica. Modelos que obtiveram F1-scores na faixa inferior, abaixo de 0.600, demonstraram dificuldade em capturar a complexidade dos dados sem introduzir muitos falsos negativos.\n",
        "\n",
        "- **AUC-ROC**: Os resultados de AUC-ROC ficaram em um intervalo entre 0.609 e 0.693. Os valores mais próximos de 0.690 indicam uma excelente capacidade de discriminar entre as classes, o que é essencial para a robustez das previsões no problema modelado. Modelos com AUC-ROC abaixo de 0.640 tiveram dificuldade em separar corretamente os casos de \"gol no primeiro tempo\" e \"sem gol no primeiro tempo\", comprometendo a eficácia no uso prático.\n",
        "\n",
        "#### Modelos Candidatos\n",
        "\n",
        "1. **Logistic Regression**\n",
        "   - **Algoritmo:** A Regressão Logística é um modelo linear utilizado para classificação binária. Ele estima as probabilidades de cada classe ao usar uma função logística sobre uma combinação linear dos atributos. Como resultado, é altamente interpretável e de fácil implementação.\n",
        "   - **Tuning de Hiperparâmetros:**\n",
        "     - LogisticRegression(C=0.1, penalty=\"l2\", solver='liblinear', random_state=42)\n",
        "     - **C** controla a regularização, prevenindo overfitting ao penalizar coeficientes muito altos.\n",
        "     - **Penalidade L2** (regularização de Ridge) força os coeficientes dos atributos menos relevantes a se aproximarem de zero, promovendo um modelo mais simples e generalizável.\n",
        "   - **Explicabilidade:** Como é um modelo linear, a **Regressão Logística** permite uma interpretação direta dos pesos atribuídos a cada variável. Esses pesos indicam a força e a direção da influência de cada atributo na probabilidade do evento de gol no primeiro tempo.\n",
        "   - **Desempenho:**\n",
        "     - F1-Score: 0.659\n",
        "     - Log Loss: 0.655\n",
        "     - AUC-ROC: 0.675\n",
        "   - **Justificativa:** É um modelo interpretável, fácil de ajustar e oferece resultados sólidos em termos de balanceamento entre precisão e recall, com boa capacidade probabilística.\n",
        "\n",
        "2. **XGBoost**\n",
        "   - **Algoritmo:** O **XGBoost** é uma técnica avançada de boosting que cria uma sequência de árvores de decisão, onde cada nova árvore corrige os erros residuais das anteriores. Ele utiliza regularização para evitar overfitting e é altamente flexível para ajustar hiperparâmetros.\n",
        "   - **Tuning de Hiperparâmetros:**\n",
        "     - XGBClassifier(colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "     - **max_depth** controla a profundidade das árvores, prevenindo overfitting.\n",
        "     - **learning_rate** ajusta o impacto de cada árvore na predição final, com valores menores garantindo uma aprendizagem mais lenta e cuidadosa.\n",
        "     - **n_estimators** define o número de árvores.\n",
        "     - **colsample_bytree** e **subsample** ajustam a fração de amostras e features utilizadas em cada árvore, aumentando a robustez.\n",
        "   - **Explicabilidade:** Embora seja mais complexo, o **XGBoost** permite a interpretação de feature importance, onde as variáveis mais utilizadas nas divisões das árvores podem ser identificadas como as mais importantes para o modelo. Além disso, sua capacidade de gerar previsões probabilísticas confiáveis é um ponto forte.\n",
        "   - **Desempenho:**\n",
        "     - F1-Score: 0.651\n",
        "     - Log Loss: 0.648\n",
        "     - AUC-ROC: 0.684\n",
        "   - **Justificativa:** Sua capacidade de ajuste fino, combinada com sua robustez em problemas complexos, torna o XGBoost ideal para maximizar a precisão e a confiabilidade das previsões.\n",
        "\n",
        "3. **Gradient Boosting**\n",
        "   - **Algoritmo:** O **Gradient Boosting** cria um ensemble de árvores de decisão, onde cada nova árvore tenta corrigir os erros das anteriores. Ele minimiza uma função de perda, aprendendo de maneira incremental.\n",
        "   - **Tuning de Hiperparâmetros:**\n",
        "     - GradientBoostingClassifier(learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100, random_state=42)\n",
        "     - **learning_rate** ajusta a contribuição de cada árvore no modelo final.\n",
        "     - **max_depth** controla a complexidade das árvores.\n",
        "     - **n_estimators** define o número de árvores no ensemble.\n",
        "   - **Explicabilidade:** Similar ao XGBoost, o **Gradient Boosting** permite a análise de importância das features. A vantagem desse método é sua capacidade de ser ajustado para minimizar diretamente a função de perda escolhida (neste caso, o Log Loss).\n",
        "   - **Desempenho:**\n",
        "     - F1-Score: 0.612\n",
        "     - Log Loss: 0.640\n",
        "     - AUC-ROC: 0.693\n",
        "   - **Justificativa:** Embora tenha um F1-Score ligeiramente inferior, o Gradient Boosting é extremamente eficaz em discriminar entre classes, com um AUC-ROC elevado. Isso o torna uma excelente escolha para cenários onde a confiança nas previsões é essencial.\n",
        "\n",
        "#### Comparação e Conclusões\n",
        "\n",
        "Os três modelos selecionados (Logistic Regression, XGBoost e Gradient Boosting) apresentam uma performance robusta em termos de F1-Score, Log Loss e AUC-ROC.\n",
        "\n",
        "- **Logistic Regression**: Sua simplicidade e alta interpretabilidade o tornam ideal para aplicações onde a explicação dos resultados ao usuário final é crucial. Embora não seja o modelo mais preciso, ele oferece previsões consistentes e é facilmente interpretável.\n",
        "  \n",
        "- **XGBoost**: Oferece uma combinação poderosa de desempenho e flexibilidade, destacando-se em todos os aspectos da predição. Ele é ideal para cenários onde precisão e discriminação são críticas, e seu controle sobre os hiperparâmetros permite ajustes detalhados para maximizar o desempenho.\n",
        "\n",
        "- **Gradient Boosting**: Com um foco em minimizar a perda (Log Loss), o Gradient Boosting oferece previsões probabilísticas de alta confiança, além de excelente discriminação entre classes. Seu desempenho em AUC-ROC sugere que ele é altamente eficaz em separar as classes de gol e não gol no primeiro tempo.\n",
        "\n",
        "**Random Forest (modelo candidato inicial)**\n",
        "\n",
        "O Random Forest foi o modelo escolhido inicialmente como linha de base para a análise. Embora tenha apresentado um desempenho consistente, ele serviu principalmente como referência. Os modelos selecionados superaram significativamente seus resultados, em relação a todas as métricas escolhidas previamente, o que levou à sua despriorização na análise final.\n",
        "\n",
        "**Considerações Finais**\n",
        "\n",
        "Em um cenário de uso onde a confiança nas previsões precisa ser demonstrada para leads e clientes, Logistic Regression, XGBoost, e Gradient Boosting emergem como os principais candidatos, equilibrando simplicidade, interpretabilidade e robustez. Esses modelos fornecem a confiança e clareza necessárias para impressionar os clientes e leads da IBM e reforçar a capacidade da \"Big Blue\" de resolver problemas complexos com soluções de tecnologia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN6uIAfMJqdZ"
      },
      "source": [
        "**Modelos Descartados**:\n",
        "\n",
        "**K-Nearest Neighbors (KNN)**: Apesar de um recall razoável (0.647) e um AUC-ROC considerável (0.658), o KNN apresentou um Log Loss alto (1.239), tornando suas previsões pouco confiáveis para o contexto de mercado, onde a confiança nas predições é crucial para fechar vendas.\n",
        "\n",
        "**Support Vector Machine (SVM)**: Embora tenha performado de forma razoável, com métricas de AUC-ROC (0.639), F1-score (0.602) e Log Loss (0.675) razoáveis, o desempenho do modelo foi superado pela performance dos modelos favoritos.\n",
        "\n",
        "**Decision Tree**: Apresentou os segundos piores valores de Log Loss (6.882) e AUC-ROC (0.609), em comparação com os outros modelos, performance baixa que inviabilizou seu uso no contexto do projeto.\n",
        "\n",
        "**Gaussian Naive Bayes**: Explicabilidade simples, com desempenhos razoáveis para valores de AUC-ROC (0.630) e F1-score (0.612), contudo, o valor de Log Loss é ligeiramente elevado (1.107) em relação aos modelos comparados em questão, assim, apresentando uma confiabilidade menor nesse contexto.\n",
        "\n",
        "**Quadratic Discriminant Analysis (QDA)** Apresentou o pior desempenho entre todos os modelos analisados nesse contexto, com os menores valores de AUC-ROC (0.591) e F1-score (0.451) e um valor de Log Loss extremamente alto (8.235) em relação aos outros modelos, apresentando um desempenho aquém do requerido para o projeto.\n",
        "\n",
        "**LightGBM**: Apresentou desempenho considerável (Log Loss: 0.663, AUC-ROC: 0.642 e F1-score: 0.613), mas foram superados pela performance de outros modelos, que foram mais eficientes na análise das métricas escolhidas.\n",
        "\n",
        "**AdaBoost**: Embora tenha obtido valores extremamente competitivos em todas as métricas (F1-score: 0.617, AUC-ROC:\t0.671 e Log Loss:\t0.653166), representando uma das melhores performances comparativamente, seu desempenho ainda foi superado principalmente em questão de F1-score quando comparado com modelos como XGBoost e Logistic Regression.\n",
        "\n",
        "**Extra Trees**: Embora o modelo tenha apresentado métricas AUC-ROC e Log Loss extremamente competitivas, se aproximando dos melhores valores entre os modelos analisados, o F1-score (0.597) foi superado pelo desempenho de outros modelos, como XGBoost e Logisitic Regression, por exemplo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id15sCeUWatm"
      },
      "source": [
        "## Próximos Passos\n",
        "\n",
        "Com base nos resultados obtidos até o momento, a próxima fase do projeto deve focar em algumas vertentes principais:\n",
        "\n",
        "**Ajustes finos nos modelos favoritos e seleção do modelo final**: Embora o GridSearchCV já tenha sido implementado como algoritmo de otimização de hiperparâmetros, ajustes finos na configuração do grid de parâmetros podem produzir melhorias marginais no desempenho dos modelos.\n",
        "\n",
        "**Análise aprofundada e validação com o parceiro**: A fim de selecionar o modelo final, da forma mais alinhada ao contexto de mercado do parceiro, uma recapitulação das necessidades e dos ganhos esperados do parceiro é adequada, para realizar uma escolha coerente com a proposta de valor da solução e maximizar a relevância do modelo selecionado.   "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
