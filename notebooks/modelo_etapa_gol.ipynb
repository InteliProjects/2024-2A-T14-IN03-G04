{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2BVu2oYRuef"
      },
      "source": [
        "# **Modelo para prever Gol no Primeiro Tempo**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzwIUxiVR905"
      },
      "source": [
        "## Modelagem do problema\n",
        "### **Contexto de Uso**\n",
        "Este modelo será demonstrado no camarote da IBM no Allianz Parque, durante partidas de futebol. Um vendedor da IBM usará as previsões em tempo real para impressionar leads e clientes, demonstrando como as tecnologias de IA da IBM podem resolver problemas complexos e imprevisíveis, como prever gols no primeiro tempo. O objetivo é mostrar a capacidade computacional da IBM e seu valor em aplicações de negócios, visando conquistar novos clientes.\n",
        "Neste contexto de mercado, a confiança nas previsões é fundamental. O cliente final verá apenas as previsões do modelo, enquanto o time técnico da IBM terá acesso às métricas detalhadas de desempenho. Portanto, é essencial que o modelo apresente resultados robustos e confiáveis, garantindo que o cliente final tenha uma experiência positiva e confiável.\n",
        "\n",
        "### **Problema a Ser Modelado**\n",
        "O desafio é construir um modelo que, com base em variáveis numéricas derivadas de estatísticas de jogos anteriores, possa prever se o time da casa ou visitante marcará um gol no primeiro tempo. O problema é uma classificação binária, com as classes 1 (Gol no primeiro tempo) e 0 (Sem gol no primeiro tempo). Dado o cenário de uso, é crucial que o modelo seja altamente preciso, equilibrando corretamente F1-Score, AUC-ROC, e Log Loss, as métricas principais que garantirão a confiança do cliente nas previsões.\n",
        "Como o problema envolve somente variáveis numéricas, o modelo deve ser ajustado de forma que capture as relações entre essas variáveis e a ocorrência de gols, utilizando técnicas que aproveitem esse tipo de dado para maximizar a precisão das previsões. O modelo precisa ser eficiente e interpretável, garantindo que qualquer ajuste necessário possa ser feito com base nas importâncias das features e que suas previsões sejam precisas o suficiente para suportar a apresentação.\n",
        "\n",
        "### **Contexto do Projeto**\n",
        "O projeto tem como objetivo o desenvolvimento de um modelo preditivo para identificar se um dos times fará ou não um gol no primeiro tempo de uma partida de futebol. O problema é modelado como uma classificação binária, onde o objetivo é prever \"gol no primeiro tempo\" (1) ou \"sem gol no primeiro tempo\" (0). As previsões são feitas com base em dados históricos e estatísticos da Série A do Campeonato Brasileiro de 2024.\n",
        "A metodologia adotada para o desenvolvimento é o CRISP-DM (Cross Industry Standard Process for Data Mining), amplamente utilizada em projetos de mineração de dados, e combinada com Metodologias Ágeis, permitindo flexibilidade e entregas contínuas ao longo do projeto.\n",
        "\n",
        "### **Tecnologias e Metodologias**\n",
        "O Random Forest foi escolhido como o modelo inicial, dada sua eficácia em lidar com grandes conjuntos de variáveis numéricas. Esse algoritmo, além de robusto em problemas de classificação binária, fornece uma análise clara da importância das features, permitindo ajustes nas variáveis selecionadas para otimizar o desempenho do modelo.\n",
        "Combinando essas tecnologias com técnicas de validação cruzada e ajustes de hiperparâmetros, o objetivo é entregar um modelo ajustado, robusto e de alta confiança, adequado ao contexto do mercado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF5oFToKVY5W"
      },
      "source": [
        "## Organização dos Dados\n",
        "Os dados disponibilizados pelo parceiro incluem dados históricos de jogadores e suas estatísticas, além de variáveis associadas aos jogos, como times da casa e visitantes. Nesse sentido, os dados foram organizados da seguinte forma:\n",
        "\n",
        "**Conjunto de Treinamento:** Dados separados para o treinamento do modelo; nesse momento, cerca de 80% dos dados foram destinados ao conjunto de treinamento, visto que temos acesso a um conjunto de dados limitado.\n",
        "\n",
        "**Conjunto de Validação:** Nesse caso, não necessariamente define um novo subconjunto ao lado dos de treinamento e de testes, mas são os subconjuntos de dados utilizados durante o treinamento para verificar o desempenho do modelo e ajustar hiperparâmetros, garantindo que ele não sofra de overfitting. Nesse sentido, foi utilizada a validação cruzada para reconhecimento da consistência de performance do modelo, com ajuste manual e arbritário de folds (subconjuntos ainda menores criados para a realização de treinamentos intensivos e aproveitamento maior dos dados durante treinamento, o que auxilia em casos de bases de dados reduzidas).\n",
        "\n",
        "**Conjunto de Testes:** Um conjunto de dados separado que o modelo não vê durante o treinamento. Ele é usado para avaliar a performance real do modelo em dados novos e garantir uma avaliação justa de seu desempenho. Nesse momento, cerca de 20% dos dados está destinada aos testes.\n",
        "\n",
        "Os dados principais incluíram variáveis como:\n",
        "\n",
        "**Quantidade de gols pelo time da casa (home_team_goal_count_half_time):** Representa se o time da casa fez (ou não) gol no primeiro tempo da partida\n",
        "\n",
        "**Quantidade de gols pelo time visitante (away_team_goal_count_half_time):** Representa se o time visitante fez (ou não) gol no primeiro tempo da partida\n",
        "\n",
        "Por fim, conforme a modelagem do problema apresentada anteriormente, essas colunas, que eram inicialmente numéricas, foram tratadas para representar um problema de classificação binária. Dessa forma, a anterior quantidade de gols foi substituída por 0 ou 1, para representar somente a ocorrência de gols durante o primeiro tempo regular da partida.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSq2r8U7Z56Q"
      },
      "source": [
        "## Escolha de Métricas e Justificativa\n",
        "\n",
        "### **F1-Score**\n",
        "**O que é:** Média harmônica entre precisão e revocação, proporcionando uma visão equilibrada da performance do modelo.\n",
        "\n",
        "**Importância:** Garante equilíbrio entre identificação correta de gols e minimização de erros, assegurando robustez.\n",
        "\n",
        "**Valores:** Máximo: 1 (perfeito), Mínimo: 0 (nenhuma precisão/revocação).\n",
        "\n",
        "**Interpretação:** F1-Score alto mostra equilíbrio entre identificar gols e evitar erros. F1-Score baixo indica ajuste inadequado, afetando a confiança.\n",
        "\n",
        "**Justificativa:** Escolhido por balancear precisão e revocação, essencial para garantir previsões robustas e confiáveis ao cliente final.\n",
        "\n",
        "### **AUC-ROC**\n",
        "**O que é:** Mede a capacidade do modelo de distinguir entre classes, plotando verdadeiros positivos contra falsos positivos.\n",
        "\n",
        "**Importância:** Avalia a eficácia geral do modelo em diferenciar gols de não gols, aumentando a confiança no modelo.\n",
        "\n",
        "**Valores:** Máximo: 1 (perfeito), Mínimo: 0.5 (aleatório).\n",
        "\n",
        "**Interpretação:** AUC-ROC alto indica boa discriminação entre classes, essencial para lidar com a complexidade das partidas.\n",
        "\n",
        "**Justificativa:** Mostra a capacidade do modelo de diferenciar entre classes em vários limiares, reforçando a confiança nas previsões.\n",
        "\n",
        "### **Log Loss**\n",
        "**O que é:** Mede a qualidade das previsões probabilísticas, penalizando previsões erradas mais quanto mais confiantes forem.\n",
        "\n",
        "**Importância:** Avalia a confiança do modelo, garantindo previsões precisas e confiáveis.\n",
        "\n",
        "**Valores:** Máximo: ∞ (pior modelo), Mínimo: 0 (perfeito).\n",
        "\n",
        "**Interpretação:** Log Loss baixo reflete alta confiança nas previsões corretas, crucial para demonstrar confiabilidade.\n",
        "\n",
        "**Justificativa:** Log Loss reforça a qualidade das previsões, essencial para demonstrar credibilidade ao cliente.\n",
        "\n",
        "### **Conclusão**\n",
        "Essas métricas garantem um modelo robusto e confiável para apresentação ao cliente final. O F1-Score equilibra performance, o AUC-ROC demonstra discriminação, e o Log Loss avalia a qualidade probabilística, essenciais para previsões confiáveis e convincentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK0ag16AUfgy"
      },
      "source": [
        "## Entendimento e Análise Exploratória dos Dados\n",
        "Nesta etapa, o código carrega um arquivo CSV contendo dados sobre partidas de futebol da Série A de 2024 e realiza uma análise exploratória inicial. Ele utiliza bibliotecas como pandas para manipular dataframes e seaborn e matplotlib.pyplot para visualizações gráficas.\n",
        "\n",
        "O primeiro passo é filtrar as partidas com status \"complete\", garantindo que apenas os jogos concluídos sejam considerados para análise. Em seguida, verifica-se a contagem dos diferentes status dos jogos, assegurando que o dataset está corretamente formatado. Algumas colunas irrelevantes, como horário e nome do estádio, são eliminadas para evitar ruído no modelo, focando apenas nas informações úteis para a predição de gols no primeiro tempo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6W5ie6xUZQz"
      },
      "outputs": [],
      "source": [
        "# Importa as bibliotecas necessárias\n",
        "import pandas as pd  # Manipulação de dados em dataframes\n",
        "import seaborn as sns  # Visualização de dados baseada em gráficos\n",
        "import matplotlib.pyplot as plt  # Biblioteca de gráficos\n",
        "import numpy as np  # Biblioteca para manipulação numérica, arrays e operações matemáticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6jnnPFXUfrt"
      },
      "outputs": [],
      "source": [
        "# Carrega o arquivo CSV contendo o histórico de partidas de futebol da Série A 2024\n",
        "df = pd.read_csv(\"/content/brazil-serie-a-matches-2024-to-2024-stats (5).csv\", delimiter=\";\", on_bad_lines='skip')\n",
        "# Lê o arquivo CSV usando ';' como delimitador e ignora linhas com problemas no formato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "collapsed": true,
        "id": "G23Wesj-UiIR",
        "outputId": "0469455b-673f-4e08-f74a-e9f77dc6d91f"
      },
      "outputs": [],
      "source": [
        "# Filtra as partidas que estão completas\n",
        "df = df[df[\"status\"] == \"complete\"]\n",
        "# Filtra o DataFrame, mantendo apenas as partidas cujo status é \"complete\" (jogos terminados)\n",
        "\n",
        "# Conta quantas vezes cada status aparece na coluna \"status\"\n",
        "df[\"status\"].value_counts()\n",
        "# Verifica se os status das partidas estão corretos e quantos jogos estão completos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O15od6a4UkEM"
      },
      "outputs": [],
      "source": [
        "# Remove colunas inadequadas para a modelagem\n",
        "df = df.drop(columns=[\"timestamp\", \"date_GMT\", \"status\", \"attendance\", \"referee\", \"home_team_goal_timings\",\n",
        "                      \"away_team_goal_timings\", \"stadium_name\", \"Game Week\", \"home_team_goal_count\", \"away_team_goal_count\",\n",
        "                      \"total_goal_count\", \"total_goals_at_half_time\", \"away_team_goal_count_half_time\"])\n",
        "# Elimina colunas que não são necessárias para o modelo, como informações de horário, público e árbitro\n",
        "# Remove colunas relacionadas ao número de gols (contagem total e por time), pois essas são estatísticas obtidas somente após o término do jogo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXfvYvNGUvy9"
      },
      "source": [
        "## Pré-Processamento dos Dados\n",
        "O pré-processamento inclui a limpeza dos dados, transformando-os em um formato adequado para o modelo de machine learning.\n",
        "\n",
        "Um passo importante aqui é a transformação da coluna de gols do time da casa no primeiro tempo em uma variável binária (1: Gol, 0: Sem Gol), tornando o problema de classificação binária.\n",
        "\n",
        "Também é realizado o tratamento de variáveis categóricas, como os nomes dos times, utilizando pd.get_dummies, que cria variáveis dummy (0 ou 1) para representar as equipes. Esta transformação é crucial para que o modelo possa lidar com essas variáveis de forma numérica.\n",
        "\n",
        "Além disso, o código identifica valores ausentes e realiza a normalização das variáveis independentes, ajustando os dados para uma média de 0 e desvio padrão de 1 com StandardScaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9jrVk40HUt2o",
        "outputId": "f514483c-2ef0-4260-9df7-c8feb6a9d318"
      },
      "outputs": [],
      "source": [
        "# Conta o número de valores nulos por coluna no dataframe\n",
        "missing_values_count = df.isnull().sum()\n",
        "print(missing_values_count)\n",
        "# Exibe a quantidade de valores ausentes (nulos) em cada coluna, para identificar a necessidade de tratamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "cMq8QE2DVs9F",
        "outputId": "ae1cfc21-c2ed-44b7-8ccf-86ea42b3f369"
      },
      "outputs": [],
      "source": [
        "# Aplica uma transformação binária à coluna de gols no 1º tempo do time da casa\n",
        "df[\"home_team_goal_count_half_time\"] = df[\"home_team_goal_count_half_time\"].apply(lambda x: 1 if x > 0 else 0)\n",
        "# Converte a coluna que contém o número de gols do time da casa no 1º tempo em uma variável binária (1: Gol, 0: Sem Gol)\n",
        "\n",
        "# Conta os valores únicos na nova coluna binária\n",
        "df[\"home_team_goal_count_half_time\"].value_counts()\n",
        "# Exibe quantas partidas resultaram em gol (1) ou não (0) no 1º tempo para o time da casa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oLw58r3bOGL"
      },
      "outputs": [],
      "source": [
        "# Converte colunas categóricas (nomes dos times) em variáveis dummy (variáveis binárias) para o modelo\n",
        "df = pd.get_dummies(df, columns=['home_team_name', 'away_team_name'])\n",
        "# Transforma os nomes dos times em colunas com valores binários (0 ou 1) para que possam ser usadas no modelo preditivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh6YnUAsYUfN",
        "outputId": "9918e8f8-8ce1-4fc9-eebf-a469d28b9aad"
      },
      "outputs": [],
      "source": [
        "outliers_index_list = []\n",
        "\n",
        "for col in df.select_dtypes(include=np.number).columns:\n",
        "  Q1 = df[col].quantile(0.25)\n",
        "  Q3 = df[col].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  # Definir limites para outliers\n",
        "  lower_bound = Q1 - 1.5 * IQR\n",
        "  upper_bound = Q3 + 1.5 * IQR\n",
        "  # Identificar outliers\n",
        "  outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "\n",
        "  # Imprimir resultados\n",
        "  if outliers.empty:\n",
        "    print(col, \": \")\n",
        "    print(f\"Nenhum outlier encontrado em {col}\\n\")\n",
        "  else:\n",
        "    # Armazenar o índice do dicionário\n",
        "    outliers_index_list.extend(outliers.index.tolist())\n",
        "    print(col, \": \")\n",
        "    print(outliers[col])\n",
        "    print(f\"Mediana de {col}: \", df[col].median(), \"\\n\")\n",
        "\n",
        "# Remove duplicatas e ordena em ordem crescente\n",
        "outliers_index_list = set(outliers_index_list)\n",
        "outliers_index_list = sorted(outliers_index_list)\n",
        "\n",
        "# # Criar um dataframe com as linhas com o índice reconhecido ! ! !\n",
        "print(\"Linhas com outliers: \")\n",
        "print(outliers_index_list)\n",
        "\n",
        "outliers_df = pd.DataFrame()\n",
        "\n",
        "for index in outliers_index_list:\n",
        "  outlier_row = pd.Series(df.loc[index])\n",
        "  outliers_df = pd.concat([outliers_df, outlier_row.to_frame().T], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "ZIxbCFCYYpo7",
        "outputId": "7c431344-2fbf-4dc8-9b55-7980694e722a"
      },
      "outputs": [],
      "source": [
        "# Retira 20 linhas em que as métricas inconsistentes estão afetando a performance do modelo\n",
        "df = df.loc[19:245]\n",
        "# Exibe o DataFrame\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlSrxR0mU0Gu"
      },
      "source": [
        "## Engenharia de features com Random Forest Importance\n",
        "### **Relevância das features**:\n",
        "A técnica de Random Forest Importance avalia a relevância de cada feature com base na sua contribuição para a redução da impureza nas árvores de decisão que compõem o Random Forest. Cada árvore avalia um subconjunto aleatório das features e, durante o processo de treinamento, calcula-se a redução de impureza (geralmente usando Gini ou Entropia) gerada por uma feature ao dividir os dados.\n",
        "\n",
        "A importância de uma feature é a média da redução de impureza acumulada em todas as árvores do modelo. Assim, quanto maior a redução, mais relevante é a feature para a predição.\n",
        "\n",
        "### **Seleção das features**:\n",
        "O método SelectFromModel com o parâmetro prefit=True é usado para realizar a seleção automática de features com base na importância calculada pelo modelo que já foi ajustado (neste caso, o RandomForestClassifier). Esse método permite selecionar as features mais importantes, ou seja, aquelas que contribuem mais para a capacidade preditiva do modelo.\n",
        "\n",
        "Após o ajuste do modelo rf_selector, o SelectFromModel avalia as importâncias de cada feature e seleciona automaticamente aquelas cujos valores estão acima de um determinado limiar, eliminando as menos relevantes. Isso ajuda a simplificar o modelo e a reduzir o risco de overfitting, mantendo apenas as features mais impactantes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih6AYZDjVy8y"
      },
      "outputs": [],
      "source": [
        "# Importa a função para dividir os dados em treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define as variáveis independentes (X) e a dependente (y)\n",
        "X = df.drop(columns=[\"home_team_goal_count_half_time\"])  # X contém as features (todas menos o alvo)\n",
        "y = df[\"home_team_goal_count_half_time\"]  # y é a variável alvo (gol no 1º tempo do time da casa)\n",
        "\n",
        "# Divide os dados em conjuntos de treino e teste (80% treino, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Realiza a divisão dos dados, garantindo que 20% sejam reservados para teste e os 80% restantes para treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4dgld83V1OE"
      },
      "outputs": [],
      "source": [
        "# Importa a biblioteca para normalizar os dados\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cria o objeto StandardScaler para normalização\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajusta o scaler aos dados de treino e transforma os dados\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Normaliza as features (X), ajustando os dados para que tenham média 0 e desvio padrão 1, para evitar discrepâncias entre escalas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u03ZguElaYwZ"
      },
      "outputs": [],
      "source": [
        "# Importa as bibliotecas para seleção de features e o classificador Random Forest\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Treina um modelo de Random Forest para selecionar as melhores features\n",
        "rf_selector = RandomForestClassifier(random_state=42)\n",
        "rf_selector.fit(X_train_scaled, y_train)\n",
        "# Ajusta o classificador Random Forest com os dados de treino, identificando a importância de cada feature\n",
        "\n",
        "# Seleciona as features mais relevantes com base no modelo Random Forest\n",
        "selector = SelectFromModel(rf_selector, prefit=True)\n",
        "X_train_selected = selector.transform(X_train_scaled)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "# Transforma os dados de treino e teste para conter apenas as features mais importantes, segundo o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "wcegPB0lvCM8",
        "outputId": "17e2e54b-9ec0-4409-df2c-17a00d96767e"
      },
      "outputs": [],
      "source": [
        "# Obter as importâncias das features\n",
        "importances = rf_selector.feature_importances_\n",
        "\n",
        "# Obter os nomes das features originais\n",
        "features = X.columns\n",
        "\n",
        "# Filtrar as features selecionadas\n",
        "selected_features = features[selector.get_support()]\n",
        "\n",
        "feature_importance_list = []\n",
        "\n",
        "# Exibir as features mais importantes e suas importâncias\n",
        "for feature, importance in zip(selected_features, importances[selector.get_support()]):\n",
        "    feature_importance_list.append((feature, importance))\n",
        "\n",
        "# Ordena as features por importância\n",
        "feature_importance_list.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "feature_importance_list\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(data=feature_importance_list[:10], x=[x[0] for x in feature_importance_list[:10]], height=[x[1] for x in feature_importance_list[:10]])\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Importância')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5-2RWaEU4vv"
      },
      "source": [
        "## Treinamento do Modelo\n",
        "O modelo preditivo escolhido é o RandomForestClassifier, um algoritmo de aprendizado de ensemble que combina o poder de múltiplas árvores de decisão para criar um modelo mais robusto e estável. O algoritmo constrói diversas árvores utilizando amostras diferentes dos dados de treino e seleciona subgrupos aleatórios de features em cada nó, aumentando a diversidade entre as árvores e reduzindo o risco de overfitting. O RandomForestClassifier é conhecido por sua resistência a dados ruidosos e pela capacidade de capturar interações complexas entre variáveis, o que o torna uma escolha ideal para problemas preditivos complexos, como prever se haverá um gol no primeiro tempo de uma partida.\n",
        "\n",
        "## Validação Cruzada\n",
        "Para garantir que o modelo seja avaliado de forma consistente e generalizável, foi utilizada a técnica de Validação Cruzada com 5 folds. Essa abordagem divide o conjunto de dados em 5 partes iguais, onde o modelo é treinado em 4 dessas partes e testado na parte restante. Esse processo é repetido 5 vezes, garantindo que cada parte seja usada como conjunto de teste uma vez. A validação cruzada fornece uma avaliação mais confiável do desempenho do modelo ao evitar que o resultado dependa de uma única divisão dos dados.\n",
        "\n",
        "Durante a validação, o modelo é avaliado utilizando métricas essenciais como Acurácia, Precisão, Recall, F1-Score, AUC-ROC e Log Loss. Essas métricas fornecem uma visão abrangente sobre o desempenho, medindo desde a capacidade do modelo em prever corretamente as classes (gols ou não no 1º tempo), até a taxa de falsos positivos e a qualidade geral das previsões probabilísticas.\n",
        "\n",
        "Após o processo de validação, o modelo é treinado no conjunto completo de dados e as previsões são geradas no conjunto de teste, permitindo uma análise final do seu desempenho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyFf_FJCLAbA"
      },
      "outputs": [],
      "source": [
        "# Define o modelo Random Forest que será usado para treinar e avaliar\n",
        "rf_model = RandomForestClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAQbN_K1bY67"
      },
      "outputs": [],
      "source": [
        "# Dicionário para armazenar os resultados da validação cruzada para o Random Forest\n",
        "cv_results_dict = {\n",
        "    'Modelo': [],\n",
        "    'Acurácia (CV)': [],\n",
        "    'Precisão (CV)': [],\n",
        "    'Recall (CV)': [],\n",
        "    'F1-Score (CV)': [],\n",
        "    'AUC-ROC (CV)': [],\n",
        "    'Log Loss (CV)': []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jVjDqIWKusy"
      },
      "outputs": [],
      "source": [
        "# Importa função para realizar validação cruzada\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Define o número de folds (divisões) para a validação cruzada\n",
        "n_folds = 5\n",
        "\n",
        "# Realiza validação cruzada com diferentes métricas para o modelo Random Forest\n",
        "cv_results = cross_validate(rf_model, X_train_selected, y_train, cv=n_folds,\n",
        "                            scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'neg_log_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9t2kt1bVpC7"
      },
      "outputs": [],
      "source": [
        "# Armazena os resultados médios das métricas no dicionário\n",
        "cv_results_dict['Modelo'].append('Random Forest')\n",
        "cv_results_dict['Acurácia (CV)'].append(cv_results['test_accuracy'].mean())\n",
        "cv_results_dict['Precisão (CV)'].append(cv_results['test_precision'].mean())\n",
        "cv_results_dict['Recall (CV)'].append(cv_results['test_recall'].mean())\n",
        "cv_results_dict['F1-Score (CV)'].append(cv_results['test_f1'].mean())\n",
        "cv_results_dict['AUC-ROC (CV)'].append(cv_results['test_roc_auc'].mean())\n",
        "cv_results_dict['Log Loss (CV)'].append(-cv_results['test_neg_log_loss'].mean())\n",
        "# Valida o modelo Random Forest com 5 folds e calcula as métricas de desempenho, como acurácia, precisão, recall, F1-Score, AUC-ROC e Log Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "UEF1PJ8YLx82",
        "outputId": "3d3ff562-42b0-4f99-a1e8-143405705302"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Supondo que 'y_true' e 'y_pred' são as verdadeiras e preditas classes\n",
        "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "\n",
        "# Plotando a matriz de confusão normalizada\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, annot=True, fmt='.2', cmap='Blues')\n",
        "plt.title('Matriz de Confusão Normalizada')\n",
        "plt.ylabel('Classe Real')\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "FgUjl-9XLNlp",
        "outputId": "b2f6a292-d56f-4c88-f404-9756fe77ba86"
      },
      "outputs": [],
      "source": [
        "# Converte os resultados da validação cruzada para um DataFrame para facilitar a visualização\n",
        "cv_results_df = pd.DataFrame(cv_results_dict)\n",
        "\n",
        "# Exibe os resultados de validação cruzada\n",
        "print(\"\\nDesempenho do Modelo Random Forest com Validação Cruzada:\")\n",
        "cv_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsySc6c4U9LR"
      },
      "source": [
        "## Discussão dos Resultados do Modelo e Conclusões\n",
        "### **Comparação com o Contexto de Mercado**\n",
        "Dado o cenário de demonstração ao vivo no camarote da IBM no Allianz Parque, a confiança e robustez das previsões são fundamentais para impressionar leads e clientes, demonstrando o poder das tecnologias da IBM. No entanto, as métricas atuais indicam que o modelo não está suficientemente refinado para garantir essa confiança:\n",
        "#### - **F1-Score (0.57):**\n",
        "Reflete um equilíbrio mediano entre a identificação de jogos com gols e a minimização de falsos positivos. No contexto de mercado, um F1-Score mais alto seria preferível para demonstrar que o modelo tem precisão e capacidade de recuperação adequadas, garantindo que o cliente veja previsões mais certeiras e menos falhas.\n",
        "#### - **AUC-ROC (0.6):**\n",
        "Esta métrica revela que o modelo consegue discriminar entre jogos com e sem gols, mas com uma performance ligeiramente acima do acaso. Para garantir que o modelo é confiável e robusto o suficiente para uma apresentação ao vivo, uma AUC-ROC acima de 0.7 seria recomendada, proporcionando mais confiança na capacidade do modelo de distinguir entre as classes (gol/no gol).\n",
        "#### - **Log Loss (0.69):**\n",
        "Indica que o modelo ainda não está fazendo previsões probabilísticas com alta confiança. Idealmente, um valor de Log Loss mais próximo de 0 garantiria que o modelo está não apenas prevendo corretamente, mas também gerando previsões confiáveis, o que é essencial em um ambiente de demonstração onde cada previsão errada pode afetar a credibilidade da IBM.\n",
        "### **Oportunidades de Melhoria**\n",
        "Dado que o desempenho atual é razoável, mas longe do ideal para um ambiente de vendas com alto impacto, os próximos passos devem incluir uma comparação com outros modelos preditivos, como Gradient Boosting e XG Boost, para identificar qual deles oferece o melhor desempenho para o problema de classificação binária de gols no primeiro tempo. Além disso, ajustes de hiperparâmetros e uso de técnicas avançadas de validação cruzada podem ajudar a melhorar as métricas escolhidas, principalmente no aumento do F1-Score e da AUC-ROC, além da redução do Log Loss.\n",
        "### **Foco nas Métricas para Apresentação ao Cliente**\n",
        "Portanto, melhorias nessas métricas são imprescindíveis para elevar a qualidade do modelo a um nível em que a IBM possa apresentar previsões com mais confiança e precisão, consolidando a credibilidade de suas tecnologias perante os leads e clientes durante as demonstrações no Allianz Parque.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
