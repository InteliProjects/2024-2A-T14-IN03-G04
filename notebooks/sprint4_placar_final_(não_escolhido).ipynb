{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SWgQMfZryp7"
      },
      "source": [
        "### Modelo preditivo de Placar Final\n",
        "\n",
        "### **Introdução**\n",
        "O presente Colab tem como objetivo apresentar o processo de desenvolvimento de um dos modelos preditivos candidatos para responder a pergunta: **\"Qual será o placar final?\"**\n",
        "\n",
        "Durante a Sprint 4, dedicamos tempo principalmente em uma realização de nova análise e exploração de dados (com escolhas de novas features), e também testes de diferentes modelos preditivos, visando melhorar as métricas dos modelos nas previsões de número de gols do time da casa e de visitante em uma partida.\n",
        "\n",
        "#### **1. Exploração de Dados**\n",
        "Realizamos uma extensa análise dos dados disponíveis, incluindo uma limpeza inicial para remover duplicatas e valores nulos. Fizemos o merge das tabelas com informações sobre os times e as partidas, e selecionamos as variáveis mais relevantes para a modelagem. Além disso, utilizamos técnicas estatísticas e visualizações como matrizes de correlação e heatmaps para identificar as variáveis mais importantes relacionadas aos gols do time da casa e visitante.\n",
        "\n",
        "#### **2. Testagem de Diversos Modelos**\n",
        "Após preparar a base de dados, exploramos diversos modelos de classificação, realizando validação cruzada e demonstrando métricas para avaliação de desempenho de modelos.\n",
        "\n",
        "\n",
        "**Observação:** esse NÃO foi o modelo escolhido, nem é o Colab que é usado como base de comparação de modelos para a Sprint 4. Está sendo apresentado para fins de demonstração de aprendizagem do grupo, como solicitado pela orientadora.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "399ir70FtKCI"
      },
      "source": [
        "#### Configuração de ambiente de desenvolvimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL_uq_jLKB7k",
        "outputId": "17854dfe-6ee2-4d30-d462-fbe916a5a18a"
      },
      "outputs": [],
      "source": [
        "# Instalar bibliotecas necessárias\n",
        "!pip install pandas matplotlib seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP1Z3TUsKlyF"
      },
      "outputs": [],
      "source": [
        "# Importação de bibliotecas para análise de dados, visualização e modelagem\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBn2vj_xyuBO"
      },
      "source": [
        "### **1. Exploração e Análise de Dados**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZAWk3Agy6Zv"
      },
      "source": [
        "#### **1.1. Carregamento e limpeza de dados**\n",
        "\n",
        "*   Remoção de duplicatas e nulos\n",
        "*   Escolha de apenas de jogos completos\n",
        "*   Descrição estatística\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwtgkggMKnPJ"
      },
      "outputs": [],
      "source": [
        "# Carregar tabelas CSV com informações de times e partidas, para realizar o merge das tabelas mais relevantes para o \"placar final\"\n",
        "\n",
        "teams1 = pd.read_csv('brazil-serie-a-teams-2024-to-2024-stats.csv')\n",
        "teams2 = pd.read_csv('brazil-serie-a-teams2-2024-to-2024-stats.csv')\n",
        "matches = pd.read_csv('brazil-serie-a-matches-2024-to-2024-stats.csv', sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPNwhXGpKpD3"
      },
      "outputs": [],
      "source": [
        "# Remover duplicatas e valores nulos em cada tabela\n",
        "teams1.drop_duplicates(inplace=True)\n",
        "teams1.dropna(inplace=True)\n",
        "\n",
        "teams2.drop_duplicates(inplace=True)\n",
        "teams2.dropna(inplace=True)\n",
        "\n",
        "matches.drop_duplicates(inplace=True)\n",
        "matches.dropna(subset=['status'], inplace=True)  # Remover apenas linhas com status nulo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzULYKFCSKPe",
        "outputId": "34c20ff9-b50d-4eed-a242-1767836e4db2"
      },
      "outputs": [],
      "source": [
        "# Exibir uma descrição dos datasets, com informações estatísticas\n",
        "\n",
        "print(matches.describe())\n",
        "print(teams1.describe())\n",
        "print(teams2.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwacCh7fQE8O"
      },
      "outputs": [],
      "source": [
        "# Filtra apenas jogos completos no dataset matches\n",
        "matches = matches[matches['status'] == 'complete']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "F3nBLZl1P408",
        "outputId": "935eb0f0-9687-4297-9da9-fcc77f603335"
      },
      "outputs": [],
      "source": [
        "# Mostra as primeiras linhas do dataset de partidas após filtragem\n",
        "matches.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tTO8Y8mu2-Y"
      },
      "source": [
        "#### **1.2. Merge das tabelas**\n",
        "\n",
        "*   Junção das tabelas baseado em team_name\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ_9ikCTQHuJ"
      },
      "outputs": [],
      "source": [
        "# Merge das tabelas teams1 e teams2\n",
        "teams = pd.concat([teams1, teams2], axis=0).drop_duplicates(subset=['team_name'])\n",
        "\n",
        "# Merge com a tabela matches baseado no nome do time\n",
        "merged_df = matches.merge(teams, left_on='home_team_name', right_on='team_name', how='left')\n",
        "merged_df = merged_df.merge(teams, left_on='away_team_name', right_on='team_name', how='left', suffixes=('_home', '_away'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "2YnYIc9UQSwt",
        "outputId": "e3c9905a-00c2-40ff-9d7a-d0b991f00bb0"
      },
      "outputs": [],
      "source": [
        "# Mostra as 5 primeiras linhas do dataset de partidas após o merge de arquivos\n",
        "\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lPO1-ysSbJn"
      },
      "outputs": [],
      "source": [
        "# Remove as colunas irrelevantes como timestamp, date_GMT, referee, e outras que não contribuem para a predição\n",
        "columns_to_drop = ['timestamp', 'attendance', 'date_GMT', 'referee', 'stadium_name']\n",
        "\n",
        "# Removendo essas colunas das três tabelas principais\n",
        "merged_df = merged_df.drop(columns=columns_to_drop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "eeRnlowIR676",
        "outputId": "77c5110a-ffa3-4ba9-8519-dfe5263fb278"
      },
      "outputs": [],
      "source": [
        "# Mostra as 5 primeiras linhas do dataset de partidas depois de tirar essas colunas\n",
        "merged_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wopBVqqrcoa"
      },
      "source": [
        "#### **1.3. Label Encoding (nomes de times)**\n",
        "*   Codificação das features categóricas, nesse caso os nomes dos times `(home_team_name,\taway_team_name)`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INBp-gbDFCcO",
        "outputId": "f32b51fe-b3d1-4179-c491-3693a4dd5011"
      },
      "outputs": [],
      "source": [
        "# Cria um dicionário para organizar o nome dos times a um número único\n",
        "team_mapping = {\n",
        "    'Atlético GO': 1,\n",
        "    'Botafogo': 2,\n",
        "    'Atlético Mineiro': 3,\n",
        "    'Atlético PR': 4,\n",
        "    'Flamengo': 5,\n",
        "    'Vasco da Gama': 6,\n",
        "    'Bragantino': 7,\n",
        "    'Criciúma': 8,\n",
        "    'Cruzeiro': 9,\n",
        "    'Cuiabá': 10,\n",
        "    'Bahia': 11,\n",
        "    'Juventude': 12,\n",
        "    'Vitória': 13,\n",
        "    'Fluminense': 14,\n",
        "    'Fortaleza': 15,\n",
        "    'Grêmio': 16,\n",
        "    'Corinthians': 17,\n",
        "    'Internacional': 18,\n",
        "    'Palmeiras': 19,\n",
        "    'São Paulo': 20\n",
        "}\n",
        "\n",
        "merged_df['home_team_name_encoded'] = merged_df['home_team_name'].map(team_mapping)\n",
        "merged_df['away_team_name_encoded'] = merged_df['away_team_name'].map(team_mapping)\n",
        "\n",
        "print(merged_df[['home_team_name', 'away_team_name', 'home_team_name_encoded', 'away_team_name_encoded']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATvPfb4OS478"
      },
      "outputs": [],
      "source": [
        "# Função para remover colunas com muitos valores nulos\n",
        "def clean_data(df, threshold=0.8):\n",
        "    merged_df = df.dropna(thresh=df.shape[0] * (1 - threshold), axis=1)\n",
        "    return merged_df\n",
        "\n",
        "# Limpar o dataframe, mantendo colunas com menos de 80% de valores nulos\n",
        "merged_df = clean_data(merged_df, threshold=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "6uTHYVMvTV9S",
        "outputId": "98cfeb65-adf3-436d-f2c7-30d3bc01194f"
      },
      "outputs": [],
      "source": [
        "# Selecionar apenas colunas numéricas\n",
        "merged_df = merged_df.select_dtypes(include=['float64', 'int64'])\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB_0rkB3wfJ3"
      },
      "source": [
        "#### **1.4. Matriz de correlação (gols da casa e visitante)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swmjG384QKDp",
        "outputId": "a9b086e9-f048-42e2-a084-d4a82fe607ca"
      },
      "outputs": [],
      "source": [
        "# Calcula a matriz de correlação e a correlação dos gols da casa e do visitante\n",
        "\n",
        "correlation_matrix = merged_df.corr()\n",
        "home_goals_corr = correlation_matrix['home_team_goal_count'].sort_values(ascending=False)\n",
        "away_goals_corr = correlation_matrix['away_team_goal_count'].sort_values(ascending=False)\n",
        "\n",
        "# Exibe as 10 maiores correlações com os gols da casa e do visitante\n",
        "home_goals_corr.head(10), away_goals_corr.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C4y6C8zOT8JQ",
        "outputId": "2aa21d96-3d6e-4802-d21f-4c6ef2da0ea9"
      },
      "outputs": [],
      "source": [
        "# Mostra a matriz de correlação usando um heatmap\n",
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "sns.heatmap(merged_df.corr(), annot=False, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title(\"Matriz de Correlação\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1egKoqzvxK-A"
      },
      "source": [
        "#### **1.5. Remoção de outliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l00P92zHUXZd"
      },
      "outputs": [],
      "source": [
        "# Padroniza os dados para identificar outliers\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(merged_df.select_dtypes(include=[np.number]))\n",
        "\n",
        "# Algoritmo para detecção de outliers\n",
        "iso_forest = IsolationForest(contamination=0.05)\n",
        "outliers = iso_forest.fit_predict(scaled_data)\n",
        "\n",
        "# Filtra os outliers (onde outliers == 1 são os dados normais)\n",
        "cleaned_df = merged_df[outliers == 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "kMZxxxb4C_ct",
        "outputId": "079c2716-764e-4d23-a014-eb98e9d8b287"
      },
      "outputs": [],
      "source": [
        "# Mostra o dataframe após limpeza de outliers\n",
        "cleaned_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "CiNl6gOyUaH8",
        "outputId": "41045366-d79d-4c64-c2a7-d4d99eb6c20c"
      },
      "outputs": [],
      "source": [
        "# Apresenta graficamente a distribuição dos gols da casa após remover outliers\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x=cleaned_df['home_team_goal_count'])\n",
        "plt.title('Distribuição da Assistência (Sem Outliers)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75ib2cj0IAfd"
      },
      "source": [
        "### **2. Testagem de modelos preditivos e avaliação de métricas**\n",
        "\n",
        "Nessa etapa vamos testar uma variedade de modelos de classificação e regressão, incluindo desde métodos mais simples, como Regressão Logística, até algoritmos avançados como XGBoost, LightGBM, Gradient Boosting e Random Forest.\n",
        "\n",
        "Pra cada modelo, realizamos validação cruzada para garantir a consistência dos resultados.\n",
        "\n",
        "Exploramos também métricas variadas para avaliar o desempenho, como Acurácia, Precisão, Recall, F1-Score, AUC-ROC e Log Loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbaIXuTqIBTH"
      },
      "outputs": [],
      "source": [
        "# Separar as features (X) e os targets (y) para gols da casa e do visitante\n",
        "X =  merged_df.drop(['home_team_goal_count', 'away_team_goal_count'], axis=1)\n",
        "y_home = merged_df['home_team_goal_count']\n",
        "y_away =  merged_df['away_team_goal_count']\n",
        "\n",
        "# Divisão do conjunto de dados em treino e teste\n",
        "X_train, X_test, y_train_home, y_test_home = train_test_split(X, y_home, test_size=0.3, random_state=42)\n",
        "X_train, X_test, y_train_away, y_test_away = train_test_split(X, y_away, test_size=0.3, random_state=42)\n",
        "\n",
        "# Normalização dos dados\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB4cLMI5yhfo"
      },
      "source": [
        "#### **2.1. Foco Principal no Time da Casa:**\n",
        "\n",
        "A partir desse momento, iremos analisar principalmente o desempenho dos modelos para a variável de \"home_team_goal_count\", buscando identificar quais algoritmos apresentavam melhor desempenho para prever o número de gols do time da casa.\n",
        "\n",
        "\n",
        "**`Definição e Avaliação de Modelos:`**\n",
        "\n",
        "  Nesta seção, definimos e avaliamos diferentes modelos de classificação para prever o **número de gols do time da casa.**\n",
        "O processo envolve a configuração de um conjunto de modelos, aplicação de validação cruzada e cálculo das principais métricas de desempenho.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FGU_q8c471t"
      },
      "source": [
        "#### **2.2. Testes em modelos, métricas e cross-validation**\n",
        "\n",
        "  **`Modelos testados:`**\n",
        "\n",
        "- Logistic Regression\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Support Vector Machine (SVM)\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "- Gradient Boosting\n",
        "- AdaBoost\n",
        "- XGBoost\n",
        "- LightGBM\n",
        "- Extra Trees\n",
        "- Gaussian Naive Bayes\n",
        "- Linear Discriminant Analysis (LDA)\n",
        "- Quadratic Discriminant Analysis (QDA)\n",
        "\n",
        "**`Validação Cruzada:`**\n",
        "\n",
        "Para avaliar o desempenho de cada modelo, utilizamos um processo de **validação cruzada** com 5 folds (`n_folds = 5`). Este processo divide os dados em 5 partes e treina o modelo em 4 partes, utilizando a parte restante para avaliação.\n",
        "Esse processo é repetido até que todos os subconjuntos tenham sido usados como conjunto de teste uma vez, resultando em uma média das métricas de desempenho.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aMGJTA5pIYO0",
        "outputId": "4c1cd568-cd37-43d2-dbbb-a4ebe4f343c2"
      },
      "outputs": [],
      "source": [
        "# Definir os modelos a serem testados com hiperparâmetros\n",
        "\n",
        "model_dict = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Support Vector Machine': SVC(probability=True, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    'LightGBM': LGBMClassifier(random_state=42),\n",
        "    'Extra Trees': ExtraTreesClassifier(random_state=42),\n",
        "    'Gaussian Naive Bayes': GaussianNB(),\n",
        "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
        "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis()\n",
        "}\n",
        "\n",
        "cv_results_dict_home = {\n",
        "    'Modelo': [],\n",
        "    'Acurácia': [],\n",
        "    'Precisão': [],\n",
        "    'Recall': [],\n",
        "    'F1-Score': [],\n",
        "    'AUC-ROC': [],\n",
        "    'Log Loss': []\n",
        "}\n",
        "\n",
        "# Número de folds para validação cruzada\n",
        "n_folds = 5\n",
        "\n",
        "# Treinar e avaliar cada modelo\n",
        "for model_name, model in model_dict.items():\n",
        "    # Validação cruzada\n",
        "    cv_results = cross_validate(model, X_train_scaled, y_train_home, cv=n_folds,\n",
        "                                scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'neg_log_loss'])\n",
        "\n",
        "    # Armazenar resultados\n",
        "    cv_results_dict_home['Modelo'].append(model_name)\n",
        "    cv_results_dict_home['Acurácia'].append(cv_results['test_accuracy'].mean())\n",
        "    cv_results_dict_home['Precisão'].append(cv_results['test_precision'].mean())\n",
        "    cv_results_dict_home['Recall'].append(cv_results['test_recall'].mean())\n",
        "    cv_results_dict_home['F1-Score'].append(cv_results['test_f1'].mean())\n",
        "    cv_results_dict_home['AUC-ROC'].append(cv_results['test_roc_auc'].mean())\n",
        "    cv_results_dict_home['Log Loss'].append(-cv_results['test_neg_log_loss'].mean())\n",
        "\n",
        "# Convertendo resultados para DataFrame\n",
        "cv_results_df_home = pd.DataFrame(cv_results_dict_home)\n",
        "\n",
        "# Ordenar por Log Loss\n",
        "cv_results_df_home = cv_results_df_home.sort_values(by='Log Loss', ascending=True)\n",
        "\n",
        "# Exibir resultados\n",
        "cv_results_df_home\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7vG_zbW11-i"
      },
      "source": [
        "Durante a fase de validação cruzada dos modelos, observamos que várias métricas, como Precisão, Recall, F1-Score, AUC-ROC e Log Loss, retornaram valores `NaN` (não numéricos). Esse comportamento foi verificado em diferentes modelos, como Logistic Regression, K-Nearest Neighbors, SVM, entre outros.\n",
        "\n",
        "Entendemos que esse problema pode ter ocorrido devido a algumas razões, como:\n",
        "\n",
        "**Desequilíbrio de Classes**:\n",
        "\n",
        "Em alguns casos, a classe preditiva não estava presente em alguns folds da validação cruzada. Isso resulta em métricas como Precisão e Recall retornando valores indefinidos, pois não há exemplos positivos ou negativos suficientes em um determinado fold para o cálculo dessas métricas.\n",
        "\n",
        "**Modelos x Métricas**:\n",
        "\n",
        "Algumas métricas, como AUC-ROC e Log Loss, requerem que o modelo retorne probabilidades, e certos modelos não possuem o suporte adequado para o método `predict_proba()` ou `decision_function()`, o que impede o cálculo correto dessas métricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRLI6YnSKdJt",
        "outputId": "10fba644-e1cc-44c0-e432-47f9a2841a36"
      },
      "outputs": [],
      "source": [
        "print(\"Resultados para Gols do Time da Casa\")\n",
        "print(cv_results_df_home)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs6qkQ7D4zuF"
      },
      "source": [
        "#### **2.3. Aplicação do melhor modelo**\n",
        "\n",
        "Foi escolhido o modelo `Linear Discriminant Analysis (LDA)`, que é uma técnica de classificação multi-classe, para fazer as predições dos gols do time da casa. Esse modelo tenta encontrar a combinação linear de variáveis que melhor separa as classes e gera uma previsão para cada amostra de teste sobre quantos gols o time da casa fez.\n",
        "\n",
        "A avaliação do modelo é feita através da métrica de acurácia usando accuracy_score, que compara as predições do modelo (y_pred_home) com os valores reais de gols do time da casa (y_test_home), sendo, nesse momento, de 58%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egUlBhvIL4O-",
        "outputId": "75bed1ed-9a27-4cdf-a7fe-11b852d26628"
      },
      "outputs": [],
      "source": [
        "best_model_home = LinearDiscriminantAnalysis()\n",
        "best_model_home.fit(X_train_scaled, y_train_home)\n",
        "\n",
        "# Fazer predições\n",
        "y_pred_home = best_model_home.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar as predições\n",
        "accuracy_home = accuracy_score(y_test_home, y_pred_home)\n",
        "\n",
        "print(f\"Acurácia (Gols Casa): {accuracy_home}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2zR8Szi4Ijb"
      },
      "source": [
        "### **Conclusão**\n",
        "\n",
        "Embora alguns modelos, como Linear Discriminant Analysis (escolhido como `best_model` (o melhor modelo) e Random Forest tenham mostrado um **desempenho aceitável** em métricas específicas, no geral, a variação de resultados entre os diferentes algoritmos foi grande, o que comprometeu a confiança nas previsões.\n",
        "\n",
        "Além disso, devido ao o tempo limitado disponível para a Sprint, **decidimos utilizar outro modelo de Placar Final** (melhor ajustado) para predição dos gols do time da casa e time visitante.\n",
        "\n",
        "Entendemos que seguindo principalmente uma abordagem de classificação exigiria ajustes significativos nos dados (como balanceamento de classes).\n",
        "\n",
        "Por outro lado, temos outros **modelos candidatos, de regressão principalmente,** para responder essa mesma pergunta (que serão, portanto, utilizados para submissão do artefato e estará documentado como modelo principal para essa pergunta).\n",
        "\n",
        "Sendo assim, o conteúdo do presente documento termina aqui, nós optamos por focar em outro modelo pra placar final, que apresentou métricas mais confiáveis durante a validação e **produziu comparações melhor fundamentadas** e maior explicabilidade."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
